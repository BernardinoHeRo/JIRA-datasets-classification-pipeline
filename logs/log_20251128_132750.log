=== INICIO DE EJECUCI√ìN DEL PIPELINE ===
Timestamp: 2025-11-28 13:27:50
==================================================



********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: activemq-5.0.0 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: activemq-5.0.0
[1] Preprocesamiento - Dimensiones originales: (1884, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1884, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (1507, 66), X_test: (377, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con activemq-5.0.0 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con activemq-5.0.0 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 1273
    Clase Minoritaria (1): 234
    Total de clases: 1507
    Ratio de desbalance: 5.44

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 753

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 520
[Minor√≠a] Tama√±o final (original + sint√©tico): 754

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 1507
    Distribuci√≥n clases: {1: 754, 0: 753}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con activemq-5.0.0 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 1273 muestras
    Clase minoritaria (1): 234 muestras
    Total de clases: 1507
    Ratio de desbalance: 5.44

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 753

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 519
[Minoritaria] Tama√±o final (original + sint√©tico): 753

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 1506
    Distribuci√≥n clases: {0: 753, 1: 753}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con activemq-5.0.0 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  1273
     Clase minoritaria (1):  234
     Total de clases:  1507
     Indice de desbalance:  5.44

[SMOTE] Clase mayoritaria (0): 1273 -> 753 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 753, 1: 753}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando activemq-5.0.0 con standard
[3] [unbalanced] Escalando activemq-5.0.0 con robust
[3] [csbboost] Escalando activemq-5.0.0 con standard
[3] [csbboost] Escalando activemq-5.0.0 con robust
[3] [hcbou] Escalando activemq-5.0.0 con standard
[3] [hcbou] Escalando activemq-5.0.0 con robust
[3] [smote] Escalando activemq-5.0.0 con standard
[3] [smote] Escalando activemq-5.0.0 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: activemq-5.0.0
================================================================================

üìã Total de configuraciones a procesar: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado: ['standard', 'robust']
   ‚Ä¢ Modelos por config: 3

********************************************************************************
[1/8] PROCESANDO CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: activemq-5.0.0 | unbalanced | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/activemq-5.0.0/standard
       ‚úì Datos cargados: X_train=(1507, 65), X_test=(377, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/activemq-5.0.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/activemq-5.0.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] PROCESANDO CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: activemq-5.0.0 | unbalanced | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/activemq-5.0.0/robust
       ‚úì Datos cargados: X_train=(1507, 65), X_test=(377, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/activemq-5.0.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/activemq-5.0.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] PROCESANDO CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: activemq-5.0.0 | csbboost | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/activemq-5.0.0/standard
       ‚úì Datos cargados: X_train=(1507, 65), X_test=(377, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/activemq-5.0.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/activemq-5.0.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] PROCESANDO CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: activemq-5.0.0 | csbboost | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/activemq-5.0.0/robust
       ‚úì Datos cargados: X_train=(1507, 65), X_test=(377, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/activemq-5.0.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/activemq-5.0.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] PROCESANDO CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: activemq-5.0.0 | hcbou | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/activemq-5.0.0/standard
       ‚úì Datos cargados: X_train=(1506, 65), X_test=(377, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/activemq-5.0.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/activemq-5.0.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] PROCESANDO CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: activemq-5.0.0 | hcbou | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/activemq-5.0.0/robust
       ‚úì Datos cargados: X_train=(1506, 65), X_test=(377, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/activemq-5.0.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/activemq-5.0.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] PROCESANDO CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: activemq-5.0.0 | smote | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/activemq-5.0.0/standard
       ‚úì Datos cargados: X_train=(1506, 65), X_test=(377, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/activemq-5.0.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/activemq-5.0.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] PROCESANDO CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: activemq-5.0.0 | smote | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/activemq-5.0.0/robust
       ‚úì Datos cargados: X_train=(1506, 65), X_test=(377, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/activemq-5.0.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/activemq-5.0.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: activemq-5.0.0
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: activemq-5.0.0
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | unbalanced | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      305        13
            Buggy          25        34
      ==================================================
      TN=305  FP=13  FN=25  TP=34
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 34
         True Negatives  (TN): 305
         False Positives (FP): 13
         False Negatives (FN): 25

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1008
         Exactitud = (TP + TN) / N          = 0.8992
         Verificaci√≥n: 1 - Error            = 0.8992

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5763
         FP-Rate = FP / N                   = 0.0409

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7234
         Recall = TP / P (= TP-Rate)        = 0.5763

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5763
         Especificidad = TN / N             = 0.9591
         Verificaci√≥n: 1 - FP-Rate          = 0.9591

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6415

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      290        28
            Buggy          25        34
      ==================================================
      TN=290  FP=28  FN=25  TP=34
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 34
         True Negatives  (TN): 290
         False Positives (FP): 28
         False Negatives (FN): 25

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1406
         Exactitud = (TP + TN) / N          = 0.8594
         Verificaci√≥n: 1 - Error            = 0.8594

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5763
         FP-Rate = FP / N                   = 0.0881

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5484
         Recall = TP / P (= TP-Rate)        = 0.5763

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5763
         Especificidad = TN / N             = 0.9119
         Verificaci√≥n: 1 - FP-Rate          = 0.9119

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5620

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      300        18
            Buggy          27        32
      ==================================================
      TN=300  FP=18  FN=27  TP=32
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 32
         True Negatives  (TN): 300
         False Positives (FP): 18
         False Negatives (FN): 27

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1194
         Exactitud = (TP + TN) / N          = 0.8806
         Verificaci√≥n: 1 - Error            = 0.8806

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5424
         FP-Rate = FP / N                   = 0.0566

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6400
         Recall = TP / P (= TP-Rate)        = 0.5424

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5424
         Especificidad = TN / N             = 0.9434
         Verificaci√≥n: 1 - FP-Rate          = 0.9434

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5872

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | unbalanced | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      284        34
            Buggy          32        27
      ==================================================
      TN=284  FP=34  FN=32  TP=27
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 27
         True Negatives  (TN): 284
         False Positives (FP): 34
         False Negatives (FN): 32

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1751
         Exactitud = (TP + TN) / N          = 0.8249
         Verificaci√≥n: 1 - Error            = 0.8249

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4576
         FP-Rate = FP / N                   = 0.1069

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4426
         Recall = TP / P (= TP-Rate)        = 0.4576

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4576
         Especificidad = TN / N             = 0.8931
         Verificaci√≥n: 1 - FP-Rate          = 0.8931

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4500

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       318
            Buggy           2        57
      ==================================================
      TN=0  FP=318  FN=2  TP=57
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 57
         True Negatives  (TN): 0
         False Positives (FP): 318
         False Negatives (FN): 2

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8488
         Exactitud = (TP + TN) / N          = 0.1512
         Verificaci√≥n: 1 - Error            = 0.1512

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9661
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1520
         Recall = TP / P (= TP-Rate)        = 0.9661

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9661
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2627

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      300        18
            Buggy          27        32
      ==================================================
      TN=300  FP=18  FN=27  TP=32
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 32
         True Negatives  (TN): 300
         False Positives (FP): 18
         False Negatives (FN): 27

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1194
         Exactitud = (TP + TN) / N          = 0.8806
         Verificaci√≥n: 1 - Error            = 0.8806

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5424
         FP-Rate = FP / N                   = 0.0566

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6400
         Recall = TP / P (= TP-Rate)        = 0.5424

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5424
         Especificidad = TN / N             = 0.9434
         Verificaci√≥n: 1 - FP-Rate          = 0.9434

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5872

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       318
            Buggy           0        59
      ==================================================
      TN=0  FP=318  FN=0  TP=59
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 59
         True Negatives  (TN): 0
         False Positives (FP): 318
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8435
         Exactitud = (TP + TN) / N          = 0.1565
         Verificaci√≥n: 1 - Error            = 0.1565

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1565
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2706

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.04s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          24        35
      ==================================================
      TN=283  FP=35  FN=24  TP=35
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 35
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1565
         Exactitud = (TP + TN) / N          = 0.8435
         Verificaci√≥n: 1 - Error            = 0.8435

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5932
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5000
         Recall = TP / P (= TP-Rate)        = 0.5932

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5932
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5426

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          15        44
      ==================================================
      TN=283  FP=35  FN=15  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1326
         Exactitud = (TP + TN) / N          = 0.8674
         Verificaci√≥n: 1 - Error            = 0.8674

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7458
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5570
         Recall = TP / P (= TP-Rate)        = 0.7458

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7458
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6377

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       318
            Buggy           0        59
      ==================================================
      TN=0  FP=318  FN=0  TP=59
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 59
         True Negatives  (TN): 0
         False Positives (FP): 318
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8435
         Exactitud = (TP + TN) / N          = 0.1565
         Verificaci√≥n: 1 - Error            = 0.1565

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1565
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2706

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.04s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       63       255
            Buggy           7        52
      ==================================================
      TN=63  FP=255  FN=7  TP=52
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 52
         True Negatives  (TN): 63
         False Positives (FP): 255
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.6950
         Exactitud = (TP + TN) / N          = 0.3050
         Verificaci√≥n: 1 - Error            = 0.3050

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.8814
         FP-Rate = FP / N                   = 0.8019

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1694
         Recall = TP / P (= TP-Rate)        = 0.8814

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.8814
         Especificidad = TN / N             = 0.1981
         Verificaci√≥n: 1 - FP-Rate          = 0.1981

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2842

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 8, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          15        44
      ==================================================
      TN=283  FP=35  FN=15  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1326
         Exactitud = (TP + TN) / N          = 0.8674
         Verificaci√≥n: 1 - Error            = 0.8674

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7458
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5570
         Recall = TP / P (= TP-Rate)        = 0.7458

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7458
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6377

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      270        48
            Buggy          17        42
      ==================================================
      TN=270  FP=48  FN=17  TP=42
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 42
         True Negatives  (TN): 270
         False Positives (FP): 48
         False Negatives (FN): 17

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1724
         Exactitud = (TP + TN) / N          = 0.8276
         Verificaci√≥n: 1 - Error            = 0.8276

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7119
         FP-Rate = FP / N                   = 0.1509

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4667
         Recall = TP / P (= TP-Rate)        = 0.7119

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7119
         Especificidad = TN / N             = 0.8491
         Verificaci√≥n: 1 - FP-Rate          = 0.8491

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5638

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      287        31
            Buggy          26        33
      ==================================================
      TN=287  FP=31  FN=26  TP=33
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 33
         True Negatives  (TN): 287
         False Positives (FP): 31
         False Negatives (FN): 26

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1512
         Exactitud = (TP + TN) / N          = 0.8488
         Verificaci√≥n: 1 - Error            = 0.8488

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5593
         FP-Rate = FP / N                   = 0.0975

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5156
         Recall = TP / P (= TP-Rate)        = 0.5593

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5593
         Especificidad = TN / N             = 0.9025
         Verificaci√≥n: 1 - FP-Rate          = 0.9025

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5366

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      279        39
            Buggy          19        40
      ==================================================
      TN=279  FP=39  FN=19  TP=40
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 40
         True Negatives  (TN): 279
         False Positives (FP): 39
         False Negatives (FN): 19

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1538
         Exactitud = (TP + TN) / N          = 0.8462
         Verificaci√≥n: 1 - Error            = 0.8462

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6780
         FP-Rate = FP / N                   = 0.1226

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5063
         Recall = TP / P (= TP-Rate)        = 0.6780

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6780
         Especificidad = TN / N             = 0.8774
         Verificaci√≥n: 1 - FP-Rate          = 0.8774

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5797

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       318
            Buggy           3        56
      ==================================================
      TN=0  FP=318  FN=3  TP=56
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 56
         True Negatives  (TN): 0
         False Positives (FP): 318
         False Negatives (FN): 3

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8515
         Exactitud = (TP + TN) / N          = 0.1485
         Verificaci√≥n: 1 - Error            = 0.1485

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9492
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1497
         Recall = TP / P (= TP-Rate)        = 0.9492

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9492
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2587

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.04s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       318
            Buggy           2        57
      ==================================================
      TN=0  FP=318  FN=2  TP=57
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 57
         True Negatives  (TN): 0
         False Positives (FP): 318
         False Negatives (FN): 2

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8488
         Exactitud = (TP + TN) / N          = 0.1512
         Verificaci√≥n: 1 - Error            = 0.1512

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9661
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1520
         Recall = TP / P (= TP-Rate)        = 0.9661

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9661
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2627

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      278        40
            Buggy          19        40
      ==================================================
      TN=278  FP=40  FN=19  TP=40
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 40
         True Negatives  (TN): 278
         False Positives (FP): 40
         False Negatives (FN): 19

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1565
         Exactitud = (TP + TN) / N          = 0.8435
         Verificaci√≥n: 1 - Error            = 0.8435

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6780
         FP-Rate = FP / N                   = 0.1258

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5000
         Recall = TP / P (= TP-Rate)        = 0.6780

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6780
         Especificidad = TN / N             = 0.8742
         Verificaci√≥n: 1 - FP-Rate          = 0.8742

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5755

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       45       273
            Buggy           0        59
      ==================================================
      TN=45  FP=273  FN=0  TP=59
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 59
         True Negatives  (TN): 45
         False Positives (FP): 273
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.7241
         Exactitud = (TP + TN) / N          = 0.2759
         Verificaci√≥n: 1 - Error            = 0.2759

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 0.8585

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1777
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.1415
         Verificaci√≥n: 1 - FP-Rate          = 0.1415

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3018

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          24        35
      ==================================================
      TN=283  FP=35  FN=24  TP=35
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 35
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1565
         Exactitud = (TP + TN) / N          = 0.8435
         Verificaci√≥n: 1 - Error            = 0.8435

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5932
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5000
         Recall = TP / P (= TP-Rate)        = 0.5932

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5932
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5426

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      274        44
            Buggy          14        45
      ==================================================
      TN=274  FP=44  FN=14  TP=45
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 45
         True Negatives  (TN): 274
         False Positives (FP): 44
         False Negatives (FN): 14

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1538
         Exactitud = (TP + TN) / N          = 0.8462
         Verificaci√≥n: 1 - Error            = 0.8462

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7627
         FP-Rate = FP / N                   = 0.1384

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5056
         Recall = TP / P (= TP-Rate)        = 0.7627

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7627
         Especificidad = TN / N             = 0.8616
         Verificaci√≥n: 1 - FP-Rate          = 0.8616

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6081

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       51       267
            Buggy           0        59
      ==================================================
      TN=51  FP=267  FN=0  TP=59
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 59
         True Negatives  (TN): 51
         False Positives (FP): 267
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.7082
         Exactitud = (TP + TN) / N          = 0.2918
         Verificaci√≥n: 1 - Error            = 0.2918

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 0.8396

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1810
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.1604
         Verificaci√≥n: 1 - FP-Rate          = 0.1604

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3065

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.04s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      133       185
            Buggy           6        53
      ==================================================
      TN=133  FP=185  FN=6  TP=53
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 53
         True Negatives  (TN): 133
         False Positives (FP): 185
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.5066
         Exactitud = (TP + TN) / N          = 0.4934
         Verificaci√≥n: 1 - Error            = 0.4934

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.8983
         FP-Rate = FP / N                   = 0.5818

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2227
         Recall = TP / P (= TP-Rate)        = 0.8983

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.8983
         Especificidad = TN / N             = 0.4182
         Verificaci√≥n: 1 - FP-Rate          = 0.4182

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3569

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      274        44
            Buggy          14        45
      ==================================================
      TN=274  FP=44  FN=14  TP=45
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 45
         True Negatives  (TN): 274
         False Positives (FP): 44
         False Negatives (FN): 14

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1538
         Exactitud = (TP + TN) / N          = 0.8462
         Verificaci√≥n: 1 - Error            = 0.8462

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7627
         FP-Rate = FP / N                   = 0.1384

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5056
         Recall = TP / P (= TP-Rate)        = 0.7627

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7627
         Especificidad = TN / N             = 0.8616
         Verificaci√≥n: 1 - FP-Rate          = 0.8616

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6081

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


================================================================================
‚úì PIPELINE COMPLETO PARA activemq-5.0.0
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: derby-10.5.1.1 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: derby-10.5.1.1
[1] Preprocesamiento - Dimensiones originales: (2705, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (2705, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (2164, 66), X_test: (541, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con derby-10.5.1.1 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con derby-10.5.1.1 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 1858
    Clase Minoritaria (1): 306
    Total de clases: 2164
    Ratio de desbalance: 6.07

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 1082

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 776
[Minor√≠a] Tama√±o final (original + sint√©tico): 1082

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 2164
    Distribuci√≥n clases: {0: 1082, 1: 1082}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con derby-10.5.1.1 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 1858 muestras
    Clase minoritaria (1): 306 muestras
    Total de clases: 2164
    Ratio de desbalance: 6.07

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 1082

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 776
[Minoritaria] Tama√±o final (original + sint√©tico): 1082

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 2164
    Distribuci√≥n clases: {0: 1082, 1: 1082}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con derby-10.5.1.1 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  1858
     Clase minoritaria (1):  306
     Total de clases:  2164
     Indice de desbalance:  6.07

[SMOTE] Clase mayoritaria (0): 1858 -> 1082 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 1082, 1: 1082}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando derby-10.5.1.1 con standard
[3] [unbalanced] Escalando derby-10.5.1.1 con robust
[3] [csbboost] Escalando derby-10.5.1.1 con standard
[3] [csbboost] Escalando derby-10.5.1.1 con robust
[3] [hcbou] Escalando derby-10.5.1.1 con standard
[3] [hcbou] Escalando derby-10.5.1.1 con robust
[3] [smote] Escalando derby-10.5.1.1 con standard
[3] [smote] Escalando derby-10.5.1.1 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: derby-10.5.1.1
================================================================================

üìã Total de configuraciones a procesar: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado: ['standard', 'robust']
   ‚Ä¢ Modelos por config: 3

********************************************************************************
[1/8] PROCESANDO CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: derby-10.5.1.1 | unbalanced | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/derby-10.5.1.1/standard
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/derby-10.5.1.1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/derby-10.5.1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] PROCESANDO CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: derby-10.5.1.1 | unbalanced | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/derby-10.5.1.1/robust
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/derby-10.5.1.1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/derby-10.5.1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] PROCESANDO CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: derby-10.5.1.1 | csbboost | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/derby-10.5.1.1/standard
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/derby-10.5.1.1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/derby-10.5.1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] PROCESANDO CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: derby-10.5.1.1 | csbboost | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/derby-10.5.1.1/robust
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/derby-10.5.1.1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/derby-10.5.1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] PROCESANDO CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: derby-10.5.1.1 | hcbou | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/derby-10.5.1.1/standard
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/derby-10.5.1.1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/derby-10.5.1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] PROCESANDO CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: derby-10.5.1.1 | hcbou | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/derby-10.5.1.1/robust
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/derby-10.5.1.1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/derby-10.5.1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] PROCESANDO CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: derby-10.5.1.1 | smote | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/derby-10.5.1.1/standard
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/derby-10.5.1.1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/derby-10.5.1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] PROCESANDO CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: derby-10.5.1.1 | smote | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/derby-10.5.1.1/robust
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/derby-10.5.1.1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/derby-10.5.1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: derby-10.5.1.1
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: derby-10.5.1.1
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | unbalanced | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      364       100
            Buggy          43        34
      ==================================================
      TN=364  FP=100  FN=43  TP=34
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 34
         True Negatives  (TN): 364
         False Positives (FP): 100
         False Negatives (FN): 43

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2643
         Exactitud = (TP + TN) / N          = 0.7357
         Verificaci√≥n: 1 - Error            = 0.7357

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4416
         FP-Rate = FP / N                   = 0.2155

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2537
         Recall = TP / P (= TP-Rate)        = 0.4416

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4416
         Especificidad = TN / N             = 0.7845
         Verificaci√≥n: 1 - FP-Rate          = 0.7845

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3223

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.05s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      429        35
            Buggy          48        29
      ==================================================
      TN=429  FP=35  FN=48  TP=29
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 29
         True Negatives  (TN): 429
         False Positives (FP): 35
         False Negatives (FN): 48

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1534
         Exactitud = (TP + TN) / N          = 0.8466
         Verificaci√≥n: 1 - Error            = 0.8466

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3766
         FP-Rate = FP / N                   = 0.0754

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4531
         Recall = TP / P (= TP-Rate)        = 0.3766

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3766
         Especificidad = TN / N             = 0.9246
         Verificaci√≥n: 1 - FP-Rate          = 0.9246

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4113

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      420        44
            Buggy          46        31
      ==================================================
      TN=420  FP=44  FN=46  TP=31
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 31
         True Negatives  (TN): 420
         False Positives (FP): 44
         False Negatives (FN): 46

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1664
         Exactitud = (TP + TN) / N          = 0.8336
         Verificaci√≥n: 1 - Error            = 0.8336

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4026
         FP-Rate = FP / N                   = 0.0948

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4133
         Recall = TP / P (= TP-Rate)        = 0.4026

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4026
         Especificidad = TN / N             = 0.9052
         Verificaci√≥n: 1 - FP-Rate          = 0.9052

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4079

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | unbalanced | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      460         4
            Buggy          74         3
      ==================================================
      TN=460  FP=4  FN=74  TP=3
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 3
         True Negatives  (TN): 460
         False Positives (FP): 4
         False Negatives (FN): 74

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1442
         Exactitud = (TP + TN) / N          = 0.8558
         Verificaci√≥n: 1 - Error            = 0.8558

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0390
         FP-Rate = FP / N                   = 0.0086

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4286
         Recall = TP / P (= TP-Rate)        = 0.0390

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0390
         Especificidad = TN / N             = 0.9914
         Verificaci√≥n: 1 - FP-Rate          = 0.9914

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.0714

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      457         7
            Buggy          74         3
      ==================================================
      TN=457  FP=7  FN=74  TP=3
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 3
         True Negatives  (TN): 457
         False Positives (FP): 7
         False Negatives (FN): 74

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1497
         Exactitud = (TP + TN) / N          = 0.8503
         Verificaci√≥n: 1 - Error            = 0.8503

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0390
         FP-Rate = FP / N                   = 0.0151

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3000
         Recall = TP / P (= TP-Rate)        = 0.0390

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0390
         Especificidad = TN / N             = 0.9849
         Verificaci√≥n: 1 - FP-Rate          = 0.9849

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.0690

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      420        44
            Buggy          46        31
      ==================================================
      TN=420  FP=44  FN=46  TP=31
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 31
         True Negatives  (TN): 420
         False Positives (FP): 44
         False Negatives (FN): 46

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1664
         Exactitud = (TP + TN) / N          = 0.8336
         Verificaci√≥n: 1 - Error            = 0.8336

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4026
         FP-Rate = FP / N                   = 0.0948

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4133
         Recall = TP / P (= TP-Rate)        = 0.4026

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4026
         Especificidad = TN / N             = 0.9052
         Verificaci√≥n: 1 - FP-Rate          = 0.9052

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4079

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      401        63
            Buggy          51        26
      ==================================================
      TN=401  FP=63  FN=51  TP=26
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 26
         True Negatives  (TN): 401
         False Positives (FP): 63
         False Negatives (FN): 51

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2107
         Exactitud = (TP + TN) / N          = 0.7893
         Verificaci√≥n: 1 - Error            = 0.7893

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3377
         FP-Rate = FP / N                   = 0.1358

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2921
         Recall = TP / P (= TP-Rate)        = 0.3377

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3377
         Especificidad = TN / N             = 0.8642
         Verificaci√≥n: 1 - FP-Rate          = 0.8642

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3133

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.08s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      425        39
            Buggy          43        34
      ==================================================
      TN=425  FP=39  FN=43  TP=34
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 34
         True Negatives  (TN): 425
         False Positives (FP): 39
         False Negatives (FN): 43

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1516
         Exactitud = (TP + TN) / N          = 0.8484
         Verificaci√≥n: 1 - Error            = 0.8484

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4416
         FP-Rate = FP / N                   = 0.0841

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4658
         Recall = TP / P (= TP-Rate)        = 0.4416

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4416
         Especificidad = TN / N             = 0.9159
         Verificaci√≥n: 1 - FP-Rate          = 0.9159

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4533

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      368        96
            Buggy          31        46
      ==================================================
      TN=368  FP=96  FN=31  TP=46
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 46
         True Negatives  (TN): 368
         False Positives (FP): 96
         False Negatives (FN): 31

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2348
         Exactitud = (TP + TN) / N          = 0.7652
         Verificaci√≥n: 1 - Error            = 0.7652

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5974
         FP-Rate = FP / N                   = 0.2069

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3239
         Recall = TP / P (= TP-Rate)        = 0.5974

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5974
         Especificidad = TN / N             = 0.7931
         Verificaci√≥n: 1 - FP-Rate          = 0.7931

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4201

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.04s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      313       151
            Buggy          24        53
      ==================================================
      TN=313  FP=151  FN=24  TP=53
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 53
         True Negatives  (TN): 313
         False Positives (FP): 151
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.3235
         Exactitud = (TP + TN) / N          = 0.6765
         Verificaci√≥n: 1 - Error            = 0.6765

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6883
         FP-Rate = FP / N                   = 0.3254

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2598
         Recall = TP / P (= TP-Rate)        = 0.6883

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6883
         Especificidad = TN / N             = 0.6746
         Verificaci√≥n: 1 - FP-Rate          = 0.6746

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3772

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.09s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      459         5
            Buggy          75         2
      ==================================================
      TN=459  FP=5  FN=75  TP=2
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 2
         True Negatives  (TN): 459
         False Positives (FP): 5
         False Negatives (FN): 75

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1479
         Exactitud = (TP + TN) / N          = 0.8521
         Verificaci√≥n: 1 - Error            = 0.8521

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0260
         FP-Rate = FP / N                   = 0.0108

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2857
         Recall = TP / P (= TP-Rate)        = 0.0260

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0260
         Especificidad = TN / N             = 0.9892
         Verificaci√≥n: 1 - FP-Rate          = 0.9892

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.0476

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      368        96
            Buggy          31        46
      ==================================================
      TN=368  FP=96  FN=31  TP=46
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 46
         True Negatives  (TN): 368
         False Positives (FP): 96
         False Negatives (FN): 31

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2348
         Exactitud = (TP + TN) / N          = 0.7652
         Verificaci√≥n: 1 - Error            = 0.7652

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5974
         FP-Rate = FP / N                   = 0.2069

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3239
         Recall = TP / P (= TP-Rate)        = 0.5974

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5974
         Especificidad = TN / N             = 0.7931
         Verificaci√≥n: 1 - FP-Rate          = 0.7931

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4201

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.04s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      223       241
            Buggy           5        72
      ==================================================
      TN=223  FP=241  FN=5  TP=72
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 72
         True Negatives  (TN): 223
         False Positives (FP): 241
         False Negatives (FN): 5

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.4547
         Exactitud = (TP + TN) / N          = 0.5453
         Verificaci√≥n: 1 - Error            = 0.5453

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9351
         FP-Rate = FP / N                   = 0.5194

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2300
         Recall = TP / P (= TP-Rate)        = 0.9351

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9351
         Especificidad = TN / N             = 0.4806
         Verificaci√≥n: 1 - FP-Rate          = 0.4806

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3692

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.08s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      422        42
            Buggy          42        35
      ==================================================
      TN=422  FP=42  FN=42  TP=35
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 35
         True Negatives  (TN): 422
         False Positives (FP): 42
         False Negatives (FN): 42

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1553
         Exactitud = (TP + TN) / N          = 0.8447
         Verificaci√≥n: 1 - Error            = 0.8447

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4545
         FP-Rate = FP / N                   = 0.0905

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4545
         Recall = TP / P (= TP-Rate)        = 0.4545

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4545
         Especificidad = TN / N             = 0.9095
         Verificaci√≥n: 1 - FP-Rate          = 0.9095

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4545

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      322       142
            Buggy          18        59
      ==================================================
      TN=322  FP=142  FN=18  TP=59
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 59
         True Negatives  (TN): 322
         False Positives (FP): 142
         False Negatives (FN): 18

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2957
         Exactitud = (TP + TN) / N          = 0.7043
         Verificaci√≥n: 1 - Error            = 0.7043

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7662
         FP-Rate = FP / N                   = 0.3060

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2935
         Recall = TP / P (= TP-Rate)        = 0.7662

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7662
         Especificidad = TN / N             = 0.6940
         Verificaci√≥n: 1 - FP-Rate          = 0.6940

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4245

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      145       319
            Buggy           2        75
      ==================================================
      TN=145  FP=319  FN=2  TP=75
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 75
         True Negatives  (TN): 145
         False Positives (FP): 319
         False Negatives (FN): 2

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.5933
         Exactitud = (TP + TN) / N          = 0.4067
         Verificaci√≥n: 1 - Error            = 0.4067

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9740
         FP-Rate = FP / N                   = 0.6875

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1904
         Recall = TP / P (= TP-Rate)        = 0.9740

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9740
         Especificidad = TN / N             = 0.3125
         Verificaci√≥n: 1 - FP-Rate          = 0.3125

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3185

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.09s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      460         4
            Buggy          74         3
      ==================================================
      TN=460  FP=4  FN=74  TP=3
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 3
         True Negatives  (TN): 460
         False Positives (FP): 4
         False Negatives (FN): 74

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1442
         Exactitud = (TP + TN) / N          = 0.8558
         Verificaci√≥n: 1 - Error            = 0.8558

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0390
         FP-Rate = FP / N                   = 0.0086

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4286
         Recall = TP / P (= TP-Rate)        = 0.0390

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0390
         Especificidad = TN / N             = 0.9914
         Verificaci√≥n: 1 - FP-Rate          = 0.9914

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.0714

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      356       108
            Buggy          24        53
      ==================================================
      TN=356  FP=108  FN=24  TP=53
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 53
         True Negatives  (TN): 356
         False Positives (FP): 108
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2440
         Exactitud = (TP + TN) / N          = 0.7560
         Verificaci√≥n: 1 - Error            = 0.7560

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6883
         FP-Rate = FP / N                   = 0.2328

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3292
         Recall = TP / P (= TP-Rate)        = 0.6883

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6883
         Especificidad = TN / N             = 0.7672
         Verificaci√≥n: 1 - FP-Rate          = 0.7672

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4454

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      409        55
            Buggy          52        25
      ==================================================
      TN=409  FP=55  FN=52  TP=25
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 25
         True Negatives  (TN): 409
         False Positives (FP): 55
         False Negatives (FN): 52

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1978
         Exactitud = (TP + TN) / N          = 0.8022
         Verificaci√≥n: 1 - Error            = 0.8022

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3247
         FP-Rate = FP / N                   = 0.1185

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3125
         Recall = TP / P (= TP-Rate)        = 0.3247

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3247
         Especificidad = TN / N             = 0.8815
         Verificaci√≥n: 1 - FP-Rate          = 0.8815

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3185

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.09s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      421        43
            Buggy          43        34
      ==================================================
      TN=421  FP=43  FN=43  TP=34
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 34
         True Negatives  (TN): 421
         False Positives (FP): 43
         False Negatives (FN): 43

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1590
         Exactitud = (TP + TN) / N          = 0.8410
         Verificaci√≥n: 1 - Error            = 0.8410

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4416
         FP-Rate = FP / N                   = 0.0927

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4416
         Recall = TP / P (= TP-Rate)        = 0.4416

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4416
         Especificidad = TN / N             = 0.9073
         Verificaci√≥n: 1 - FP-Rate          = 0.9073

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4416

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      360       104
            Buggy          36        41
      ==================================================
      TN=360  FP=104  FN=36  TP=41
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 41
         True Negatives  (TN): 360
         False Positives (FP): 104
         False Negatives (FN): 36

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2588
         Exactitud = (TP + TN) / N          = 0.7412
         Verificaci√≥n: 1 - Error            = 0.7412

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5325
         FP-Rate = FP / N                   = 0.2241

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2828
         Recall = TP / P (= TP-Rate)        = 0.5325

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5325
         Especificidad = TN / N             = 0.7759
         Verificaci√≥n: 1 - FP-Rate          = 0.7759

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3694

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      304       160
            Buggy          20        57
      ==================================================
      TN=304  FP=160  FN=20  TP=57
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 57
         True Negatives  (TN): 304
         False Positives (FP): 160
         False Negatives (FN): 20

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.3327
         Exactitud = (TP + TN) / N          = 0.6673
         Verificaci√≥n: 1 - Error            = 0.6673

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7403
         FP-Rate = FP / N                   = 0.3448

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2627
         Recall = TP / P (= TP-Rate)        = 0.7403

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7403
         Especificidad = TN / N             = 0.6552
         Verificaci√≥n: 1 - FP-Rate          = 0.6552

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3878

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.09s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      457         7
            Buggy          73         4
      ==================================================
      TN=457  FP=7  FN=73  TP=4
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 4
         True Negatives  (TN): 457
         False Positives (FP): 7
         False Negatives (FN): 73

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1479
         Exactitud = (TP + TN) / N          = 0.8521
         Verificaci√≥n: 1 - Error            = 0.8521

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0519
         FP-Rate = FP / N                   = 0.0151

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3636
         Recall = TP / P (= TP-Rate)        = 0.0519

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0519
         Especificidad = TN / N             = 0.9849
         Verificaci√≥n: 1 - FP-Rate          = 0.9849

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.0909

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      373        91
            Buggy          33        44
      ==================================================
      TN=373  FP=91  FN=33  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 373
         False Positives (FP): 91
         False Negatives (FN): 33

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2292
         Exactitud = (TP + TN) / N          = 0.7708
         Verificaci√≥n: 1 - Error            = 0.7708

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5714
         FP-Rate = FP / N                   = 0.1961

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3259
         Recall = TP / P (= TP-Rate)        = 0.5714

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5714
         Especificidad = TN / N             = 0.8039
         Verificaci√≥n: 1 - FP-Rate          = 0.8039

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4151

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


================================================================================
‚úì PIPELINE COMPLETO PARA derby-10.5.1.1
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: groovy-1_6_BETA_1 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: groovy-1_6_BETA_1
[1] Preprocesamiento - Dimensiones originales: (821, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (821, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (656, 66), X_test: (165, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con groovy-1_6_BETA_1 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con groovy-1_6_BETA_1 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 600
    Clase Minoritaria (1): 56
    Total de clases: 656
    Ratio de desbalance: 10.71

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 328

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 272
[Minor√≠a] Tama√±o final (original + sint√©tico): 328

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 656
    Distribuci√≥n clases: {0: 328, 1: 328}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con groovy-1_6_BETA_1 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 600 muestras
    Clase minoritaria (1): 56 muestras
    Total de clases: 656
    Ratio de desbalance: 10.71

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 328

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 272
[Minoritaria] Tama√±o final (original + sint√©tico): 328

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 656
    Distribuci√≥n clases: {0: 328, 1: 328}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con groovy-1_6_BETA_1 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  600
     Clase minoritaria (1):  56
     Total de clases:  656
     Indice de desbalance:  10.71

[SMOTE] Clase mayoritaria (0): 600 -> 328 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 328, 1: 328}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando groovy-1_6_BETA_1 con standard
[3] [unbalanced] Escalando groovy-1_6_BETA_1 con robust
[3] [csbboost] Escalando groovy-1_6_BETA_1 con standard
[3] [csbboost] Escalando groovy-1_6_BETA_1 con robust
[3] [hcbou] Escalando groovy-1_6_BETA_1 con standard
[3] [hcbou] Escalando groovy-1_6_BETA_1 con robust
[3] [smote] Escalando groovy-1_6_BETA_1 con standard
[3] [smote] Escalando groovy-1_6_BETA_1 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: groovy-1_6_BETA_1
================================================================================

üìã Total de configuraciones a procesar: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado: ['standard', 'robust']
   ‚Ä¢ Modelos por config: 3

********************************************************************************
[1/8] PROCESANDO CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: groovy-1_6_BETA_1 | unbalanced | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/groovy-1_6_BETA_1/standard
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/groovy-1_6_BETA_1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/groovy-1_6_BETA_1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] PROCESANDO CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: groovy-1_6_BETA_1 | unbalanced | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/groovy-1_6_BETA_1/robust
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/groovy-1_6_BETA_1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/groovy-1_6_BETA_1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] PROCESANDO CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: groovy-1_6_BETA_1 | csbboost | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/groovy-1_6_BETA_1/standard
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/groovy-1_6_BETA_1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/groovy-1_6_BETA_1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] PROCESANDO CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: groovy-1_6_BETA_1 | csbboost | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/groovy-1_6_BETA_1/robust
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/groovy-1_6_BETA_1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/groovy-1_6_BETA_1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] PROCESANDO CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: groovy-1_6_BETA_1 | hcbou | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/groovy-1_6_BETA_1/standard
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/groovy-1_6_BETA_1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/groovy-1_6_BETA_1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] PROCESANDO CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: groovy-1_6_BETA_1 | hcbou | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/groovy-1_6_BETA_1/robust
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/groovy-1_6_BETA_1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/groovy-1_6_BETA_1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] PROCESANDO CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: groovy-1_6_BETA_1 | smote | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/groovy-1_6_BETA_1/standard
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/groovy-1_6_BETA_1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/groovy-1_6_BETA_1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] PROCESANDO CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: groovy-1_6_BETA_1 | smote | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/groovy-1_6_BETA_1/robust
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/groovy-1_6_BETA_1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/groovy-1_6_BETA_1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: groovy-1_6_BETA_1
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: groovy-1_6_BETA_1
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | unbalanced | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       59        92
            Buggy           8         6
      ==================================================
      TN=59  FP=92  FN=8  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 59
         False Positives (FP): 92
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.6061
         Exactitud = (TP + TN) / N          = 0.3939
         Verificaci√≥n: 1 - Error            = 0.3939

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4286
         FP-Rate = FP / N                   = 0.6093

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0612
         Recall = TP / P (= TP-Rate)        = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4286
         Especificidad = TN / N             = 0.3907
         Verificaci√≥n: 1 - FP-Rate          = 0.3907

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1071

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      140        11
            Buggy          10         4
      ==================================================
      TN=140  FP=11  FN=10  TP=4
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 4
         True Negatives  (TN): 140
         False Positives (FP): 11
         False Negatives (FN): 10

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1273
         Exactitud = (TP + TN) / N          = 0.8727
         Verificaci√≥n: 1 - Error            = 0.8727

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2857
         FP-Rate = FP / N                   = 0.0728

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2667
         Recall = TP / P (= TP-Rate)        = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2857
         Especificidad = TN / N             = 0.9272
         Verificaci√≥n: 1 - FP-Rate          = 0.9272

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2759

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      142         9
            Buggy          10         4
      ==================================================
      TN=142  FP=9  FN=10  TP=4
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 4
         True Negatives  (TN): 142
         False Positives (FP): 9
         False Negatives (FN): 10

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1152
         Exactitud = (TP + TN) / N          = 0.8848
         Verificaci√≥n: 1 - Error            = 0.8848

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2857
         FP-Rate = FP / N                   = 0.0596

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3077
         Recall = TP / P (= TP-Rate)        = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2857
         Especificidad = TN / N             = 0.9404
         Verificaci√≥n: 1 - FP-Rate          = 0.9404

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2963

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | unbalanced | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      147         4
            Buggy          11         3
      ==================================================
      TN=147  FP=4  FN=11  TP=3
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 3
         True Negatives  (TN): 147
         False Positives (FP): 4
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0909
         Exactitud = (TP + TN) / N          = 0.9091
         Verificaci√≥n: 1 - Error            = 0.9091

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2143
         FP-Rate = FP / N                   = 0.0265

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4286
         Recall = TP / P (= TP-Rate)        = 0.2143

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2143
         Especificidad = TN / N             = 0.9735
         Verificaci√≥n: 1 - FP-Rate          = 0.9735

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2857

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       151
            Buggy           1        13
      ==================================================
      TN=0  FP=151  FN=1  TP=13
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 13
         True Negatives  (TN): 0
         False Positives (FP): 151
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.9212
         Exactitud = (TP + TN) / N          = 0.0788
         Verificaci√≥n: 1 - Error            = 0.0788

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9286
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0793
         Recall = TP / P (= TP-Rate)        = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9286
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1461

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      142         9
            Buggy          10         4
      ==================================================
      TN=142  FP=9  FN=10  TP=4
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 4
         True Negatives  (TN): 142
         False Positives (FP): 9
         False Negatives (FN): 10

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1152
         Exactitud = (TP + TN) / N          = 0.8848
         Verificaci√≥n: 1 - Error            = 0.8848

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2857
         FP-Rate = FP / N                   = 0.0596

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3077
         Recall = TP / P (= TP-Rate)        = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2857
         Especificidad = TN / N             = 0.9404
         Verificaci√≥n: 1 - FP-Rate          = 0.9404

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2963

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      139        12
            Buggy          10         4
      ==================================================
      TN=139  FP=12  FN=10  TP=4
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 4
         True Negatives  (TN): 139
         False Positives (FP): 12
         False Negatives (FN): 10

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1333
         Exactitud = (TP + TN) / N          = 0.8667
         Verificaci√≥n: 1 - Error            = 0.8667

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2857
         FP-Rate = FP / N                   = 0.0795

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2500
         Recall = TP / P (= TP-Rate)        = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2857
         Especificidad = TN / N             = 0.9205
         Verificaci√≥n: 1 - FP-Rate          = 0.9205

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2667

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      140        11
            Buggy          10         4
      ==================================================
      TN=140  FP=11  FN=10  TP=4
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 4
         True Negatives  (TN): 140
         False Positives (FP): 11
         False Negatives (FN): 10

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1273
         Exactitud = (TP + TN) / N          = 0.8727
         Verificaci√≥n: 1 - Error            = 0.8727

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2857
         FP-Rate = FP / N                   = 0.0728

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2667
         Recall = TP / P (= TP-Rate)        = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2857
         Especificidad = TN / N             = 0.9272
         Verificaci√≥n: 1 - FP-Rate          = 0.9272

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2759

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      118        33
            Buggy           4        10
      ==================================================
      TN=118  FP=33  FN=4  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 118
         False Positives (FP): 33
         False Negatives (FN): 4

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2242
         Exactitud = (TP + TN) / N          = 0.7758
         Verificaci√≥n: 1 - Error            = 0.7758

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7143
         FP-Rate = FP / N                   = 0.2185

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2326
         Recall = TP / P (= TP-Rate)        = 0.7143

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7143
         Especificidad = TN / N             = 0.7815
         Verificaci√≥n: 1 - FP-Rate          = 0.7815

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3509

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      144         7
            Buggy          10         4
      ==================================================
      TN=144  FP=7  FN=10  TP=4
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 4
         True Negatives  (TN): 144
         False Positives (FP): 7
         False Negatives (FN): 10

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1030
         Exactitud = (TP + TN) / N          = 0.8970
         Verificaci√≥n: 1 - Error            = 0.8970

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2857
         FP-Rate = FP / N                   = 0.0464

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3636
         Recall = TP / P (= TP-Rate)        = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2857
         Especificidad = TN / N             = 0.9536
         Verificaci√≥n: 1 - FP-Rate          = 0.9536

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3200

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       151
            Buggy           1        13
      ==================================================
      TN=0  FP=151  FN=1  TP=13
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 13
         True Negatives  (TN): 0
         False Positives (FP): 151
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.9212
         Exactitud = (TP + TN) / N          = 0.0788
         Verificaci√≥n: 1 - Error            = 0.0788

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9286
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0793
         Recall = TP / P (= TP-Rate)        = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9286
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1461

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      118        33
            Buggy           4        10
      ==================================================
      TN=118  FP=33  FN=4  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 118
         False Positives (FP): 33
         False Negatives (FN): 4

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2242
         Exactitud = (TP + TN) / N          = 0.7758
         Verificaci√≥n: 1 - Error            = 0.7758

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7143
         FP-Rate = FP / N                   = 0.2185

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2326
         Recall = TP / P (= TP-Rate)        = 0.7143

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7143
         Especificidad = TN / N             = 0.7815
         Verificaci√≥n: 1 - FP-Rate          = 0.7815

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3509

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      136        15
            Buggy           7         7
      ==================================================
      TN=136  FP=15  FN=7  TP=7
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 7
         True Negatives  (TN): 136
         False Positives (FP): 15
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1333
         Exactitud = (TP + TN) / N          = 0.8667
         Verificaci√≥n: 1 - Error            = 0.8667

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5000
         FP-Rate = FP / N                   = 0.0993

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3182
         Recall = TP / P (= TP-Rate)        = 0.5000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5000
         Especificidad = TN / N             = 0.9007
         Verificaci√≥n: 1 - FP-Rate          = 0.9007

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3889

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       93        58
            Buggy           4        10
      ==================================================
      TN=93  FP=58  FN=4  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 93
         False Positives (FP): 58
         False Negatives (FN): 4

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.3758
         Exactitud = (TP + TN) / N          = 0.6242
         Verificaci√≥n: 1 - Error            = 0.6242

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7143
         FP-Rate = FP / N                   = 0.3841

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1471
         Recall = TP / P (= TP-Rate)        = 0.7143

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7143
         Especificidad = TN / N             = 0.6159
         Verificaci√≥n: 1 - FP-Rate          = 0.6159

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2439

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      128        23
            Buggy           5         9
      ==================================================
      TN=128  FP=23  FN=5  TP=9
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 9
         True Negatives  (TN): 128
         False Positives (FP): 23
         False Negatives (FN): 5

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1697
         Exactitud = (TP + TN) / N          = 0.8303
         Verificaci√≥n: 1 - Error            = 0.8303

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6429
         FP-Rate = FP / N                   = 0.1523

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2812
         Recall = TP / P (= TP-Rate)        = 0.6429

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6429
         Especificidad = TN / N             = 0.8477
         Verificaci√≥n: 1 - FP-Rate          = 0.8477

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3913

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       151
            Buggy           0        14
      ==================================================
      TN=0  FP=151  FN=0  TP=14
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 14
         True Negatives  (TN): 0
         False Positives (FP): 151
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.9152
         Exactitud = (TP + TN) / N          = 0.0848
         Verificaci√≥n: 1 - Error            = 0.0848

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0848
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1564

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       151
            Buggy           1        13
      ==================================================
      TN=0  FP=151  FN=1  TP=13
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 13
         True Negatives  (TN): 0
         False Positives (FP): 151
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.9212
         Exactitud = (TP + TN) / N          = 0.0788
         Verificaci√≥n: 1 - Error            = 0.0788

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9286
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0793
         Recall = TP / P (= TP-Rate)        = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9286
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1461

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      128        23
            Buggy           5         9
      ==================================================
      TN=128  FP=23  FN=5  TP=9
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 9
         True Negatives  (TN): 128
         False Positives (FP): 23
         False Negatives (FN): 5

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1697
         Exactitud = (TP + TN) / N          = 0.8303
         Verificaci√≥n: 1 - Error            = 0.8303

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6429
         FP-Rate = FP / N                   = 0.1523

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2812
         Recall = TP / P (= TP-Rate)        = 0.6429

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6429
         Especificidad = TN / N             = 0.8477
         Verificaci√≥n: 1 - FP-Rate          = 0.8477

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3913

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      141        10
            Buggy           8         6
      ==================================================
      TN=141  FP=10  FN=8  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 141
         False Positives (FP): 10
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1091
         Exactitud = (TP + TN) / N          = 0.8909
         Verificaci√≥n: 1 - Error            = 0.8909

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4286
         FP-Rate = FP / N                   = 0.0662

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3750
         Recall = TP / P (= TP-Rate)        = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4286
         Especificidad = TN / N             = 0.9338
         Verificaci√≥n: 1 - FP-Rate          = 0.9338

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4000

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      132        19
            Buggy           9         5
      ==================================================
      TN=132  FP=19  FN=9  TP=5
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 5
         True Negatives  (TN): 132
         False Positives (FP): 19
         False Negatives (FN): 9

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1697
         Exactitud = (TP + TN) / N          = 0.8303
         Verificaci√≥n: 1 - Error            = 0.8303

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3571
         FP-Rate = FP / N                   = 0.1258

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2083
         Recall = TP / P (= TP-Rate)        = 0.3571

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3571
         Especificidad = TN / N             = 0.8742
         Verificaci√≥n: 1 - FP-Rate          = 0.8742

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2632

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      140        11
            Buggy           8         6
      ==================================================
      TN=140  FP=11  FN=8  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 140
         False Positives (FP): 11
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1152
         Exactitud = (TP + TN) / N          = 0.8848
         Verificaci√≥n: 1 - Error            = 0.8848

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4286
         FP-Rate = FP / N                   = 0.0728

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3529
         Recall = TP / P (= TP-Rate)        = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4286
         Especificidad = TN / N             = 0.9272
         Verificaci√≥n: 1 - FP-Rate          = 0.9272

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3871

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       75        76
            Buggy           3        11
      ==================================================
      TN=75  FP=76  FN=3  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 75
         False Positives (FP): 76
         False Negatives (FN): 3

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.4788
         Exactitud = (TP + TN) / N          = 0.5212
         Verificaci√≥n: 1 - Error            = 0.5212

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7857
         FP-Rate = FP / N                   = 0.5033

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1264
         Recall = TP / P (= TP-Rate)        = 0.7857

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7857
         Especificidad = TN / N             = 0.4967
         Verificaci√≥n: 1 - FP-Rate          = 0.4967

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2178

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       151
            Buggy           1        13
      ==================================================
      TN=0  FP=151  FN=1  TP=13
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 13
         True Negatives  (TN): 0
         False Positives (FP): 151
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.9212
         Exactitud = (TP + TN) / N          = 0.0788
         Verificaci√≥n: 1 - Error            = 0.0788

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9286
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0793
         Recall = TP / P (= TP-Rate)        = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9286
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1461

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      140        11
            Buggy           8         6
      ==================================================
      TN=140  FP=11  FN=8  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 140
         False Positives (FP): 11
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1152
         Exactitud = (TP + TN) / N          = 0.8848
         Verificaci√≥n: 1 - Error            = 0.8848

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4286
         FP-Rate = FP / N                   = 0.0728

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3529
         Recall = TP / P (= TP-Rate)        = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4286
         Especificidad = TN / N             = 0.9272
         Verificaci√≥n: 1 - FP-Rate          = 0.9272

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3871

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


================================================================================
‚úì PIPELINE COMPLETO PARA groovy-1_6_BETA_1
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: hbase-0.94.0 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: hbase-0.94.0
[1] Preprocesamiento - Dimensiones originales: (1059, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1059, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (847, 66), X_test: (212, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con hbase-0.94.0 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con hbase-0.94.0 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 673
    Clase Minoritaria (1): 174
    Total de clases: 847
    Ratio de desbalance: 3.87

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 424

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 248
[Minor√≠a] Tama√±o final (original + sint√©tico): 422

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 846
    Distribuci√≥n clases: {0: 424, 1: 422}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con hbase-0.94.0 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 673 muestras
    Clase minoritaria (1): 174 muestras
    Total de clases: 847
    Ratio de desbalance: 3.87

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 423

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 249
[Minoritaria] Tama√±o final (original + sint√©tico): 423

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 846
    Distribuci√≥n clases: {0: 423, 1: 423}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con hbase-0.94.0 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  673
     Clase minoritaria (1):  174
     Total de clases:  847
     Indice de desbalance:  3.87

[SMOTE] Clase mayoritaria (0): 673 -> 423 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 423, 1: 423}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando hbase-0.94.0 con standard
[3] [unbalanced] Escalando hbase-0.94.0 con robust
[3] [csbboost] Escalando hbase-0.94.0 con standard
[3] [csbboost] Escalando hbase-0.94.0 con robust
[3] [hcbou] Escalando hbase-0.94.0 con standard
[3] [hcbou] Escalando hbase-0.94.0 con robust
[3] [smote] Escalando hbase-0.94.0 con standard
[3] [smote] Escalando hbase-0.94.0 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: hbase-0.94.0
================================================================================

üìã Total de configuraciones a procesar: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado: ['standard', 'robust']
   ‚Ä¢ Modelos por config: 3

********************************************************************************
[1/8] PROCESANDO CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hbase-0.94.0 | unbalanced | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/hbase-0.94.0/standard
       ‚úì Datos cargados: X_train=(847, 65), X_test=(212, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hbase-0.94.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hbase-0.94.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] PROCESANDO CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hbase-0.94.0 | unbalanced | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/hbase-0.94.0/robust
       ‚úì Datos cargados: X_train=(847, 65), X_test=(212, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hbase-0.94.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hbase-0.94.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] PROCESANDO CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hbase-0.94.0 | csbboost | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/hbase-0.94.0/standard
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hbase-0.94.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hbase-0.94.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] PROCESANDO CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hbase-0.94.0 | csbboost | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/hbase-0.94.0/robust
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hbase-0.94.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hbase-0.94.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] PROCESANDO CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hbase-0.94.0 | hcbou | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/hbase-0.94.0/standard
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hbase-0.94.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hbase-0.94.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] PROCESANDO CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hbase-0.94.0 | hcbou | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/hbase-0.94.0/robust
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hbase-0.94.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hbase-0.94.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] PROCESANDO CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hbase-0.94.0 | smote | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/hbase-0.94.0/standard
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hbase-0.94.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hbase-0.94.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] PROCESANDO CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hbase-0.94.0 | smote | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/hbase-0.94.0/robust
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hbase-0.94.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hbase-0.94.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: hbase-0.94.0
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: hbase-0.94.0
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | unbalanced | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      146        22
            Buggy          28        16
      ==================================================
      TN=146  FP=22  FN=28  TP=16
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 16
         True Negatives  (TN): 146
         False Positives (FP): 22
         False Negatives (FN): 28

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2358
         Exactitud = (TP + TN) / N          = 0.7642
         Verificaci√≥n: 1 - Error            = 0.7642

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3636
         FP-Rate = FP / N                   = 0.1310

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4211
         Recall = TP / P (= TP-Rate)        = 0.3636

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3636
         Especificidad = TN / N             = 0.8690
         Verificaci√≥n: 1 - FP-Rate          = 0.8690

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3902

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      137        31
            Buggy          19        25
      ==================================================
      TN=137  FP=31  FN=19  TP=25
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 25
         True Negatives  (TN): 137
         False Positives (FP): 31
         False Negatives (FN): 19

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2358
         Exactitud = (TP + TN) / N          = 0.7642
         Verificaci√≥n: 1 - Error            = 0.7642

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5682
         FP-Rate = FP / N                   = 0.1845

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4464
         Recall = TP / P (= TP-Rate)        = 0.5682

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5682
         Especificidad = TN / N             = 0.8155
         Verificaci√≥n: 1 - FP-Rate          = 0.8155

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5000

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      155        13
            Buggy          22        22
      ==================================================
      TN=155  FP=13  FN=22  TP=22
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 22
         True Negatives  (TN): 155
         False Positives (FP): 13
         False Negatives (FN): 22

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1651
         Exactitud = (TP + TN) / N          = 0.8349
         Verificaci√≥n: 1 - Error            = 0.8349

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5000
         FP-Rate = FP / N                   = 0.0774

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6286
         Recall = TP / P (= TP-Rate)        = 0.5000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5000
         Especificidad = TN / N             = 0.9226
         Verificaci√≥n: 1 - FP-Rate          = 0.9226

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5570

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | unbalanced | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       168
            Buggy           0        44
      ==================================================
      TN=0  FP=168  FN=0  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 0
         False Positives (FP): 168
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.7925
         Exactitud = (TP + TN) / N          = 0.2075
         Verificaci√≥n: 1 - Error            = 0.2075

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2075
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3438

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        1       167
            Buggy           0        44
      ==================================================
      TN=1  FP=167  FN=0  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 1
         False Positives (FP): 167
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.7877
         Exactitud = (TP + TN) / N          = 0.2123
         Verificaci√≥n: 1 - Error            = 0.2123

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 0.9940

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2085
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0060
         Verificaci√≥n: 1 - FP-Rate          = 0.0060

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3451

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      155        13
            Buggy          22        22
      ==================================================
      TN=155  FP=13  FN=22  TP=22
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 22
         True Negatives  (TN): 155
         False Positives (FP): 13
         False Negatives (FN): 22

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1651
         Exactitud = (TP + TN) / N          = 0.8349
         Verificaci√≥n: 1 - Error            = 0.8349

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5000
         FP-Rate = FP / N                   = 0.0774

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6286
         Recall = TP / P (= TP-Rate)        = 0.5000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5000
         Especificidad = TN / N             = 0.9226
         Verificaci√≥n: 1 - FP-Rate          = 0.9226

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5570

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       78        90
            Buggy           7        37
      ==================================================
      TN=78  FP=90  FN=7  TP=37
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 37
         True Negatives  (TN): 78
         False Positives (FP): 90
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.4575
         Exactitud = (TP + TN) / N          = 0.5425
         Verificaci√≥n: 1 - Error            = 0.5425

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.8409
         FP-Rate = FP / N                   = 0.5357

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2913
         Recall = TP / P (= TP-Rate)        = 0.8409

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.8409
         Especificidad = TN / N             = 0.4643
         Verificaci√≥n: 1 - FP-Rate          = 0.4643

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4327

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      136        32
            Buggy          23        21
      ==================================================
      TN=136  FP=32  FN=23  TP=21
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 21
         True Negatives  (TN): 136
         False Positives (FP): 32
         False Negatives (FN): 23

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2594
         Exactitud = (TP + TN) / N          = 0.7406
         Verificaci√≥n: 1 - Error            = 0.7406

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4773
         FP-Rate = FP / N                   = 0.1905

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3962
         Recall = TP / P (= TP-Rate)        = 0.4773

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4773
         Especificidad = TN / N             = 0.8095
         Verificaci√≥n: 1 - FP-Rate          = 0.8095

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4330

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      147        21
            Buggy          18        26
      ==================================================
      TN=147  FP=21  FN=18  TP=26
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 26
         True Negatives  (TN): 147
         False Positives (FP): 21
         False Negatives (FN): 18

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1840
         Exactitud = (TP + TN) / N          = 0.8160
         Verificaci√≥n: 1 - Error            = 0.8160

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5909
         FP-Rate = FP / N                   = 0.1250

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5532
         Recall = TP / P (= TP-Rate)        = 0.5909

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5909
         Especificidad = TN / N             = 0.8750
         Verificaci√≥n: 1 - FP-Rate          = 0.8750

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5714

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       32       136
            Buggy           2        42
      ==================================================
      TN=32  FP=136  FN=2  TP=42
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 42
         True Negatives  (TN): 32
         False Positives (FP): 136
         False Negatives (FN): 2

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.6509
         Exactitud = (TP + TN) / N          = 0.3491
         Verificaci√≥n: 1 - Error            = 0.3491

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9545
         FP-Rate = FP / N                   = 0.8095

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2360
         Recall = TP / P (= TP-Rate)        = 0.9545

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9545
         Especificidad = TN / N             = 0.1905
         Verificaci√≥n: 1 - FP-Rate          = 0.1905

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3784

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        2       166
            Buggy           1        43
      ==================================================
      TN=2  FP=166  FN=1  TP=43
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 43
         True Negatives  (TN): 2
         False Positives (FP): 166
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.7877
         Exactitud = (TP + TN) / N          = 0.2123
         Verificaci√≥n: 1 - Error            = 0.2123

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9773
         FP-Rate = FP / N                   = 0.9881

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2057
         Recall = TP / P (= TP-Rate)        = 0.9773

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9773
         Especificidad = TN / N             = 0.0119
         Verificaci√≥n: 1 - FP-Rate          = 0.0119

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3399

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      148        20
            Buggy          18        26
      ==================================================
      TN=148  FP=20  FN=18  TP=26
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 26
         True Negatives  (TN): 148
         False Positives (FP): 20
         False Negatives (FN): 18

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1792
         Exactitud = (TP + TN) / N          = 0.8208
         Verificaci√≥n: 1 - Error            = 0.8208

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5909
         FP-Rate = FP / N                   = 0.1190

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5652
         Recall = TP / P (= TP-Rate)        = 0.5909

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5909
         Especificidad = TN / N             = 0.8810
         Verificaci√≥n: 1 - FP-Rate          = 0.8810

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5778

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       62       106
            Buggy           7        37
      ==================================================
      TN=62  FP=106  FN=7  TP=37
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 37
         True Negatives  (TN): 62
         False Positives (FP): 106
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.5330
         Exactitud = (TP + TN) / N          = 0.4670
         Verificaci√≥n: 1 - Error            = 0.4670

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.8409
         FP-Rate = FP / N                   = 0.6310

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2587
         Recall = TP / P (= TP-Rate)        = 0.8409

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.8409
         Especificidad = TN / N             = 0.3690
         Verificaci√≥n: 1 - FP-Rate          = 0.3690

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3957

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      130        38
            Buggy          12        32
      ==================================================
      TN=130  FP=38  FN=12  TP=32
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 32
         True Negatives  (TN): 130
         False Positives (FP): 38
         False Negatives (FN): 12

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2358
         Exactitud = (TP + TN) / N          = 0.7642
         Verificaci√≥n: 1 - Error            = 0.7642

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7273
         FP-Rate = FP / N                   = 0.2262

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4571
         Recall = TP / P (= TP-Rate)        = 0.7273

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7273
         Especificidad = TN / N             = 0.7738
         Verificaci√≥n: 1 - FP-Rate          = 0.7738

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5614

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      140        28
            Buggy          12        32
      ==================================================
      TN=140  FP=28  FN=12  TP=32
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 32
         True Negatives  (TN): 140
         False Positives (FP): 28
         False Negatives (FN): 12

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1887
         Exactitud = (TP + TN) / N          = 0.8113
         Verificaci√≥n: 1 - Error            = 0.8113

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7273
         FP-Rate = FP / N                   = 0.1667

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5333
         Recall = TP / P (= TP-Rate)        = 0.7273

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7273
         Especificidad = TN / N             = 0.8333
         Verificaci√≥n: 1 - FP-Rate          = 0.8333

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6154

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       37       131
            Buggy           3        41
      ==================================================
      TN=37  FP=131  FN=3  TP=41
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 41
         True Negatives  (TN): 37
         False Positives (FP): 131
         False Negatives (FN): 3

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.6321
         Exactitud = (TP + TN) / N          = 0.3679
         Verificaci√≥n: 1 - Error            = 0.3679

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9318
         FP-Rate = FP / N                   = 0.7798

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2384
         Recall = TP / P (= TP-Rate)        = 0.9318

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9318
         Especificidad = TN / N             = 0.2202
         Verificaci√≥n: 1 - FP-Rate          = 0.2202

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3796

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        1       167
            Buggy           0        44
      ==================================================
      TN=1  FP=167  FN=0  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 1
         False Positives (FP): 167
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.7877
         Exactitud = (TP + TN) / N          = 0.2123
         Verificaci√≥n: 1 - Error            = 0.2123

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 0.9940

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2085
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0060
         Verificaci√≥n: 1 - FP-Rate          = 0.0060

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3451

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      140        28
            Buggy          12        32
      ==================================================
      TN=140  FP=28  FN=12  TP=32
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 32
         True Negatives  (TN): 140
         False Positives (FP): 28
         False Negatives (FN): 12

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1887
         Exactitud = (TP + TN) / N          = 0.8113
         Verificaci√≥n: 1 - Error            = 0.8113

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7273
         FP-Rate = FP / N                   = 0.1667

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5333
         Recall = TP / P (= TP-Rate)        = 0.7273

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7273
         Especificidad = TN / N             = 0.8333
         Verificaci√≥n: 1 - FP-Rate          = 0.8333

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6154

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       66       102
            Buggy           7        37
      ==================================================
      TN=66  FP=102  FN=7  TP=37
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 37
         True Negatives  (TN): 66
         False Positives (FP): 102
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.5142
         Exactitud = (TP + TN) / N          = 0.4858
         Verificaci√≥n: 1 - Error            = 0.4858

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.8409
         FP-Rate = FP / N                   = 0.6071

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2662
         Recall = TP / P (= TP-Rate)        = 0.8409

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.8409
         Especificidad = TN / N             = 0.3929
         Verificaci√≥n: 1 - FP-Rate          = 0.3929

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4044

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      140        28
            Buggy          24        20
      ==================================================
      TN=140  FP=28  FN=24  TP=20
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 20
         True Negatives  (TN): 140
         False Positives (FP): 28
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2453
         Exactitud = (TP + TN) / N          = 0.7547
         Verificaci√≥n: 1 - Error            = 0.7547

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4545
         FP-Rate = FP / N                   = 0.1667

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4167
         Recall = TP / P (= TP-Rate)        = 0.4545

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4545
         Especificidad = TN / N             = 0.8333
         Verificaci√≥n: 1 - FP-Rate          = 0.8333

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4348

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      137        31
            Buggy          11        33
      ==================================================
      TN=137  FP=31  FN=11  TP=33
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 33
         True Negatives  (TN): 137
         False Positives (FP): 31
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1981
         Exactitud = (TP + TN) / N          = 0.8019
         Verificaci√≥n: 1 - Error            = 0.8019

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7500
         FP-Rate = FP / N                   = 0.1845

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5156
         Recall = TP / P (= TP-Rate)        = 0.7500

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7500
         Especificidad = TN / N             = 0.8155
         Verificaci√≥n: 1 - FP-Rate          = 0.8155

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6111

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       41       127
            Buggy           3        41
      ==================================================
      TN=41  FP=127  FN=3  TP=41
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 41
         True Negatives  (TN): 41
         False Positives (FP): 127
         False Negatives (FN): 3

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.6132
         Exactitud = (TP + TN) / N          = 0.3868
         Verificaci√≥n: 1 - Error            = 0.3868

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9318
         FP-Rate = FP / N                   = 0.7560

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2440
         Recall = TP / P (= TP-Rate)        = 0.9318

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9318
         Especificidad = TN / N             = 0.2440
         Verificaci√≥n: 1 - FP-Rate          = 0.2440

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3868

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        1       167
            Buggy           0        44
      ==================================================
      TN=1  FP=167  FN=0  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 1
         False Positives (FP): 167
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.7877
         Exactitud = (TP + TN) / N          = 0.2123
         Verificaci√≥n: 1 - Error            = 0.2123

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 0.9940

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2085
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0060
         Verificaci√≥n: 1 - FP-Rate          = 0.0060

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3451

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      137        31
            Buggy          11        33
      ==================================================
      TN=137  FP=31  FN=11  TP=33
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 33
         True Negatives  (TN): 137
         False Positives (FP): 31
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1981
         Exactitud = (TP + TN) / N          = 0.8019
         Verificaci√≥n: 1 - Error            = 0.8019

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7500
         FP-Rate = FP / N                   = 0.1845

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5156
         Recall = TP / P (= TP-Rate)        = 0.7500

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7500
         Especificidad = TN / N             = 0.8155
         Verificaci√≥n: 1 - FP-Rate          = 0.8155

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6111

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


================================================================================
‚úì PIPELINE COMPLETO PARA hbase-0.94.0
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: hive-0.9.0 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: hive-0.9.0
[1] Preprocesamiento - Dimensiones originales: (1416, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1416, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (1132, 66), X_test: (284, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con hive-0.9.0 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con hive-0.9.0 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 906
    Clase Minoritaria (1): 226
    Total de clases: 1132
    Ratio de desbalance: 4.01

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 566

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 3
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 339
[Minor√≠a] Tama√±o final (original + sint√©tico): 565

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 1131
    Distribuci√≥n clases: {0: 566, 1: 565}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con hive-0.9.0 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 906 muestras
    Clase minoritaria (1): 226 muestras
    Total de clases: 1132
    Ratio de desbalance: 4.01

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 566

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 340
[Minoritaria] Tama√±o final (original + sint√©tico): 566

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 1132
    Distribuci√≥n clases: {0: 566, 1: 566}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con hive-0.9.0 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  906
     Clase minoritaria (1):  226
     Total de clases:  1132
     Indice de desbalance:  4.01

[SMOTE] Clase mayoritaria (0): 906 -> 566 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 566, 1: 566}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando hive-0.9.0 con standard
[3] [unbalanced] Escalando hive-0.9.0 con robust
[3] [csbboost] Escalando hive-0.9.0 con standard
[3] [csbboost] Escalando hive-0.9.0 con robust
[3] [hcbou] Escalando hive-0.9.0 con standard
[3] [hcbou] Escalando hive-0.9.0 con robust
[3] [smote] Escalando hive-0.9.0 con standard
[3] [smote] Escalando hive-0.9.0 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: hive-0.9.0
================================================================================

üìã Total de configuraciones a procesar: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado: ['standard', 'robust']
   ‚Ä¢ Modelos por config: 3

********************************************************************************
[1/8] PROCESANDO CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hive-0.9.0 | unbalanced | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/hive-0.9.0/standard
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hive-0.9.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hive-0.9.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] PROCESANDO CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hive-0.9.0 | unbalanced | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/hive-0.9.0/robust
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hive-0.9.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hive-0.9.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] PROCESANDO CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hive-0.9.0 | csbboost | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/hive-0.9.0/standard
       ‚úì Datos cargados: X_train=(1131, 65), X_test=(284, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hive-0.9.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hive-0.9.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] PROCESANDO CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hive-0.9.0 | csbboost | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/hive-0.9.0/robust
       ‚úì Datos cargados: X_train=(1131, 65), X_test=(284, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hive-0.9.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hive-0.9.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] PROCESANDO CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hive-0.9.0 | hcbou | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/hive-0.9.0/standard
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hive-0.9.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hive-0.9.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] PROCESANDO CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hive-0.9.0 | hcbou | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/hive-0.9.0/robust
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hive-0.9.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hive-0.9.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] PROCESANDO CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hive-0.9.0 | smote | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/hive-0.9.0/standard
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hive-0.9.0/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hive-0.9.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] PROCESANDO CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: hive-0.9.0 | smote | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/hive-0.9.0/robust
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hive-0.9.0/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hive-0.9.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: hive-0.9.0
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: hive-0.9.0
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | unbalanced | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      210        17
            Buggy          30        27
      ==================================================
      TN=210  FP=17  FN=30  TP=27
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 27
         True Negatives  (TN): 210
         False Positives (FP): 17
         False Negatives (FN): 30

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1655
         Exactitud = (TP + TN) / N          = 0.8345
         Verificaci√≥n: 1 - Error            = 0.8345

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4737
         FP-Rate = FP / N                   = 0.0749

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6136
         Recall = TP / P (= TP-Rate)        = 0.4737

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4737
         Especificidad = TN / N             = 0.9251
         Verificaci√≥n: 1 - FP-Rate          = 0.9251

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5347

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      222         5
            Buggy          42        15
      ==================================================
      TN=222  FP=5  FN=42  TP=15
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 15
         True Negatives  (TN): 222
         False Positives (FP): 5
         False Negatives (FN): 42

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1655
         Exactitud = (TP + TN) / N          = 0.8345
         Verificaci√≥n: 1 - Error            = 0.8345

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2632
         FP-Rate = FP / N                   = 0.0220

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7500
         Recall = TP / P (= TP-Rate)        = 0.2632

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2632
         Especificidad = TN / N             = 0.9780
         Verificaci√≥n: 1 - FP-Rate          = 0.9780

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3896

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      217        10
            Buggy          26        31
      ==================================================
      TN=217  FP=10  FN=26  TP=31
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 31
         True Negatives  (TN): 217
         False Positives (FP): 10
         False Negatives (FN): 26

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1268
         Exactitud = (TP + TN) / N          = 0.8732
         Verificaci√≥n: 1 - Error            = 0.8732

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5439
         FP-Rate = FP / N                   = 0.0441

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7561
         Recall = TP / P (= TP-Rate)        = 0.5439

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5439
         Especificidad = TN / N             = 0.9559
         Verificaci√≥n: 1 - FP-Rate          = 0.9559

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6327

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | unbalanced | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        6       221
            Buggy          10        47
      ==================================================
      TN=6  FP=221  FN=10  TP=47
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 47
         True Negatives  (TN): 6
         False Positives (FP): 221
         False Negatives (FN): 10

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8134
         Exactitud = (TP + TN) / N          = 0.1866
         Verificaci√≥n: 1 - Error            = 0.1866

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.8246
         FP-Rate = FP / N                   = 0.9736

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1754
         Recall = TP / P (= TP-Rate)        = 0.8246

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.8246
         Especificidad = TN / N             = 0.0264
         Verificaci√≥n: 1 - FP-Rate          = 0.0264

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2892

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      224         3
            Buggy          50         7
      ==================================================
      TN=224  FP=3  FN=50  TP=7
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 7
         True Negatives  (TN): 224
         False Positives (FP): 3
         False Negatives (FN): 50

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1866
         Exactitud = (TP + TN) / N          = 0.8134
         Verificaci√≥n: 1 - Error            = 0.8134

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1228
         FP-Rate = FP / N                   = 0.0132

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7000
         Recall = TP / P (= TP-Rate)        = 0.1228

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1228
         Especificidad = TN / N             = 0.9868
         Verificaci√≥n: 1 - FP-Rate          = 0.9868

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2090

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      217        10
            Buggy          26        31
      ==================================================
      TN=217  FP=10  FN=26  TP=31
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 31
         True Negatives  (TN): 217
         False Positives (FP): 10
         False Negatives (FN): 26

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1268
         Exactitud = (TP + TN) / N          = 0.8732
         Verificaci√≥n: 1 - Error            = 0.8732

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5439
         FP-Rate = FP / N                   = 0.0441

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7561
         Recall = TP / P (= TP-Rate)        = 0.5439

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5439
         Especificidad = TN / N             = 0.9559
         Verificaci√≥n: 1 - FP-Rate          = 0.9559

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6327

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       99       128
            Buggy           5        52
      ==================================================
      TN=99  FP=128  FN=5  TP=52
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 52
         True Negatives  (TN): 99
         False Positives (FP): 128
         False Negatives (FN): 5

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.4683
         Exactitud = (TP + TN) / N          = 0.5317
         Verificaci√≥n: 1 - Error            = 0.5317

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9123
         FP-Rate = FP / N                   = 0.5639

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2889
         Recall = TP / P (= TP-Rate)        = 0.9123

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9123
         Especificidad = TN / N             = 0.4361
         Verificaci√≥n: 1 - FP-Rate          = 0.4361

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4388

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      220         7
            Buggy          42        15
      ==================================================
      TN=220  FP=7  FN=42  TP=15
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 15
         True Negatives  (TN): 220
         False Positives (FP): 7
         False Negatives (FN): 42

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1725
         Exactitud = (TP + TN) / N          = 0.8275
         Verificaci√≥n: 1 - Error            = 0.8275

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2632
         FP-Rate = FP / N                   = 0.0308

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6818
         Recall = TP / P (= TP-Rate)        = 0.2632

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2632
         Especificidad = TN / N             = 0.9692
         Verificaci√≥n: 1 - FP-Rate          = 0.9692

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3797

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      185        42
            Buggy          13        44
      ==================================================
      TN=185  FP=42  FN=13  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 185
         False Positives (FP): 42
         False Negatives (FN): 13

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1937
         Exactitud = (TP + TN) / N          = 0.8063
         Verificaci√≥n: 1 - Error            = 0.8063

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7719
         FP-Rate = FP / N                   = 0.1850

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5116
         Recall = TP / P (= TP-Rate)        = 0.7719

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7719
         Especificidad = TN / N             = 0.8150
         Verificaci√≥n: 1 - FP-Rate          = 0.8150

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6154

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       51       176
            Buggy           2        55
      ==================================================
      TN=51  FP=176  FN=2  TP=55
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 55
         True Negatives  (TN): 51
         False Positives (FP): 176
         False Negatives (FN): 2

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.6268
         Exactitud = (TP + TN) / N          = 0.3732
         Verificaci√≥n: 1 - Error            = 0.3732

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9649
         FP-Rate = FP / N                   = 0.7753

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2381
         Recall = TP / P (= TP-Rate)        = 0.9649

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9649
         Especificidad = TN / N             = 0.2247
         Verificaci√≥n: 1 - FP-Rate          = 0.2247

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3819

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      223         4
            Buggy          48         9
      ==================================================
      TN=223  FP=4  FN=48  TP=9
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 9
         True Negatives  (TN): 223
         False Positives (FP): 4
         False Negatives (FN): 48

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1831
         Exactitud = (TP + TN) / N          = 0.8169
         Verificaci√≥n: 1 - Error            = 0.8169

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1579
         FP-Rate = FP / N                   = 0.0176

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6923
         Recall = TP / P (= TP-Rate)        = 0.1579

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1579
         Especificidad = TN / N             = 0.9824
         Verificaci√≥n: 1 - FP-Rate          = 0.9824

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2571

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      185        42
            Buggy          13        44
      ==================================================
      TN=185  FP=42  FN=13  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 185
         False Positives (FP): 42
         False Negatives (FN): 13

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1937
         Exactitud = (TP + TN) / N          = 0.8063
         Verificaci√≥n: 1 - Error            = 0.8063

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7719
         FP-Rate = FP / N                   = 0.1850

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5116
         Recall = TP / P (= TP-Rate)        = 0.7719

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7719
         Especificidad = TN / N             = 0.8150
         Verificaci√≥n: 1 - FP-Rate          = 0.8150

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6154

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      201        26
            Buggy          28        29
      ==================================================
      TN=201  FP=26  FN=28  TP=29
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 29
         True Negatives  (TN): 201
         False Positives (FP): 26
         False Negatives (FN): 28

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1901
         Exactitud = (TP + TN) / N          = 0.8099
         Verificaci√≥n: 1 - Error            = 0.8099

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5088
         FP-Rate = FP / N                   = 0.1145

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5273
         Recall = TP / P (= TP-Rate)        = 0.5088

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5088
         Especificidad = TN / N             = 0.8855
         Verificaci√≥n: 1 - FP-Rate          = 0.8855

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5179

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      223         4
            Buggy          43        14
      ==================================================
      TN=223  FP=4  FN=43  TP=14
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 14
         True Negatives  (TN): 223
         False Positives (FP): 4
         False Negatives (FN): 43

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1655
         Exactitud = (TP + TN) / N          = 0.8345
         Verificaci√≥n: 1 - Error            = 0.8345

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2456
         FP-Rate = FP / N                   = 0.0176

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7778
         Recall = TP / P (= TP-Rate)        = 0.2456

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2456
         Especificidad = TN / N             = 0.9824
         Verificaci√≥n: 1 - FP-Rate          = 0.9824

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3733

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      175        52
            Buggy          15        42
      ==================================================
      TN=175  FP=52  FN=15  TP=42
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 42
         True Negatives  (TN): 175
         False Positives (FP): 52
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2359
         Exactitud = (TP + TN) / N          = 0.7641
         Verificaci√≥n: 1 - Error            = 0.7641

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7368
         FP-Rate = FP / N                   = 0.2291

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4468
         Recall = TP / P (= TP-Rate)        = 0.7368

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7368
         Especificidad = TN / N             = 0.7709
         Verificaci√≥n: 1 - FP-Rate          = 0.7709

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5563

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      170        57
            Buggy          13        44
      ==================================================
      TN=170  FP=57  FN=13  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 170
         False Positives (FP): 57
         False Negatives (FN): 13

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2465
         Exactitud = (TP + TN) / N          = 0.7535
         Verificaci√≥n: 1 - Error            = 0.7535

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7719
         FP-Rate = FP / N                   = 0.2511

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4356
         Recall = TP / P (= TP-Rate)        = 0.7719

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7719
         Especificidad = TN / N             = 0.7489
         Verificaci√≥n: 1 - FP-Rate          = 0.7489

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5570

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      224         3
            Buggy          49         8
      ==================================================
      TN=224  FP=3  FN=49  TP=8
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 8
         True Negatives  (TN): 224
         False Positives (FP): 3
         False Negatives (FN): 49

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1831
         Exactitud = (TP + TN) / N          = 0.8169
         Verificaci√≥n: 1 - Error            = 0.8169

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1404
         FP-Rate = FP / N                   = 0.0132

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7273
         Recall = TP / P (= TP-Rate)        = 0.1404

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1404
         Especificidad = TN / N             = 0.9868
         Verificaci√≥n: 1 - FP-Rate          = 0.9868

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2353

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      175        52
            Buggy          15        42
      ==================================================
      TN=175  FP=52  FN=15  TP=42
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 42
         True Negatives  (TN): 175
         False Positives (FP): 52
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2359
         Exactitud = (TP + TN) / N          = 0.7641
         Verificaci√≥n: 1 - Error            = 0.7641

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7368
         FP-Rate = FP / N                   = 0.2291

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4468
         Recall = TP / P (= TP-Rate)        = 0.7368

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7368
         Especificidad = TN / N             = 0.7709
         Verificaci√≥n: 1 - FP-Rate          = 0.7709

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5563

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      197        30
            Buggy          22        35
      ==================================================
      TN=197  FP=30  FN=22  TP=35
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 35
         True Negatives  (TN): 197
         False Positives (FP): 30
         False Negatives (FN): 22

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1831
         Exactitud = (TP + TN) / N          = 0.8169
         Verificaci√≥n: 1 - Error            = 0.8169

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6140
         FP-Rate = FP / N                   = 0.1322

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5385
         Recall = TP / P (= TP-Rate)        = 0.6140

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6140
         Especificidad = TN / N             = 0.8678
         Verificaci√≥n: 1 - FP-Rate          = 0.8678

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5738

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      218         9
            Buggy          40        17
      ==================================================
      TN=218  FP=9  FN=40  TP=17
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 17
         True Negatives  (TN): 218
         False Positives (FP): 9
         False Negatives (FN): 40

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1725
         Exactitud = (TP + TN) / N          = 0.8275
         Verificaci√≥n: 1 - Error            = 0.8275

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2982
         FP-Rate = FP / N                   = 0.0396

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6538
         Recall = TP / P (= TP-Rate)        = 0.2982

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2982
         Especificidad = TN / N             = 0.9604
         Verificaci√≥n: 1 - FP-Rate          = 0.9604

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4096

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      192        35
            Buggy          17        40
      ==================================================
      TN=192  FP=35  FN=17  TP=40
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 40
         True Negatives  (TN): 192
         False Positives (FP): 35
         False Negatives (FN): 17

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1831
         Exactitud = (TP + TN) / N          = 0.8169
         Verificaci√≥n: 1 - Error            = 0.8169

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7018
         FP-Rate = FP / N                   = 0.1542

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5333
         Recall = TP / P (= TP-Rate)        = 0.7018

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7018
         Especificidad = TN / N             = 0.8458
         Verificaci√≥n: 1 - FP-Rate          = 0.8458

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6061

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      166        61
            Buggy          11        46
      ==================================================
      TN=166  FP=61  FN=11  TP=46
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 46
         True Negatives  (TN): 166
         False Positives (FP): 61
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2535
         Exactitud = (TP + TN) / N          = 0.7465
         Verificaci√≥n: 1 - Error            = 0.7465

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.8070
         FP-Rate = FP / N                   = 0.2687

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4299
         Recall = TP / P (= TP-Rate)        = 0.8070

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.8070
         Especificidad = TN / N             = 0.7313
         Verificaci√≥n: 1 - FP-Rate          = 0.7313

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5610

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      222         5
            Buggy          50         7
      ==================================================
      TN=222  FP=5  FN=50  TP=7
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 7
         True Negatives  (TN): 222
         False Positives (FP): 5
         False Negatives (FN): 50

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1937
         Exactitud = (TP + TN) / N          = 0.8063
         Verificaci√≥n: 1 - Error            = 0.8063

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1228
         FP-Rate = FP / N                   = 0.0220

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5833
         Recall = TP / P (= TP-Rate)        = 0.1228

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1228
         Especificidad = TN / N             = 0.9780
         Verificaci√≥n: 1 - FP-Rate          = 0.9780

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2029

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      191        36
            Buggy          16        41
      ==================================================
      TN=191  FP=36  FN=16  TP=41
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 41
         True Negatives  (TN): 191
         False Positives (FP): 36
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1831
         Exactitud = (TP + TN) / N          = 0.8169
         Verificaci√≥n: 1 - Error            = 0.8169

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7193
         FP-Rate = FP / N                   = 0.1586

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5325
         Recall = TP / P (= TP-Rate)        = 0.7193

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7193
         Especificidad = TN / N             = 0.8414
         Verificaci√≥n: 1 - FP-Rate          = 0.8414

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6119

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


================================================================================
‚úì PIPELINE COMPLETO PARA hive-0.9.0
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: jruby-1.1 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: jruby-1.1
[1] Preprocesamiento - Dimensiones originales: (731, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (731, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (584, 66), X_test: (147, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con jruby-1.1 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con jruby-1.1 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 514
    Clase Minoritaria (1): 70
    Total de clases: 584
    Ratio de desbalance: 7.34

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 292

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 222
[Minor√≠a] Tama√±o final (original + sint√©tico): 292

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 584
    Distribuci√≥n clases: {0: 292, 1: 292}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con jruby-1.1 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 514 muestras
    Clase minoritaria (1): 70 muestras
    Total de clases: 584
    Ratio de desbalance: 7.34

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 292

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 222
[Minoritaria] Tama√±o final (original + sint√©tico): 292

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 584
    Distribuci√≥n clases: {0: 292, 1: 292}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con jruby-1.1 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  514
     Clase minoritaria (1):  70
     Total de clases:  584
     Indice de desbalance:  7.34

[SMOTE] Clase mayoritaria (0): 514 -> 292 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 292, 1: 292}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando jruby-1.1 con standard
[3] [unbalanced] Escalando jruby-1.1 con robust
[3] [csbboost] Escalando jruby-1.1 con standard
[3] [csbboost] Escalando jruby-1.1 con robust
[3] [hcbou] Escalando jruby-1.1 con standard
[3] [hcbou] Escalando jruby-1.1 con robust
[3] [smote] Escalando jruby-1.1 con standard
[3] [smote] Escalando jruby-1.1 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: jruby-1.1
================================================================================

üìã Total de configuraciones a procesar: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado: ['standard', 'robust']
   ‚Ä¢ Modelos por config: 3

********************************************************************************
[1/8] PROCESANDO CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: jruby-1.1 | unbalanced | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/jruby-1.1/standard
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/jruby-1.1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/jruby-1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] PROCESANDO CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: jruby-1.1 | unbalanced | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/jruby-1.1/robust
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/jruby-1.1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/jruby-1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] PROCESANDO CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: jruby-1.1 | csbboost | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/jruby-1.1/standard
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/jruby-1.1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/jruby-1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] PROCESANDO CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: jruby-1.1 | csbboost | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/jruby-1.1/robust
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/jruby-1.1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/jruby-1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] PROCESANDO CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: jruby-1.1 | hcbou | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/jruby-1.1/standard
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/jruby-1.1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/jruby-1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] PROCESANDO CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: jruby-1.1 | hcbou | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/jruby-1.1/robust
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/jruby-1.1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/jruby-1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] PROCESANDO CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: jruby-1.1 | smote | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/jruby-1.1/standard
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/jruby-1.1/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/jruby-1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] PROCESANDO CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: jruby-1.1 | smote | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/jruby-1.1/robust
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/jruby-1.1/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/jruby-1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: jruby-1.1
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: jruby-1.1
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | unbalanced | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      126         4
            Buggy           7        10
      ==================================================
      TN=126  FP=4  FN=7  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 126
         False Positives (FP): 4
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0748
         Exactitud = (TP + TN) / N          = 0.9252
         Verificaci√≥n: 1 - Error            = 0.9252

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5882
         FP-Rate = FP / N                   = 0.0308

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7143
         Recall = TP / P (= TP-Rate)        = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5882
         Especificidad = TN / N             = 0.9692
         Verificaci√≥n: 1 - FP-Rate          = 0.9692

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6452

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      124         6
            Buggy           6        11
      ==================================================
      TN=124  FP=6  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 124
         False Positives (FP): 6
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0816
         Exactitud = (TP + TN) / N          = 0.9184
         Verificaci√≥n: 1 - Error            = 0.9184

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.0462

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6471
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.9538
         Verificaci√≥n: 1 - FP-Rate          = 0.9538

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6471

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      126         4
            Buggy           8         9
      ==================================================
      TN=126  FP=4  FN=8  TP=9
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 9
         True Negatives  (TN): 126
         False Positives (FP): 4
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0816
         Exactitud = (TP + TN) / N          = 0.9184
         Verificaci√≥n: 1 - Error            = 0.9184

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5294
         FP-Rate = FP / N                   = 0.0308

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6923
         Recall = TP / P (= TP-Rate)        = 0.5294

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5294
         Especificidad = TN / N             = 0.9692
         Verificaci√≥n: 1 - FP-Rate          = 0.9692

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6000

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | unbalanced | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       130
            Buggy           0        17
      ==================================================
      TN=0  FP=130  FN=0  TP=17
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 17
         True Negatives  (TN): 0
         False Positives (FP): 130
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8844
         Exactitud = (TP + TN) / N          = 0.1156
         Verificaci√≥n: 1 - Error            = 0.1156

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1156
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2073

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      130         0
            Buggy          15         2
      ==================================================
      TN=130  FP=0  FN=15  TP=2
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 2
         True Negatives  (TN): 130
         False Positives (FP): 0
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1020
         Exactitud = (TP + TN) / N          = 0.8980
         Verificaci√≥n: 1 - Error            = 0.8980

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1176
         FP-Rate = FP / N                   = 0.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 1.0000
         Recall = TP / P (= TP-Rate)        = 0.1176

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1176
         Especificidad = TN / N             = 1.0000
         Verificaci√≥n: 1 - FP-Rate          = 1.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2105

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      126         4
            Buggy           8         9
      ==================================================
      TN=126  FP=4  FN=8  TP=9
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 9
         True Negatives  (TN): 126
         False Positives (FP): 4
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0816
         Exactitud = (TP + TN) / N          = 0.9184
         Verificaci√≥n: 1 - Error            = 0.9184

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5294
         FP-Rate = FP / N                   = 0.0308

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6923
         Recall = TP / P (= TP-Rate)        = 0.5294

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5294
         Especificidad = TN / N             = 0.9692
         Verificaci√≥n: 1 - FP-Rate          = 0.9692

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6000

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      117        13
            Buggy           6        11
      ==================================================
      TN=117  FP=13  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 117
         False Positives (FP): 13
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1293
         Exactitud = (TP + TN) / N          = 0.8707
         Verificaci√≥n: 1 - Error            = 0.8707

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.1000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4583
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.9000
         Verificaci√≥n: 1 - FP-Rate          = 0.9000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5366

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      122         8
            Buggy           6        11
      ==================================================
      TN=122  FP=8  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 122
         False Positives (FP): 8
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0952
         Exactitud = (TP + TN) / N          = 0.9048
         Verificaci√≥n: 1 - Error            = 0.9048

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.0615

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5789
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.9385
         Verificaci√≥n: 1 - FP-Rate          = 0.9385

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6111

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      115        15
            Buggy           5        12
      ==================================================
      TN=115  FP=15  FN=5  TP=12
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 12
         True Negatives  (TN): 115
         False Positives (FP): 15
         False Negatives (FN): 5

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1361
         Exactitud = (TP + TN) / N          = 0.8639
         Verificaci√≥n: 1 - Error            = 0.8639

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7059
         FP-Rate = FP / N                   = 0.1154

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4444
         Recall = TP / P (= TP-Rate)        = 0.7059

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7059
         Especificidad = TN / N             = 0.8846
         Verificaci√≥n: 1 - FP-Rate          = 0.8846

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5455

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       95        35
            Buggy           5        12
      ==================================================
      TN=95  FP=35  FN=5  TP=12
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 12
         True Negatives  (TN): 95
         False Positives (FP): 35
         False Negatives (FN): 5

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2721
         Exactitud = (TP + TN) / N          = 0.7279
         Verificaci√≥n: 1 - Error            = 0.7279

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7059
         FP-Rate = FP / N                   = 0.2692

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2553
         Recall = TP / P (= TP-Rate)        = 0.7059

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7059
         Especificidad = TN / N             = 0.7308
         Verificaci√≥n: 1 - FP-Rate          = 0.7308

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3750

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      130         0
            Buggy          16         1
      ==================================================
      TN=130  FP=0  FN=16  TP=1
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 1
         True Negatives  (TN): 130
         False Positives (FP): 0
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1088
         Exactitud = (TP + TN) / N          = 0.8912
         Verificaci√≥n: 1 - Error            = 0.8912

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0588
         FP-Rate = FP / N                   = 0.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 1.0000
         Recall = TP / P (= TP-Rate)        = 0.0588

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0588
         Especificidad = TN / N             = 1.0000
         Verificaci√≥n: 1 - FP-Rate          = 1.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1111

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      115        15
            Buggy           5        12
      ==================================================
      TN=115  FP=15  FN=5  TP=12
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 12
         True Negatives  (TN): 115
         False Positives (FP): 15
         False Negatives (FN): 5

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1361
         Exactitud = (TP + TN) / N          = 0.8639
         Verificaci√≥n: 1 - Error            = 0.8639

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7059
         FP-Rate = FP / N                   = 0.1154

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4444
         Recall = TP / P (= TP-Rate)        = 0.7059

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7059
         Especificidad = TN / N             = 0.8846
         Verificaci√≥n: 1 - FP-Rate          = 0.8846

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5455

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      121         9
            Buggy           9         8
      ==================================================
      TN=121  FP=9  FN=9  TP=8
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 8
         True Negatives  (TN): 121
         False Positives (FP): 9
         False Negatives (FN): 9

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1224
         Exactitud = (TP + TN) / N          = 0.8776
         Verificaci√≥n: 1 - Error            = 0.8776

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4706
         FP-Rate = FP / N                   = 0.0692

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4706
         Recall = TP / P (= TP-Rate)        = 0.4706

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4706
         Especificidad = TN / N             = 0.9308
         Verificaci√≥n: 1 - FP-Rate          = 0.9308

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4706

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      124         6
            Buggy           6        11
      ==================================================
      TN=124  FP=6  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 124
         False Positives (FP): 6
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0816
         Exactitud = (TP + TN) / N          = 0.9184
         Verificaci√≥n: 1 - Error            = 0.9184

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.0462

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6471
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.9538
         Verificaci√≥n: 1 - FP-Rate          = 0.9538

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6471

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      114        16
            Buggy           6        11
      ==================================================
      TN=114  FP=16  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 114
         False Positives (FP): 16
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1497
         Exactitud = (TP + TN) / N          = 0.8503
         Verificaci√≥n: 1 - Error            = 0.8503

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.1231

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4074
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.8769
         Verificaci√≥n: 1 - FP-Rate          = 0.8769

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5000

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      118        12
            Buggy           7        10
      ==================================================
      TN=118  FP=12  FN=7  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 118
         False Positives (FP): 12
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1293
         Exactitud = (TP + TN) / N          = 0.8707
         Verificaci√≥n: 1 - Error            = 0.8707

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5882
         FP-Rate = FP / N                   = 0.0923

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4545
         Recall = TP / P (= TP-Rate)        = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5882
         Especificidad = TN / N             = 0.9077
         Verificaci√≥n: 1 - FP-Rate          = 0.9077

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5128

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      130         0
            Buggy          16         1
      ==================================================
      TN=130  FP=0  FN=16  TP=1
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 1
         True Negatives  (TN): 130
         False Positives (FP): 0
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1088
         Exactitud = (TP + TN) / N          = 0.8912
         Verificaci√≥n: 1 - Error            = 0.8912

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0588
         FP-Rate = FP / N                   = 0.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 1.0000
         Recall = TP / P (= TP-Rate)        = 0.0588

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0588
         Especificidad = TN / N             = 1.0000
         Verificaci√≥n: 1 - FP-Rate          = 1.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1111

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      114        16
            Buggy           6        11
      ==================================================
      TN=114  FP=16  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 114
         False Positives (FP): 16
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1497
         Exactitud = (TP + TN) / N          = 0.8503
         Verificaci√≥n: 1 - Error            = 0.8503

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.1231

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4074
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.8769
         Verificaci√≥n: 1 - FP-Rate          = 0.8769

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5000

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      124         6
            Buggy          10         7
      ==================================================
      TN=124  FP=6  FN=10  TP=7
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 7
         True Negatives  (TN): 124
         False Positives (FP): 6
         False Negatives (FN): 10

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1088
         Exactitud = (TP + TN) / N          = 0.8912
         Verificaci√≥n: 1 - Error            = 0.8912

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4118
         FP-Rate = FP / N                   = 0.0462

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5385
         Recall = TP / P (= TP-Rate)        = 0.4118

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4118
         Especificidad = TN / N             = 0.9538
         Verificaci√≥n: 1 - FP-Rate          = 0.9538

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4667

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-06}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      124         6
            Buggy           6        11
      ==================================================
      TN=124  FP=6  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 124
         False Positives (FP): 6
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0816
         Exactitud = (TP + TN) / N          = 0.9184
         Verificaci√≥n: 1 - Error            = 0.9184

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.0462

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6471
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.9538
         Verificaci√≥n: 1 - FP-Rate          = 0.9538

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6471

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      123         7
            Buggy           7        10
      ==================================================
      TN=123  FP=7  FN=7  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 123
         False Positives (FP): 7
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0952
         Exactitud = (TP + TN) / N          = 0.9048
         Verificaci√≥n: 1 - Error            = 0.9048

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5882
         FP-Rate = FP / N                   = 0.0538

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5882
         Recall = TP / P (= TP-Rate)        = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5882
         Especificidad = TN / N             = 0.9462
         Verificaci√≥n: 1 - FP-Rate          = 0.9462

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5882

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       54        76
            Buggy           1        16
      ==================================================
      TN=54  FP=76  FN=1  TP=16
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 16
         True Negatives  (TN): 54
         False Positives (FP): 76
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.5238
         Exactitud = (TP + TN) / N          = 0.4762
         Verificaci√≥n: 1 - Error            = 0.4762

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9412
         FP-Rate = FP / N                   = 0.5846

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1739
         Recall = TP / P (= TP-Rate)        = 0.9412

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9412
         Especificidad = TN / N             = 0.4154
         Verificaci√≥n: 1 - FP-Rate          = 0.4154

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2936

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      130         0
            Buggy          16         1
      ==================================================
      TN=130  FP=0  FN=16  TP=1
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 1
         True Negatives  (TN): 130
         False Positives (FP): 0
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1088
         Exactitud = (TP + TN) / N          = 0.8912
         Verificaci√≥n: 1 - Error            = 0.8912

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0588
         FP-Rate = FP / N                   = 0.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 1.0000
         Recall = TP / P (= TP-Rate)        = 0.0588

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0588
         Especificidad = TN / N             = 1.0000
         Verificaci√≥n: 1 - FP-Rate          = 1.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1111

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      122         8
            Buggy           7        10
      ==================================================
      TN=122  FP=8  FN=7  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 122
         False Positives (FP): 8
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1020
         Exactitud = (TP + TN) / N          = 0.8980
         Verificaci√≥n: 1 - Error            = 0.8980

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5882
         FP-Rate = FP / N                   = 0.0615

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5556
         Recall = TP / P (= TP-Rate)        = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5882
         Especificidad = TN / N             = 0.9385
         Verificaci√≥n: 1 - FP-Rate          = 0.9385

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5714

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


================================================================================
‚úì PIPELINE COMPLETO PARA jruby-1.1
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: wicket-1.3.0-beta2 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: wicket-1.3.0-beta2
[1] Preprocesamiento - Dimensiones originales: (1763, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1763, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (1410, 66), X_test: (353, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con wicket-1.3.0-beta2 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con wicket-1.3.0-beta2 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 1306
    Clase Minoritaria (1): 104
    Total de clases: 1410
    Ratio de desbalance: 12.56

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 705

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 601
[Minor√≠a] Tama√±o final (original + sint√©tico): 705

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 1410
    Distribuci√≥n clases: {0: 705, 1: 705}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con wicket-1.3.0-beta2 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 1306 muestras
    Clase minoritaria (1): 104 muestras
    Total de clases: 1410
    Ratio de desbalance: 12.56

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 705

Clase minoritarias---------
[Minoritaria] K √≥ptimo (Silhouete) = 2
[Minoritaria] N√∫mero √≥ptimo de clusters: 2
Mejor √≠ndice silhouette: 0.7938
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 2
[Minoritaria] Nuevas muestras sint√©ticas generadas: 600
[Minoritaria] Tama√±o final (original + sint√©tico): 704

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 1409
    Distribuci√≥n clases: {0: 705, 1: 704}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con wicket-1.3.0-beta2 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  1306
     Clase minoritaria (1):  104
     Total de clases:  1410
     Indice de desbalance:  12.56

[SMOTE] Clase mayoritaria (0): 1306 -> 705 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 705, 1: 705}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando wicket-1.3.0-beta2 con standard
[3] [unbalanced] Escalando wicket-1.3.0-beta2 con robust
[3] [csbboost] Escalando wicket-1.3.0-beta2 con standard
[3] [csbboost] Escalando wicket-1.3.0-beta2 con robust
[3] [hcbou] Escalando wicket-1.3.0-beta2 con standard
[3] [hcbou] Escalando wicket-1.3.0-beta2 con robust
[3] [smote] Escalando wicket-1.3.0-beta2 con standard
[3] [smote] Escalando wicket-1.3.0-beta2 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: wicket-1.3.0-beta2
================================================================================

üìã Total de configuraciones a procesar: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado: ['standard', 'robust']
   ‚Ä¢ Modelos por config: 3

********************************************************************************
[1/8] PROCESANDO CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: wicket-1.3.0-beta2 | unbalanced | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/wicket-1.3.0-beta2/standard
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/wicket-1.3.0-beta2/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/wicket-1.3.0-beta2/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] PROCESANDO CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: wicket-1.3.0-beta2 | unbalanced | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/unbalanced/wicket-1.3.0-beta2/robust
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/wicket-1.3.0-beta2/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/wicket-1.3.0-beta2/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] PROCESANDO CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: wicket-1.3.0-beta2 | csbboost | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/wicket-1.3.0-beta2/standard
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/wicket-1.3.0-beta2/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/wicket-1.3.0-beta2/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] PROCESANDO CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: wicket-1.3.0-beta2 | csbboost | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/csbboost/wicket-1.3.0-beta2/robust
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/wicket-1.3.0-beta2/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/wicket-1.3.0-beta2/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] PROCESANDO CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: wicket-1.3.0-beta2 | hcbou | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/wicket-1.3.0-beta2/standard
       ‚úì Datos cargados: X_train=(1409, 65), X_test=(353, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/wicket-1.3.0-beta2/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/wicket-1.3.0-beta2/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] PROCESANDO CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: wicket-1.3.0-beta2 | hcbou | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/hcbou/wicket-1.3.0-beta2/robust
       ‚úì Datos cargados: X_train=(1409, 65), X_test=(353, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/wicket-1.3.0-beta2/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/wicket-1.3.0-beta2/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] PROCESANDO CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: wicket-1.3.0-beta2 | smote | standard
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/wicket-1.3.0-beta2/standard
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/wicket-1.3.0-beta2/standard

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/wicket-1.3.0-beta2/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] PROCESANDO CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: wicket-1.3.0-beta2 | smote | robust
======================================================================
       üìÇ Cargando datos desde: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/03_scaling/smote/wicket-1.3.0-beta2/robust
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/wicket-1.3.0-beta2/robust

       üìã Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       ‚ö° Modo PARALELO
       üíæ Cach√© ACTIVADO

       üöÄ Iniciando procesamiento paralelo de 3 modelos...
       ‚úì Progreso: 1/3 modelos completados
       ‚úì Progreso: 2/3 modelos completados
       ‚úì Progreso: 3/3 modelos completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/wicket-1.3.0-beta2/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: wicket-1.3.0-beta2
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: wicket-1.3.0-beta2
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | unbalanced | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      284        43
            Buggy          23         3
      ==================================================
      TN=284  FP=43  FN=23  TP=3
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 3
         True Negatives  (TN): 284
         False Positives (FP): 43
         False Negatives (FN): 23

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1870
         Exactitud = (TP + TN) / N          = 0.8130
         Verificaci√≥n: 1 - Error            = 0.8130

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1154
         FP-Rate = FP / N                   = 0.1315

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0652
         Recall = TP / P (= TP-Rate)        = 0.1154

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1154
         Especificidad = TN / N             = 0.8685
         Verificaci√≥n: 1 - FP-Rate          = 0.8685

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.0833

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      302        25
            Buggy          16        10
      ==================================================
      TN=302  FP=25  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 302
         False Positives (FP): 25
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1161
         Exactitud = (TP + TN) / N          = 0.8839
         Verificaci√≥n: 1 - Error            = 0.8839

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0765

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2857
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9235
         Verificaci√≥n: 1 - FP-Rate          = 0.9235

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3279

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      307        20
            Buggy          21         5
      ==================================================
      TN=307  FP=20  FN=21  TP=5
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 5
         True Negatives  (TN): 307
         False Positives (FP): 20
         False Negatives (FN): 21

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1161
         Exactitud = (TP + TN) / N          = 0.8839
         Verificaci√≥n: 1 - Error            = 0.8839

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1923
         FP-Rate = FP / N                   = 0.0612

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2000
         Recall = TP / P (= TP-Rate)        = 0.1923

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1923
         Especificidad = TN / N             = 0.9388
         Verificaci√≥n: 1 - FP-Rate          = 0.9388

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1961

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | unbalanced | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       21       306
            Buggy           2        24
      ==================================================
      TN=21  FP=306  FN=2  TP=24
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 24
         True Negatives  (TN): 21
         False Positives (FP): 306
         False Negatives (FN): 2

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8725
         Exactitud = (TP + TN) / N          = 0.1275
         Verificaci√≥n: 1 - Error            = 0.1275

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9231
         FP-Rate = FP / N                   = 0.9358

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0727
         Recall = TP / P (= TP-Rate)        = 0.9231

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9231
         Especificidad = TN / N             = 0.0642
         Verificaci√≥n: 1 - FP-Rate          = 0.0642

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1348

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      302        25
            Buggy          16        10
      ==================================================
      TN=302  FP=25  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 302
         False Positives (FP): 25
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1161
         Exactitud = (TP + TN) / N          = 0.8839
         Verificaci√≥n: 1 - Error            = 0.8839

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0765

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2857
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9235
         Verificaci√≥n: 1 - FP-Rate          = 0.9235

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3279

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      307        20
            Buggy          20         6
      ==================================================
      TN=307  FP=20  FN=20  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 307
         False Positives (FP): 20
         False Negatives (FN): 20

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1133
         Exactitud = (TP + TN) / N          = 0.8867
         Verificaci√≥n: 1 - Error            = 0.8867

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2308
         FP-Rate = FP / N                   = 0.0612

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2308
         Recall = TP / P (= TP-Rate)        = 0.2308

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2308
         Especificidad = TN / N             = 0.9388
         Verificaci√≥n: 1 - FP-Rate          = 0.9388

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2308

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       25       302
            Buggy           0        26
      ==================================================
      TN=25  FP=302  FN=0  TP=26
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 26
         True Negatives  (TN): 25
         False Positives (FP): 302
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8555
         Exactitud = (TP + TN) / N          = 0.1445
         Verificaci√≥n: 1 - Error            = 0.1445

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 0.9235

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0793
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0765
         Verificaci√≥n: 1 - FP-Rate          = 0.0765

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1469

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      299        28
            Buggy          16        10
      ==================================================
      TN=299  FP=28  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 299
         False Positives (FP): 28
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1246
         Exactitud = (TP + TN) / N          = 0.8754
         Verificaci√≥n: 1 - Error            = 0.8754

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0856

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2632
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9144
         Verificaci√≥n: 1 - FP-Rate          = 0.9144

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3125

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      294        33
            Buggy          18         8
      ==================================================
      TN=294  FP=33  FN=18  TP=8
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 8
         True Negatives  (TN): 294
         False Positives (FP): 33
         False Negatives (FN): 18

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1445
         Exactitud = (TP + TN) / N          = 0.8555
         Verificaci√≥n: 1 - Error            = 0.8555

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3077
         FP-Rate = FP / N                   = 0.1009

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1951
         Recall = TP / P (= TP-Rate)        = 0.3077

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3077
         Especificidad = TN / N             = 0.8991
         Verificaci√≥n: 1 - FP-Rate          = 0.8991

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2388

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       33       294
            Buggy           1        25
      ==================================================
      TN=33  FP=294  FN=1  TP=25
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 25
         True Negatives  (TN): 33
         False Positives (FP): 294
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8357
         Exactitud = (TP + TN) / N          = 0.1643
         Verificaci√≥n: 1 - Error            = 0.1643

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9615
         FP-Rate = FP / N                   = 0.8991

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0784
         Recall = TP / P (= TP-Rate)        = 0.9615

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9615
         Especificidad = TN / N             = 0.1009
         Verificaci√≥n: 1 - FP-Rate          = 0.1009

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1449

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.04s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      299        28
            Buggy          16        10
      ==================================================
      TN=299  FP=28  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 299
         False Positives (FP): 28
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1246
         Exactitud = (TP + TN) / N          = 0.8754
         Verificaci√≥n: 1 - Error            = 0.8754

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0856

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2632
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9144
         Verificaci√≥n: 1 - FP-Rate          = 0.9144

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3125

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      294        33
            Buggy          18         8
      ==================================================
      TN=294  FP=33  FN=18  TP=8
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 8
         True Negatives  (TN): 294
         False Positives (FP): 33
         False Negatives (FN): 18

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1445
         Exactitud = (TP + TN) / N          = 0.8555
         Verificaci√≥n: 1 - Error            = 0.8555

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3077
         FP-Rate = FP / N                   = 0.1009

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1951
         Recall = TP / P (= TP-Rate)        = 0.3077

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3077
         Especificidad = TN / N             = 0.8991
         Verificaci√≥n: 1 - FP-Rate          = 0.8991

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2388

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      222       105
            Buggy           7        19
      ==================================================
      TN=222  FP=105  FN=7  TP=19
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 19
         True Negatives  (TN): 222
         False Positives (FP): 105
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.3173
         Exactitud = (TP + TN) / N          = 0.6827
         Verificaci√≥n: 1 - Error            = 0.6827

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7308
         FP-Rate = FP / N                   = 0.3211

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1532
         Recall = TP / P (= TP-Rate)        = 0.7308

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7308
         Especificidad = TN / N             = 0.6789
         Verificaci√≥n: 1 - FP-Rate          = 0.6789

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2533

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      304        23
            Buggy          16        10
      ==================================================
      TN=304  FP=23  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 304
         False Positives (FP): 23
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1105
         Exactitud = (TP + TN) / N          = 0.8895
         Verificaci√≥n: 1 - Error            = 0.8895

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0703

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3030
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9297
         Verificaci√≥n: 1 - FP-Rate          = 0.9297

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3390

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      240        87
            Buggy          11        15
      ==================================================
      TN=240  FP=87  FN=11  TP=15
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 15
         True Negatives  (TN): 240
         False Positives (FP): 87
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2776
         Exactitud = (TP + TN) / N          = 0.7224
         Verificaci√≥n: 1 - Error            = 0.7224

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5769
         FP-Rate = FP / N                   = 0.2661

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1471
         Recall = TP / P (= TP-Rate)        = 0.5769

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5769
         Especificidad = TN / N             = 0.7339
         Verificaci√≥n: 1 - FP-Rate          = 0.7339

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2344

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      197       130
            Buggy           5        21
      ==================================================
      TN=197  FP=130  FN=5  TP=21
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 21
         True Negatives  (TN): 197
         False Positives (FP): 130
         False Negatives (FN): 5

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.3824
         Exactitud = (TP + TN) / N          = 0.6176
         Verificaci√≥n: 1 - Error            = 0.6176

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.8077
         FP-Rate = FP / N                   = 0.3976

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1391
         Recall = TP / P (= TP-Rate)        = 0.8077

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.8077
         Especificidad = TN / N             = 0.6024
         Verificaci√≥n: 1 - FP-Rate          = 0.6024

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2373

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      307        20
            Buggy          18         8
      ==================================================
      TN=307  FP=20  FN=18  TP=8
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 8
         True Negatives  (TN): 307
         False Positives (FP): 20
         False Negatives (FN): 18

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1076
         Exactitud = (TP + TN) / N          = 0.8924
         Verificaci√≥n: 1 - Error            = 0.8924

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3077
         FP-Rate = FP / N                   = 0.0612

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2857
         Recall = TP / P (= TP-Rate)        = 0.3077

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3077
         Especificidad = TN / N             = 0.9388
         Verificaci√≥n: 1 - FP-Rate          = 0.9388

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2963

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      240        87
            Buggy          11        15
      ==================================================
      TN=240  FP=87  FN=11  TP=15
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 15
         True Negatives  (TN): 240
         False Positives (FP): 87
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2776
         Exactitud = (TP + TN) / N          = 0.7224
         Verificaci√≥n: 1 - Error            = 0.7224

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5769
         FP-Rate = FP / N                   = 0.2661

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1471
         Recall = TP / P (= TP-Rate)        = 0.5769

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5769
         Especificidad = TN / N             = 0.7339
         Verificaci√≥n: 1 - FP-Rate          = 0.7339

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2344

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       31       296
            Buggy           0        26
      ==================================================
      TN=31  FP=296  FN=0  TP=26
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 26
         True Negatives  (TN): 31
         False Positives (FP): 296
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8385
         Exactitud = (TP + TN) / N          = 0.1615
         Verificaci√≥n: 1 - Error            = 0.1615

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 0.9052

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0807
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0948
         Verificaci√≥n: 1 - FP-Rate          = 0.0948

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1494

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-06}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      300        27
            Buggy          15        11
      ==================================================
      TN=300  FP=27  FN=15  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 300
         False Positives (FP): 27
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1190
         Exactitud = (TP + TN) / N          = 0.8810
         Verificaci√≥n: 1 - Error            = 0.8810

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4231
         FP-Rate = FP / N                   = 0.0826

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2895
         Recall = TP / P (= TP-Rate)        = 0.4231

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4231
         Especificidad = TN / N             = 0.9174
         Verificaci√≥n: 1 - FP-Rate          = 0.9174

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3438

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      280        47
            Buggy          16        10
      ==================================================
      TN=280  FP=47  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 280
         False Positives (FP): 47
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1785
         Exactitud = (TP + TN) / N          = 0.8215
         Verificaci√≥n: 1 - Error            = 0.8215

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.1437

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1754
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.8563
         Verificaci√≥n: 1 - FP-Rate          = 0.8563

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2410

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy       35       292
            Buggy           1        25
      ==================================================
      TN=35  FP=292  FN=1  TP=25
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 25
         True Negatives  (TN): 35
         False Positives (FP): 292
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.8300
         Exactitud = (TP + TN) / N          = 0.1700
         Verificaci√≥n: 1 - Error            = 0.1700

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9615
         FP-Rate = FP / N                   = 0.8930

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0789
         Recall = TP / P (= TP-Rate)        = 0.9615

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9615
         Especificidad = TN / N             = 0.1070
         Verificaci√≥n: 1 - FP-Rate          = 0.1070

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1458

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-06}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      299        28
            Buggy          16        10
      ==================================================
      TN=299  FP=28  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 299
         False Positives (FP): 28
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1246
         Exactitud = (TP + TN) / N          = 0.8754
         Verificaci√≥n: 1 - Error            = 0.8754

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0856

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2632
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9144
         Verificaci√≥n: 1 - FP-Rate          = 0.9144

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3125

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      280        47
            Buggy          16        10
      ==================================================
      TN=280  FP=47  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 280
         False Positives (FP): 47
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1785
         Exactitud = (TP + TN) / N          = 0.8215
         Verificaci√≥n: 1 - Error            = 0.8215

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.1437

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1754
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.8563
         Verificaci√≥n: 1 - FP-Rate          = 0.8563

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2410

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


================================================================================
‚úì PIPELINE COMPLETO PARA wicket-1.3.0-beta2
================================================================================

==================================================
=== FIN DE EJECUCI√ìN DEL PIPELINE ===
Timestamp: 2025-11-28 13:35:23
==================================================
