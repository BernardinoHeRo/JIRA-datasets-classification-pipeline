=== INICIO DE EJECUCI√ìN DEL PIPELINE ===
Timestamp: 2025-12-11 09:09:51
==================================================



********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: activemq-5.0.0 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: activemq-5.0.0
[1] Preprocesamiento - Dimensiones originales: (1884, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1884, 67)
[1] Preprocesamiento - Etiquetas √∫nicas en y: [0, 1]
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (1507, 66), X_test: (377, 66)
[1] Preprocesamiento - Distribuci√≥n y_train: {0: 0.8447246184472462, 1: 0.1552753815527538}
[1] Preprocesamiento - Distribuci√≥n y_test:  {0: 0.843501326259947, 1: 0.15649867374005305}
[1] Preprocesamiento - Archivos CSV guardados con √©xito en /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/01_preprocessing/activemq-5.0.0

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con activemq-5.0.0 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con activemq-5.0.0 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 1273
    Clase Minoritaria (1): 234
    Total de clases: 1507
    Ratio de desbalance: 5.44

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 753

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 520
[Minor√≠a] Tama√±o final (original + sint√©tico): 754

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 1507
    Distribuci√≥n clases: {1: 754, 0: 753}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con activemq-5.0.0 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 1273 muestras
    Clase minoritaria (1): 234 muestras
    Total de clases: 1507
    Ratio de desbalance: 5.44

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 753

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 519
[Minoritaria] Tama√±o final (original + sint√©tico): 753

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 1506
    Distribuci√≥n clases: {0: 753, 1: 753}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con activemq-5.0.0 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  1273
     Clase minoritaria (1):  234
     Total de clases:  1507
     Indice de desbalance:  5.44

[SMOTE] Clase mayoritaria (0): 1273 -> 753 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 753, 1: 753}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando activemq-5.0.0 con standard
[3] [unbalanced] Escalando activemq-5.0.0 con robust
[3] [csbboost] Escalando activemq-5.0.0 con standard
[3] [csbboost] Escalando activemq-5.0.0 con robust
[3] [hcbou] Escalando activemq-5.0.0 con standard
[3] [hcbou] Escalando activemq-5.0.0 con robust
[3] [smote] Escalando activemq-5.0.0 con standard
[3] [smote] Escalando activemq-5.0.0 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================
‚úì Etiquetas OK para activemq-5.0.0 | unbalanced | standard (positivos=234, negativos=1273)
‚úì Etiquetas OK para activemq-5.0.0 | unbalanced | robust (positivos=234, negativos=1273)
‚úì Etiquetas OK para activemq-5.0.0 | csbboost | standard (positivos=754, negativos=753)
‚úì Etiquetas OK para activemq-5.0.0 | csbboost | robust (positivos=754, negativos=753)
‚úì Etiquetas OK para activemq-5.0.0 | hcbou | standard (positivos=753, negativos=753)
‚úì Etiquetas OK para activemq-5.0.0 | hcbou | robust (positivos=753, negativos=753)
‚úì Etiquetas OK para activemq-5.0.0 | smote | standard (positivos=753, negativos=753)
‚úì Etiquetas OK para activemq-5.0.0 | smote | robust (positivos=753, negativos=753)

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: activemq-5.0.0
================================================================================

üìã Total de configuraciones: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado:   ['standard', 'robust']
   ‚Ä¢ Modelos por config:  3


********************************************************************************
[1/8] CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=activemq-5.0.0 | method=unbalanced | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1507, 65), X_test=(377, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/activemq-5.0.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/activemq-5.0.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=activemq-5.0.0 | method=unbalanced | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1507, 65), X_test=(377, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/activemq-5.0.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/activemq-5.0.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=activemq-5.0.0 | method=csbboost | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1507, 65), X_test=(377, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/activemq-5.0.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/activemq-5.0.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=activemq-5.0.0 | method=csbboost | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1507, 65), X_test=(377, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/activemq-5.0.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/activemq-5.0.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=activemq-5.0.0 | method=hcbou | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1506, 65), X_test=(377, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/activemq-5.0.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/activemq-5.0.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=activemq-5.0.0 | method=hcbou | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1506, 65), X_test=(377, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/activemq-5.0.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/activemq-5.0.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=activemq-5.0.0 | method=smote | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1506, 65), X_test=(377, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/activemq-5.0.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/activemq-5.0.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=activemq-5.0.0 | method=smote | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1506, 65), X_test=(377, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/activemq-5.0.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/activemq-5.0.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: activemq-5.0.0 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: activemq-5.0.0
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS - DATASET: activemq-5.0.0
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | unbalanced | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       297        21
            Buggy           30        29
      ====================================================
      TN=297  FP=21  FN=30  TP=29
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 29   TN: 297
         FP: 21   FN: 30

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1353
         Exactitud     = (TP + TN) / N   = 0.8647
         Accuracy      (sklearn)         = 0.8647

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4915
         FP-Rate                         = 0.0660

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5800
         Recall    = TP / P              = 0.4915

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4915
         Especificidad (TN/N)            = 0.9340

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7127
         BER (Balanced Error Rate)       = 0.2873

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4558

      ‚≠ê F1-Score:
         F1_Score                        = 0.5321

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5070

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       290        28
            Buggy           25        34
      ====================================================
      TN=290  FP=28  FN=25  TP=34
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 34   TN: 290
         FP: 28   FN: 25

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1406
         Exactitud     = (TP + TN) / N   = 0.8594
         Accuracy      (sklearn)         = 0.8594

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5763
         FP-Rate                         = 0.0881

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5484
         Recall    = TP / P              = 0.5763

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5763
         Especificidad (TN/N)            = 0.9119

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7441
         BER (Balanced Error Rate)       = 0.2559

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4785

      ‚≠ê F1-Score:
         F1_Score                        = 0.5620

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5705

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       293        25
            Buggy           19        40
      ====================================================
      TN=293  FP=25  FN=19  TP=40
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 40   TN: 293
         FP: 25   FN: 19

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1167
         Exactitud     = (TP + TN) / N   = 0.8833
         Accuracy      (sklearn)         = 0.8833

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6780
         FP-Rate                         = 0.0786

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6154
         Recall    = TP / P              = 0.6780

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6780
         Especificidad (TN/N)            = 0.9214

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7997
         BER (Balanced Error Rate)       = 0.2003

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5765

      ‚≠ê F1-Score:
         F1_Score                        = 0.6452

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6645

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | unbalanced | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         1       317
            Buggy            2        57
      ====================================================
      TN=1  FP=317  FN=2  TP=57
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 57   TN: 1
         FP: 317   FN: 2

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.8462
         Exactitud     = (TP + TN) / N   = 0.1538
         Accuracy      (sklearn)         = 0.1538

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.9661
         FP-Rate                         = 0.9969

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1524
         Recall    = TP / P              = 0.9661

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.9661
         Especificidad (TN/N)            = 0.0031

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.4846
         BER (Balanced Error Rate)       = 0.5154

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = -0.1258

      ‚≠ê F1-Score:
         F1_Score                        = 0.2633

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4672

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       287        31
            Buggy           25        34
      ====================================================
      TN=287  FP=31  FN=25  TP=34
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 34   TN: 287
         FP: 31   FN: 25

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1485
         Exactitud     = (TP + TN) / N   = 0.8515
         Accuracy      (sklearn)         = 0.8515

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5763
         FP-Rate                         = 0.0975

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5231
         Recall    = TP / P              = 0.5763

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5763
         Especificidad (TN/N)            = 0.9025

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7394
         BER (Balanced Error Rate)       = 0.2606

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4605

      ‚≠ê F1-Score:
         F1_Score                        = 0.5484

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5648

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       293        25
            Buggy           19        40
      ====================================================
      TN=293  FP=25  FN=19  TP=40
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 40   TN: 293
         FP: 25   FN: 19

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1167
         Exactitud     = (TP + TN) / N   = 0.8833
         Accuracy      (sklearn)         = 0.8833

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6780
         FP-Rate                         = 0.0786

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6154
         Recall    = TP / P              = 0.6780

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6780
         Especificidad (TN/N)            = 0.9214

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7997
         BER (Balanced Error Rate)       = 0.2003

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5765

      ‚≠ê F1-Score:
         F1_Score                        = 0.6452

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6645

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | csbboost | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       267        51
            Buggy           14        45
      ====================================================
      TN=267  FP=51  FN=14  TP=45
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 45   TN: 267
         FP: 51   FN: 14

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1724
         Exactitud     = (TP + TN) / N   = 0.8276
         Accuracy      (sklearn)         = 0.8276

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7627
         FP-Rate                         = 0.1604

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4688
         Recall    = TP / P              = 0.7627

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7627
         Especificidad (TN/N)            = 0.8396

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8012
         BER (Balanced Error Rate)       = 0.1988

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5023

      ‚≠ê F1-Score:
         F1_Score                        = 0.5806

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6777

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.04s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       283        35
            Buggy           24        35
      ====================================================
      TN=283  FP=35  FN=24  TP=35
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 35   TN: 283
         FP: 35   FN: 24

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1565
         Exactitud     = (TP + TN) / N   = 0.8435
         Accuracy      (sklearn)         = 0.8435

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5932
         FP-Rate                         = 0.1101

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5000
         Recall    = TP / P              = 0.5932

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5932
         Especificidad (TN/N)            = 0.8899

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7416
         BER (Balanced Error Rate)       = 0.2584

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4515

      ‚≠ê F1-Score:
         F1_Score                        = 0.5426

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5719

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       262        56
            Buggy           17        42
      ====================================================
      TN=262  FP=56  FN=17  TP=42
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 42   TN: 262
         FP: 56   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1936
         Exactitud     = (TP + TN) / N   = 0.8064
         Accuracy      (sklearn)         = 0.8064

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7119
         FP-Rate                         = 0.1761

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4286
         Recall    = TP / P              = 0.7119

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7119
         Especificidad (TN/N)            = 0.8239

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7679
         BER (Balanced Error Rate)       = 0.2321

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4438

      ‚≠ê F1-Score:
         F1_Score                        = 0.5350

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6287

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | csbboost | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       241        77
            Buggy            7        52
      ====================================================
      TN=241  FP=77  FN=7  TP=52
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 52   TN: 241
         FP: 77   FN: 7

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2228
         Exactitud     = (TP + TN) / N   = 0.7772
         Accuracy      (sklearn)         = 0.7772

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.8814
         FP-Rate                         = 0.2421

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4031
         Recall    = TP / P              = 0.8814

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.8814
         Especificidad (TN/N)            = 0.7579

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8196
         BER (Balanced Error Rate)       = 0.1804

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4895

      ‚≠ê F1-Score:
         F1_Score                        = 0.5532

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.7123

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.04s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         1       317
            Buggy            2        57
      ====================================================
      TN=1  FP=317  FN=2  TP=57
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 57   TN: 1
         FP: 317   FN: 2

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.8462
         Exactitud     = (TP + TN) / N   = 0.1538
         Accuracy      (sklearn)         = 0.1538

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.9661
         FP-Rate                         = 0.9969

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1524
         Recall    = TP / P              = 0.9661

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.9661
         Especificidad (TN/N)            = 0.0031

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.4846
         BER (Balanced Error Rate)       = 0.5154

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = -0.1258

      ‚≠ê F1-Score:
         F1_Score                        = 0.2633

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4672

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       263        55
            Buggy           17        42
      ====================================================
      TN=263  FP=55  FN=17  TP=42
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 42   TN: 263
         FP: 55   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1910
         Exactitud     = (TP + TN) / N   = 0.8090
         Accuracy      (sklearn)         = 0.8090

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7119
         FP-Rate                         = 0.1730

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4330
         Recall    = TP / P              = 0.7119

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7119
         Especificidad (TN/N)            = 0.8270

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7695
         BER (Balanced Error Rate)       = 0.2305

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4479

      ‚≠ê F1-Score:
         F1_Score                        = 0.5385

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6306

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | hcbou | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       270        48
            Buggy           17        42
      ====================================================
      TN=270  FP=48  FN=17  TP=42
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 42   TN: 270
         FP: 48   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1724
         Exactitud     = (TP + TN) / N   = 0.8276
         Accuracy      (sklearn)         = 0.8276

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7119
         FP-Rate                         = 0.1509

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4667
         Recall    = TP / P              = 0.7119

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7119
         Especificidad (TN/N)            = 0.8491

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7805
         BER (Balanced Error Rate)       = 0.2195

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4781

      ‚≠ê F1-Score:
         F1_Score                        = 0.5638

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6442

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.04s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       287        31
            Buggy           26        33
      ====================================================
      TN=287  FP=31  FN=26  TP=33
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 33   TN: 287
         FP: 31   FN: 26

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1512
         Exactitud     = (TP + TN) / N   = 0.8488
         Accuracy      (sklearn)         = 0.8488

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5593
         FP-Rate                         = 0.0975

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5156
         Recall    = TP / P              = 0.5593

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5593
         Especificidad (TN/N)            = 0.9025

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7309
         BER (Balanced Error Rate)       = 0.2691

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4470

      ‚≠ê F1-Score:
         F1_Score                        = 0.5366

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5500

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       272        46
            Buggy           17        42
      ====================================================
      TN=272  FP=46  FN=17  TP=42
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 42   TN: 272
         FP: 46   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1671
         Exactitud     = (TP + TN) / N   = 0.8329
         Accuracy      (sklearn)         = 0.8329

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7119
         FP-Rate                         = 0.1447

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4773
         Recall    = TP / P              = 0.7119

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7119
         Especificidad (TN/N)            = 0.8553

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7836
         BER (Balanced Error Rate)       = 0.2164

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4872

      ‚≠ê F1-Score:
         F1_Score                        = 0.5714

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6481

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | hcbou | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       255        63
            Buggy           20        39
      ====================================================
      TN=255  FP=63  FN=20  TP=39
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 39   TN: 255
         FP: 63   FN: 20

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2202
         Exactitud     = (TP + TN) / N   = 0.7798
         Accuracy      (sklearn)         = 0.7798

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6610
         FP-Rate                         = 0.1981

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3824
         Recall    = TP / P              = 0.6610

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6610
         Especificidad (TN/N)            = 0.8019

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7315
         BER (Balanced Error Rate)       = 0.2685

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3786

      ‚≠ê F1-Score:
         F1_Score                        = 0.4845

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5769

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.04s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         2       316
            Buggy            2        57
      ====================================================
      TN=2  FP=316  FN=2  TP=57
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 57   TN: 2
         FP: 316   FN: 2

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.8435
         Exactitud     = (TP + TN) / N   = 0.1565
         Accuracy      (sklearn)         = 0.1565

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.9661
         FP-Rate                         = 0.9937

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1528
         Recall    = TP / P              = 0.9661

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.9661
         Especificidad (TN/N)            = 0.0063

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.4862
         BER (Balanced Error Rate)       = 0.5138

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = -0.0979

      ‚≠ê F1-Score:
         F1_Score                        = 0.2639

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4680

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       272        46
            Buggy           17        42
      ====================================================
      TN=272  FP=46  FN=17  TP=42
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 42   TN: 272
         FP: 46   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1671
         Exactitud     = (TP + TN) / N   = 0.8329
         Accuracy      (sklearn)         = 0.8329

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7119
         FP-Rate                         = 0.1447

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4773
         Recall    = TP / P              = 0.7119

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7119
         Especificidad (TN/N)            = 0.8553

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7836
         BER (Balanced Error Rate)       = 0.2164

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4872

      ‚≠ê F1-Score:
         F1_Score                        = 0.5714

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6481

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | smote | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       267        51
            Buggy           17        42
      ====================================================
      TN=267  FP=51  FN=17  TP=42
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 42   TN: 267
         FP: 51   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1804
         Exactitud     = (TP + TN) / N   = 0.8196
         Accuracy      (sklearn)         = 0.8196

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7119
         FP-Rate                         = 0.1604

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4516
         Recall    = TP / P              = 0.7119

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7119
         Especificidad (TN/N)            = 0.8396

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7757
         BER (Balanced Error Rate)       = 0.2243

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4648

      ‚≠ê F1-Score:
         F1_Score                        = 0.5526

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6383

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       283        35
            Buggy           24        35
      ====================================================
      TN=283  FP=35  FN=24  TP=35
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 35   TN: 283
         FP: 35   FN: 24

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1565
         Exactitud     = (TP + TN) / N   = 0.8435
         Accuracy      (sklearn)         = 0.8435

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5932
         FP-Rate                         = 0.1101

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5000
         Recall    = TP / P              = 0.5932

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5932
         Especificidad (TN/N)            = 0.8899

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7416
         BER (Balanced Error Rate)       = 0.2584

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4515

      ‚≠ê F1-Score:
         F1_Score                        = 0.5426

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5719

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       270        48
            Buggy           15        44
      ====================================================
      TN=270  FP=48  FN=15  TP=44
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 44   TN: 270
         FP: 48   FN: 15

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1671
         Exactitud     = (TP + TN) / N   = 0.8329
         Accuracy      (sklearn)         = 0.8329

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7458
         FP-Rate                         = 0.1509

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4783
         Recall    = TP / P              = 0.7458

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7458
         Especificidad (TN/N)            = 0.8491

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7974
         BER (Balanced Error Rate)       = 0.2026

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5032

      ‚≠ê F1-Score:
         F1_Score                        = 0.5828

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6707

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | smote | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       255        63
            Buggy           17        42
      ====================================================
      TN=255  FP=63  FN=17  TP=42
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 42   TN: 255
         FP: 63   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2122
         Exactitud     = (TP + TN) / N   = 0.7878
         Accuracy      (sklearn)         = 0.7878

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7119
         FP-Rate                         = 0.1981

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4000
         Recall    = TP / P              = 0.7119

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7119
         Especificidad (TN/N)            = 0.8019

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7569
         BER (Balanced Error Rate)       = 0.2431

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4164

      ‚≠ê F1-Score:
         F1_Score                        = 0.5122

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6158

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.04s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       133       185
            Buggy            6        53
      ====================================================
      TN=133  FP=185  FN=6  TP=53
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 53   TN: 133
         FP: 185   FN: 6

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.5066
         Exactitud     = (TP + TN) / N   = 0.4934
         Accuracy      (sklearn)         = 0.4934

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.8983
         FP-Rate                         = 0.5818

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2227
         Recall    = TP / P              = 0.8983

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.8983
         Especificidad (TN/N)            = 0.4182

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6583
         BER (Balanced Error Rate)       = 0.3417

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2384

      ‚≠ê F1-Score:
         F1_Score                        = 0.3569

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5591

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       270        48
            Buggy           15        44
      ====================================================
      TN=270  FP=48  FN=15  TP=44
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 44   TN: 270
         FP: 48   FN: 15

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1671
         Exactitud     = (TP + TN) / N   = 0.8329
         Accuracy      (sklearn)         = 0.8329

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7458
         FP-Rate                         = 0.1509

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4783
         Recall    = TP / P              = 0.7458

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7458
         Especificidad (TN/N)            = 0.8491

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7974
         BER (Balanced Error Rate)       = 0.2026

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5032

      ‚≠ê F1-Score:
         F1_Score                        = 0.5828

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6707

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO FINAL
================================================================================

================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO - DATASET: activemq-5.0.0
================================================================================
  ‚úì Ranking completo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/activemq-5.0.0_full_ranking.csv
  ‚úì Mejor modelo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/activemq-5.0.0_best_model.json

  ‚ñ∫ MEJOR MODELO SELECCIONADO
     - Dataset           : activemq-5.0.0
     - Modelo            : naive_bayes_gaussian
     - Balanceo          : hcbou
     - Escalado          : robust
     - M√©tricas clave:
         Recall (Buggy)  : 0.9661
         F2_Score        : 0.4680
         Precision       : 0.1528
         F1_Score        : 0.2639
         MCC             : -0.0979
         BER (‚Üì mejor)   : 0.5138
         Exactitud       : 0.1565
         Error           : 0.8435
================================================================================


================================================================================
‚úì PIPELINE COMPLETO PARA activemq-5.0.0
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: derby-10.5.1.1 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: derby-10.5.1.1
[1] Preprocesamiento - Dimensiones originales: (2705, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (2705, 67)
[1] Preprocesamiento - Etiquetas √∫nicas en y: [0, 1]
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (2164, 66), X_test: (541, 66)
[1] Preprocesamiento - Distribuci√≥n y_train: {0: 0.8585951940850277, 1: 0.1414048059149723}
[1] Preprocesamiento - Distribuci√≥n y_test:  {0: 0.8576709796672828, 1: 0.1423290203327172}
[1] Preprocesamiento - Archivos CSV guardados con √©xito en /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/01_preprocessing/derby-10.5.1.1

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con derby-10.5.1.1 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con derby-10.5.1.1 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 1858
    Clase Minoritaria (1): 306
    Total de clases: 2164
    Ratio de desbalance: 6.07

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 1082

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 776
[Minor√≠a] Tama√±o final (original + sint√©tico): 1082

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 2164
    Distribuci√≥n clases: {0: 1082, 1: 1082}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con derby-10.5.1.1 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 1858 muestras
    Clase minoritaria (1): 306 muestras
    Total de clases: 2164
    Ratio de desbalance: 6.07

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 1082

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 776
[Minoritaria] Tama√±o final (original + sint√©tico): 1082

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 2164
    Distribuci√≥n clases: {0: 1082, 1: 1082}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con derby-10.5.1.1 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  1858
     Clase minoritaria (1):  306
     Total de clases:  2164
     Indice de desbalance:  6.07

[SMOTE] Clase mayoritaria (0): 1858 -> 1082 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 1082, 1: 1082}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando derby-10.5.1.1 con standard
[3] [unbalanced] Escalando derby-10.5.1.1 con robust
[3] [csbboost] Escalando derby-10.5.1.1 con standard
[3] [csbboost] Escalando derby-10.5.1.1 con robust
[3] [hcbou] Escalando derby-10.5.1.1 con standard
[3] [hcbou] Escalando derby-10.5.1.1 con robust
[3] [smote] Escalando derby-10.5.1.1 con standard
[3] [smote] Escalando derby-10.5.1.1 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================
‚úì Etiquetas OK para derby-10.5.1.1 | unbalanced | standard (positivos=306, negativos=1858)
‚úì Etiquetas OK para derby-10.5.1.1 | unbalanced | robust (positivos=306, negativos=1858)
‚úì Etiquetas OK para derby-10.5.1.1 | csbboost | standard (positivos=1082, negativos=1082)
‚úì Etiquetas OK para derby-10.5.1.1 | csbboost | robust (positivos=1082, negativos=1082)
‚úì Etiquetas OK para derby-10.5.1.1 | hcbou | standard (positivos=1082, negativos=1082)
‚úì Etiquetas OK para derby-10.5.1.1 | hcbou | robust (positivos=1082, negativos=1082)
‚úì Etiquetas OK para derby-10.5.1.1 | smote | standard (positivos=1082, negativos=1082)
‚úì Etiquetas OK para derby-10.5.1.1 | smote | robust (positivos=1082, negativos=1082)

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: derby-10.5.1.1
================================================================================

üìã Total de configuraciones: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado:   ['standard', 'robust']
   ‚Ä¢ Modelos por config:  3


********************************************************************************
[1/8] CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=derby-10.5.1.1 | method=unbalanced | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/derby-10.5.1.1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/derby-10.5.1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=derby-10.5.1.1 | method=unbalanced | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/derby-10.5.1.1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/derby-10.5.1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=derby-10.5.1.1 | method=csbboost | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/derby-10.5.1.1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/derby-10.5.1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=derby-10.5.1.1 | method=csbboost | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/derby-10.5.1.1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/derby-10.5.1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=derby-10.5.1.1 | method=hcbou | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/derby-10.5.1.1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/derby-10.5.1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=derby-10.5.1.1 | method=hcbou | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/derby-10.5.1.1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/derby-10.5.1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=derby-10.5.1.1 | method=smote | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/derby-10.5.1.1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/derby-10.5.1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=derby-10.5.1.1 | method=smote | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(2164, 65), X_test=(541, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/derby-10.5.1.1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/derby-10.5.1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: derby-10.5.1.1 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: derby-10.5.1.1
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS - DATASET: derby-10.5.1.1
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | unbalanced | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       431        33
            Buggy           50        27
      ====================================================
      TN=431  FP=33  FN=50  TP=27
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 27   TN: 431
         FP: 33   FN: 50

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1534
         Exactitud     = (TP + TN) / N   = 0.8466
         Accuracy      (sklearn)         = 0.8466

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3506
         FP-Rate                         = 0.0711

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4500
         Recall    = TP / P              = 0.3506

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3506
         Especificidad (TN/N)            = 0.9289

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6398
         BER (Balanced Error Rate)       = 0.3602

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3110

      ‚≠ê F1-Score:
         F1_Score                        = 0.3942

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3668

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.07s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       429        35
            Buggy           48        29
      ====================================================
      TN=429  FP=35  FN=48  TP=29
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 29   TN: 429
         FP: 35   FN: 48

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1534
         Exactitud     = (TP + TN) / N   = 0.8466
         Accuracy      (sklearn)         = 0.8466

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3766
         FP-Rate                         = 0.0754

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4531
         Recall    = TP / P              = 0.3766

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3766
         Especificidad (TN/N)            = 0.9246

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6506
         BER (Balanced Error Rate)       = 0.3494

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3258

      ‚≠ê F1-Score:
         F1_Score                        = 0.4113

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3898

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       430        34
            Buggy           45        32
      ====================================================
      TN=430  FP=34  FN=45  TP=32
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 32   TN: 430
         FP: 34   FN: 45

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1460
         Exactitud     = (TP + TN) / N   = 0.8540
         Accuracy      (sklearn)         = 0.8540

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4156
         FP-Rate                         = 0.0733

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4848
         Recall    = TP / P              = 0.4156

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4156
         Especificidad (TN/N)            = 0.9267

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6712
         BER (Balanced Error Rate)       = 0.3288

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3654

      ‚≠ê F1-Score:
         F1_Score                        = 0.4476

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4278

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | unbalanced | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       438        26
            Buggy           62        15
      ====================================================
      TN=438  FP=26  FN=62  TP=15
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 15   TN: 438
         FP: 26   FN: 62

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1627
         Exactitud     = (TP + TN) / N   = 0.8373
         Accuracy      (sklearn)         = 0.8373

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1948
         FP-Rate                         = 0.0560

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3659
         Recall    = TP / P              = 0.1948

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1948
         Especificidad (TN/N)            = 0.9440

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5694
         BER (Balanced Error Rate)       = 0.4306

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1832

      ‚≠ê F1-Score:
         F1_Score                        = 0.2542

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2149

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.07s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       457         7
            Buggy           74         3
      ====================================================
      TN=457  FP=7  FN=74  TP=3
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 3   TN: 457
         FP: 7   FN: 74

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1497
         Exactitud     = (TP + TN) / N   = 0.8503
         Accuracy      (sklearn)         = 0.8503

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.0390
         FP-Rate                         = 0.0151

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3000
         Recall    = TP / P              = 0.0390

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.0390
         Especificidad (TN/N)            = 0.9849

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5119
         BER (Balanced Error Rate)       = 0.4881

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.0619

      ‚≠ê F1-Score:
         F1_Score                        = 0.0690

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.0472

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       424        40
            Buggy           52        25
      ====================================================
      TN=424  FP=40  FN=52  TP=25
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 25   TN: 424
         FP: 40   FN: 52

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1701
         Exactitud     = (TP + TN) / N   = 0.8299
         Accuracy      (sklearn)         = 0.8299

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3247
         FP-Rate                         = 0.0862

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3846
         Recall    = TP / P              = 0.3247

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3247
         Especificidad (TN/N)            = 0.9138

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6192
         BER (Balanced Error Rate)       = 0.3808

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2563

      ‚≠ê F1-Score:
         F1_Score                        = 0.3521

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3351

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | csbboost | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       400        64
            Buggy           52        25
      ====================================================
      TN=400  FP=64  FN=52  TP=25
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 25   TN: 400
         FP: 64   FN: 52

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2144
         Exactitud     = (TP + TN) / N   = 0.7856
         Accuracy      (sklearn)         = 0.7856

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3247
         FP-Rate                         = 0.1379

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2809
         Recall    = TP / P              = 0.3247

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3247
         Especificidad (TN/N)            = 0.8621

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5934
         BER (Balanced Error Rate)       = 0.4066

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1760

      ‚≠ê F1-Score:
         F1_Score                        = 0.3012

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3149

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.08s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       425        39
            Buggy           43        34
      ====================================================
      TN=425  FP=39  FN=43  TP=34
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 34   TN: 425
         FP: 39   FN: 43

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1516
         Exactitud     = (TP + TN) / N   = 0.8484
         Accuracy      (sklearn)         = 0.8484

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4416
         FP-Rate                         = 0.0841

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4658
         Recall    = TP / P              = 0.4416

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4416
         Especificidad (TN/N)            = 0.9159

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6788
         BER (Balanced Error Rate)       = 0.3212

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3656

      ‚≠ê F1-Score:
         F1_Score                        = 0.4533

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4462

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       382        82
            Buggy           35        42
      ====================================================
      TN=382  FP=82  FN=35  TP=42
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 42   TN: 382
         FP: 82   FN: 35

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2163
         Exactitud     = (TP + TN) / N   = 0.7837
         Accuracy      (sklearn)         = 0.7837

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5455
         FP-Rate                         = 0.1767

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3387
         Recall    = TP / P              = 0.5455

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5455
         Especificidad (TN/N)            = 0.8233

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6844
         BER (Balanced Error Rate)       = 0.3156

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3065

      ‚≠ê F1-Score:
         F1_Score                        = 0.4179

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4861

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.04s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | csbboost | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       313       151
            Buggy           24        53
      ====================================================
      TN=313  FP=151  FN=24  TP=53
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 53   TN: 313
         FP: 151   FN: 24

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.3235
         Exactitud     = (TP + TN) / N   = 0.6765
         Accuracy      (sklearn)         = 0.6765

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6883
         FP-Rate                         = 0.3254

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2598
         Recall    = TP / P              = 0.6883

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6883
         Especificidad (TN/N)            = 0.6746

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6814
         BER (Balanced Error Rate)       = 0.3186

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2616

      ‚≠ê F1-Score:
         F1_Score                        = 0.3772

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5176

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.09s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       459         5
            Buggy           75         2
      ====================================================
      TN=459  FP=5  FN=75  TP=2
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 2   TN: 459
         FP: 5   FN: 75

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1479
         Exactitud     = (TP + TN) / N   = 0.8521
         Accuracy      (sklearn)         = 0.8521

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.0260
         FP-Rate                         = 0.0108

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2857
         Recall    = TP / P              = 0.0260

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.0260
         Especificidad (TN/N)            = 0.9892

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5076
         BER (Balanced Error Rate)       = 0.4924

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.0470

      ‚≠ê F1-Score:
         F1_Score                        = 0.0476

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.0317

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       380        84
            Buggy           34        43
      ====================================================
      TN=380  FP=84  FN=34  TP=43
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 43   TN: 380
         FP: 84   FN: 34

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2181
         Exactitud     = (TP + TN) / N   = 0.7819
         Accuracy      (sklearn)         = 0.7819

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5584
         FP-Rate                         = 0.1810

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3386
         Recall    = TP / P              = 0.5584

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5584
         Especificidad (TN/N)            = 0.8190

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6887
         BER (Balanced Error Rate)       = 0.3113

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3111

      ‚≠ê F1-Score:
         F1_Score                        = 0.4216

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4943

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.04s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | hcbou | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       363       101
            Buggy           29        48
      ====================================================
      TN=363  FP=101  FN=29  TP=48
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 48   TN: 363
         FP: 101   FN: 29

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2403
         Exactitud     = (TP + TN) / N   = 0.7597
         Accuracy      (sklearn)         = 0.7597

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6234
         FP-Rate                         = 0.2177

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3221
         Recall    = TP / P              = 0.6234

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6234
         Especificidad (TN/N)            = 0.7823

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7029
         BER (Balanced Error Rate)       = 0.2971

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3173

      ‚≠ê F1-Score:
         F1_Score                        = 0.4248

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5252

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.09s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       422        42
            Buggy           42        35
      ====================================================
      TN=422  FP=42  FN=42  TP=35
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 35   TN: 422
         FP: 42   FN: 42

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1553
         Exactitud     = (TP + TN) / N   = 0.8447
         Accuracy      (sklearn)         = 0.8447

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4545
         FP-Rate                         = 0.0905

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4545
         Recall    = TP / P              = 0.4545

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4545
         Especificidad (TN/N)            = 0.9095

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6820
         BER (Balanced Error Rate)       = 0.3180

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3640

      ‚≠ê F1-Score:
         F1_Score                        = 0.4545

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4545

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       349       115
            Buggy           32        45
      ====================================================
      TN=349  FP=115  FN=32  TP=45
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 45   TN: 349
         FP: 115   FN: 32

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2717
         Exactitud     = (TP + TN) / N   = 0.7283
         Accuracy      (sklearn)         = 0.7283

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5844
         FP-Rate                         = 0.2478

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2812
         Recall    = TP / P              = 0.5844

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5844
         Especificidad (TN/N)            = 0.7522

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6683
         BER (Balanced Error Rate)       = 0.3317

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2577

      ‚≠ê F1-Score:
         F1_Score                        = 0.3797

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4808

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | hcbou | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       296       168
            Buggy           21        56
      ====================================================
      TN=296  FP=168  FN=21  TP=56
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 56   TN: 296
         FP: 168   FN: 21

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.3494
         Exactitud     = (TP + TN) / N   = 0.6506
         Accuracy      (sklearn)         = 0.6506

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7273
         FP-Rate                         = 0.3621

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2500
         Recall    = TP / P              = 0.7273

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7273
         Especificidad (TN/N)            = 0.6379

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6826
         BER (Balanced Error Rate)       = 0.3174

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2591

      ‚≠ê F1-Score:
         F1_Score                        = 0.3721

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5263

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.09s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       460         4
            Buggy           74         3
      ====================================================
      TN=460  FP=4  FN=74  TP=3
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 3   TN: 460
         FP: 4   FN: 74

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1442
         Exactitud     = (TP + TN) / N   = 0.8558
         Accuracy      (sklearn)         = 0.8558

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.0390
         FP-Rate                         = 0.0086

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4286
         Recall    = TP / P              = 0.0390

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.0390
         Especificidad (TN/N)            = 0.9914

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5152
         BER (Balanced Error Rate)       = 0.4848

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.0938

      ‚≠ê F1-Score:
         F1_Score                        = 0.0714

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.0476

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       344       120
            Buggy           34        43
      ====================================================
      TN=344  FP=120  FN=34  TP=43
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 43   TN: 344
         FP: 120   FN: 34

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2847
         Exactitud     = (TP + TN) / N   = 0.7153
         Accuracy      (sklearn)         = 0.7153

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5584
         FP-Rate                         = 0.2586

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2638
         Recall    = TP / P              = 0.5584

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5584
         Especificidad (TN/N)            = 0.7414

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6499
         BER (Balanced Error Rate)       = 0.3501

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2283

      ‚≠ê F1-Score:
         F1_Score                        = 0.3583

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4565

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | smote | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       393        71
            Buggy           36        41
      ====================================================
      TN=393  FP=71  FN=36  TP=41
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 41   TN: 393
         FP: 71   FN: 36

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1978
         Exactitud     = (TP + TN) / N   = 0.8022
         Accuracy      (sklearn)         = 0.8022

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5325
         FP-Rate                         = 0.1530

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3661
         Recall    = TP / P              = 0.5325

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5325
         Especificidad (TN/N)            = 0.8470

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6897
         BER (Balanced Error Rate)       = 0.3103

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3272

      ‚≠ê F1-Score:
         F1_Score                        = 0.4339

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4881

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.07s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       421        43
            Buggy           43        34
      ====================================================
      TN=421  FP=43  FN=43  TP=34
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 34   TN: 421
         FP: 43   FN: 43

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1590
         Exactitud     = (TP + TN) / N   = 0.8410
         Accuracy      (sklearn)         = 0.8410

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4416
         FP-Rate                         = 0.0927

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4416
         Recall    = TP / P              = 0.4416

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4416
         Especificidad (TN/N)            = 0.9073

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6744
         BER (Balanced Error Rate)       = 0.3256

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3489

      ‚≠ê F1-Score:
         F1_Score                        = 0.4416

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4416

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       385        79
            Buggy           31        46
      ====================================================
      TN=385  FP=79  FN=31  TP=46
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 46   TN: 385
         FP: 79   FN: 31

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2033
         Exactitud     = (TP + TN) / N   = 0.7967
         Accuracy      (sklearn)         = 0.7967

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5974
         FP-Rate                         = 0.1703

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3680
         Recall    = TP / P              = 0.5974

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5974
         Especificidad (TN/N)            = 0.8297

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7136
         BER (Balanced Error Rate)       = 0.2864

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3541

      ‚≠ê F1-Score:
         F1_Score                        = 0.4554

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5312

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | smote | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       304       160
            Buggy           20        57
      ====================================================
      TN=304  FP=160  FN=20  TP=57
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 57   TN: 304
         FP: 160   FN: 20

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.3327
         Exactitud     = (TP + TN) / N   = 0.6673
         Accuracy      (sklearn)         = 0.6673

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7403
         FP-Rate                         = 0.3448

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2627
         Recall    = TP / P              = 0.7403

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7403
         Especificidad (TN/N)            = 0.6552

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6977
         BER (Balanced Error Rate)       = 0.3023

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2819

      ‚≠ê F1-Score:
         F1_Score                        = 0.3878

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5429

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.09s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       457         7
            Buggy           73         4
      ====================================================
      TN=457  FP=7  FN=73  TP=4
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 4   TN: 457
         FP: 7   FN: 73

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1479
         Exactitud     = (TP + TN) / N   = 0.8521
         Accuracy      (sklearn)         = 0.8521

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.0519
         FP-Rate                         = 0.0151

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3636
         Recall    = TP / P              = 0.0519

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.0519
         Especificidad (TN/N)            = 0.9849

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5184
         BER (Balanced Error Rate)       = 0.4816

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.0913

      ‚≠ê F1-Score:
         F1_Score                        = 0.0909

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.0627

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       386        78
            Buggy           31        46
      ====================================================
      TN=386  FP=78  FN=31  TP=46
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 46   TN: 386
         FP: 78   FN: 31

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2015
         Exactitud     = (TP + TN) / N   = 0.7985
         Accuracy      (sklearn)         = 0.7985

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5974
         FP-Rate                         = 0.1681

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3710
         Recall    = TP / P              = 0.5974

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5974
         Especificidad (TN/N)            = 0.8319

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7146
         BER (Balanced Error Rate)       = 0.2854

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3568

      ‚≠ê F1-Score:
         F1_Score                        = 0.4577

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5324

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s


================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO FINAL
================================================================================

================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO - DATASET: derby-10.5.1.1
================================================================================
  ‚úì Ranking completo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/derby-10.5.1.1_full_ranking.csv
  ‚úì Mejor modelo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/derby-10.5.1.1_best_model.json

  ‚ñ∫ MEJOR MODELO SELECCIONADO
     - Dataset           : derby-10.5.1.1
     - Modelo            : svm
     - Balanceo          : smote
     - Escalado          : robust
     - M√©tricas clave:
         Recall (Buggy)  : 0.7403
         F2_Score        : 0.5429
         Precision       : 0.2627
         F1_Score        : 0.3878
         MCC             : 0.2819
         BER (‚Üì mejor)   : 0.3023
         Exactitud       : 0.6673
         Error           : 0.3327
================================================================================


================================================================================
‚úì PIPELINE COMPLETO PARA derby-10.5.1.1
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: groovy-1_6_BETA_1 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: groovy-1_6_BETA_1
[1] Preprocesamiento - Dimensiones originales: (821, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (821, 67)
[1] Preprocesamiento - Etiquetas √∫nicas en y: [0, 1]
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (656, 66), X_test: (165, 66)
[1] Preprocesamiento - Distribuci√≥n y_train: {0: 0.9146341463414634, 1: 0.08536585365853659}
[1] Preprocesamiento - Distribuci√≥n y_test:  {0: 0.9151515151515152, 1: 0.08484848484848485}
[1] Preprocesamiento - Archivos CSV guardados con √©xito en /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/01_preprocessing/groovy-1_6_BETA_1

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con groovy-1_6_BETA_1 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con groovy-1_6_BETA_1 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 600
    Clase Minoritaria (1): 56
    Total de clases: 656
    Ratio de desbalance: 10.71

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 328

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 272
[Minor√≠a] Tama√±o final (original + sint√©tico): 328

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 656
    Distribuci√≥n clases: {0: 328, 1: 328}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con groovy-1_6_BETA_1 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 600 muestras
    Clase minoritaria (1): 56 muestras
    Total de clases: 656
    Ratio de desbalance: 10.71

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 328

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 272
[Minoritaria] Tama√±o final (original + sint√©tico): 328

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 656
    Distribuci√≥n clases: {0: 328, 1: 328}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con groovy-1_6_BETA_1 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  600
     Clase minoritaria (1):  56
     Total de clases:  656
     Indice de desbalance:  10.71

[SMOTE] Clase mayoritaria (0): 600 -> 328 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 328, 1: 328}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando groovy-1_6_BETA_1 con standard
[3] [unbalanced] Escalando groovy-1_6_BETA_1 con robust
[3] [csbboost] Escalando groovy-1_6_BETA_1 con standard
[3] [csbboost] Escalando groovy-1_6_BETA_1 con robust
[3] [hcbou] Escalando groovy-1_6_BETA_1 con standard
[3] [hcbou] Escalando groovy-1_6_BETA_1 con robust
[3] [smote] Escalando groovy-1_6_BETA_1 con standard
[3] [smote] Escalando groovy-1_6_BETA_1 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================
‚úì Etiquetas OK para groovy-1_6_BETA_1 | unbalanced | standard (positivos=56, negativos=600)
‚úì Etiquetas OK para groovy-1_6_BETA_1 | unbalanced | robust (positivos=56, negativos=600)
‚úì Etiquetas OK para groovy-1_6_BETA_1 | csbboost | standard (positivos=328, negativos=328)
‚úì Etiquetas OK para groovy-1_6_BETA_1 | csbboost | robust (positivos=328, negativos=328)
‚úì Etiquetas OK para groovy-1_6_BETA_1 | hcbou | standard (positivos=328, negativos=328)
‚úì Etiquetas OK para groovy-1_6_BETA_1 | hcbou | robust (positivos=328, negativos=328)
‚úì Etiquetas OK para groovy-1_6_BETA_1 | smote | standard (positivos=328, negativos=328)
‚úì Etiquetas OK para groovy-1_6_BETA_1 | smote | robust (positivos=328, negativos=328)

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: groovy-1_6_BETA_1
================================================================================

üìã Total de configuraciones: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado:   ['standard', 'robust']
   ‚Ä¢ Modelos por config:  3


********************************************************************************
[1/8] CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=groovy-1_6_BETA_1 | method=unbalanced | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/groovy-1_6_BETA_1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/groovy-1_6_BETA_1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=groovy-1_6_BETA_1 | method=unbalanced | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/groovy-1_6_BETA_1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/groovy-1_6_BETA_1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=groovy-1_6_BETA_1 | method=csbboost | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/groovy-1_6_BETA_1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/groovy-1_6_BETA_1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=groovy-1_6_BETA_1 | method=csbboost | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/groovy-1_6_BETA_1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/groovy-1_6_BETA_1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=groovy-1_6_BETA_1 | method=hcbou | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/groovy-1_6_BETA_1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/groovy-1_6_BETA_1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=groovy-1_6_BETA_1 | method=hcbou | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/groovy-1_6_BETA_1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/groovy-1_6_BETA_1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=groovy-1_6_BETA_1 | method=smote | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/groovy-1_6_BETA_1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/groovy-1_6_BETA_1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=groovy-1_6_BETA_1 | method=smote | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(656, 65), X_test=(165, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/groovy-1_6_BETA_1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/groovy-1_6_BETA_1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: groovy-1_6_BETA_1 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: groovy-1_6_BETA_1
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS - DATASET: groovy-1_6_BETA_1
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | unbalanced | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       144         7
            Buggy            9         5
      ====================================================
      TN=144  FP=7  FN=9  TP=5
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 5   TN: 144
         FP: 7   FN: 9

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0970
         Exactitud     = (TP + TN) / N   = 0.9030
         Accuracy      (sklearn)         = 0.9030

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3571
         FP-Rate                         = 0.0464

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4167
         Recall    = TP / P              = 0.3571

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3571
         Especificidad (TN/N)            = 0.9536

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6554
         BER (Balanced Error Rate)       = 0.3446

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3335

      ‚≠ê F1-Score:
         F1_Score                        = 0.3846

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3676

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       140        11
            Buggy           10         4
      ====================================================
      TN=140  FP=11  FN=10  TP=4
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 4   TN: 140
         FP: 11   FN: 10

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1273
         Exactitud     = (TP + TN) / N   = 0.8727
         Accuracy      (sklearn)         = 0.8727

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2857
         FP-Rate                         = 0.0728

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2667
         Recall    = TP / P              = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2857
         Especificidad (TN/N)            = 0.9272

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6064
         BER (Balanced Error Rate)       = 0.3936

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2063

      ‚≠ê F1-Score:
         F1_Score                        = 0.2759

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2817

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       142         9
            Buggy           10         4
      ====================================================
      TN=142  FP=9  FN=10  TP=4
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 4   TN: 142
         FP: 9   FN: 10

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1152
         Exactitud     = (TP + TN) / N   = 0.8848
         Accuracy      (sklearn)         = 0.8848

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2857
         FP-Rate                         = 0.0596

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3077
         Recall    = TP / P              = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2857
         Especificidad (TN/N)            = 0.9404

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6131
         BER (Balanced Error Rate)       = 0.3869

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2339

      ‚≠ê F1-Score:
         F1_Score                        = 0.2963

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2899

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | unbalanced | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       141        10
            Buggy           12         2
      ====================================================
      TN=141  FP=10  FN=12  TP=2
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 2   TN: 141
         FP: 10   FN: 12

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1333
         Exactitud     = (TP + TN) / N   = 0.8667
         Accuracy      (sklearn)         = 0.8667

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1429
         FP-Rate                         = 0.0662

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1667
         Recall    = TP / P              = 0.1429

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1429
         Especificidad (TN/N)            = 0.9338

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5383
         BER (Balanced Error Rate)       = 0.4617

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.0822

      ‚≠ê F1-Score:
         F1_Score                        = 0.1538

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.1471

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         0       151
            Buggy            1        13
      ====================================================
      TN=0  FP=151  FN=1  TP=13
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 13   TN: 0
         FP: 151   FN: 1

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.9212
         Exactitud     = (TP + TN) / N   = 0.0788
         Accuracy      (sklearn)         = 0.0788

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.9286
         FP-Rate                         = 1.0000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.0793
         Recall    = TP / P              = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.9286
         Especificidad (TN/N)            = 0.0000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.4643
         BER (Balanced Error Rate)       = 0.5357

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = -0.2564

      ‚≠ê F1-Score:
         F1_Score                        = 0.1461

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2955

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       142         9
            Buggy           10         4
      ====================================================
      TN=142  FP=9  FN=10  TP=4
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 4   TN: 142
         FP: 9   FN: 10

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1152
         Exactitud     = (TP + TN) / N   = 0.8848
         Accuracy      (sklearn)         = 0.8848

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2857
         FP-Rate                         = 0.0596

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3077
         Recall    = TP / P              = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2857
         Especificidad (TN/N)            = 0.9404

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6131
         BER (Balanced Error Rate)       = 0.3869

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2339

      ‚≠ê F1-Score:
         F1_Score                        = 0.2963

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2899

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | csbboost | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       139        12
            Buggy           10         4
      ====================================================
      TN=139  FP=12  FN=10  TP=4
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 4   TN: 139
         FP: 12   FN: 10

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1333
         Exactitud     = (TP + TN) / N   = 0.8667
         Accuracy      (sklearn)         = 0.8667

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2857
         FP-Rate                         = 0.0795

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2500
         Recall    = TP / P              = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2857
         Especificidad (TN/N)            = 0.9205

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6031
         BER (Balanced Error Rate)       = 0.3969

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1942

      ‚≠ê F1-Score:
         F1_Score                        = 0.2667

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2778

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       140        11
            Buggy           10         4
      ====================================================
      TN=140  FP=11  FN=10  TP=4
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 4   TN: 140
         FP: 11   FN: 10

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1273
         Exactitud     = (TP + TN) / N   = 0.8727
         Accuracy      (sklearn)         = 0.8727

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2857
         FP-Rate                         = 0.0728

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2667
         Recall    = TP / P              = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2857
         Especificidad (TN/N)            = 0.9272

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6064
         BER (Balanced Error Rate)       = 0.3936

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2063

      ‚≠ê F1-Score:
         F1_Score                        = 0.2759

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2817

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       132        19
            Buggy            5         9
      ====================================================
      TN=132  FP=19  FN=5  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 132
         FP: 19   FN: 5

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1455
         Exactitud     = (TP + TN) / N   = 0.8545
         Accuracy      (sklearn)         = 0.8545

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6429
         FP-Rate                         = 0.1258

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3214
         Recall    = TP / P              = 0.6429

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6429
         Especificidad (TN/N)            = 0.8742

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7585
         BER (Balanced Error Rate)       = 0.2415

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3838

      ‚≠ê F1-Score:
         F1_Score                        = 0.4286

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5357

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | csbboost | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       122        29
            Buggy            5         9
      ====================================================
      TN=122  FP=29  FN=5  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 122
         FP: 29   FN: 5

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2061
         Exactitud     = (TP + TN) / N   = 0.7939
         Accuracy      (sklearn)         = 0.7939

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6429
         FP-Rate                         = 0.1921

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2368
         Recall    = TP / P              = 0.6429

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6429
         Especificidad (TN/N)            = 0.8079

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7254
         BER (Balanced Error Rate)       = 0.2746

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2984

      ‚≠ê F1-Score:
         F1_Score                        = 0.3462

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4787

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         0       151
            Buggy            1        13
      ====================================================
      TN=0  FP=151  FN=1  TP=13
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 13   TN: 0
         FP: 151   FN: 1

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.9212
         Exactitud     = (TP + TN) / N   = 0.0788
         Accuracy      (sklearn)         = 0.0788

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.9286
         FP-Rate                         = 1.0000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.0793
         Recall    = TP / P              = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.9286
         Especificidad (TN/N)            = 0.0000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.4643
         BER (Balanced Error Rate)       = 0.5357

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = -0.2564

      ‚≠ê F1-Score:
         F1_Score                        = 0.1461

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2955

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       132        19
            Buggy            5         9
      ====================================================
      TN=132  FP=19  FN=5  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 132
         FP: 19   FN: 5

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1455
         Exactitud     = (TP + TN) / N   = 0.8545
         Accuracy      (sklearn)         = 0.8545

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6429
         FP-Rate                         = 0.1258

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3214
         Recall    = TP / P              = 0.6429

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6429
         Especificidad (TN/N)            = 0.8742

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7585
         BER (Balanced Error Rate)       = 0.2415

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3838

      ‚≠ê F1-Score:
         F1_Score                        = 0.4286

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5357

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | hcbou | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       137        14
            Buggy            7         7
      ====================================================
      TN=137  FP=14  FN=7  TP=7
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 7   TN: 137
         FP: 14   FN: 7

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1273
         Exactitud     = (TP + TN) / N   = 0.8727
         Accuracy      (sklearn)         = 0.8727

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5000
         FP-Rate                         = 0.0927

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3333
         Recall    = TP / P              = 0.5000

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5000
         Especificidad (TN/N)            = 0.9073

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7036
         BER (Balanced Error Rate)       = 0.2964

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3405

      ‚≠ê F1-Score:
         F1_Score                        = 0.4000

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4545

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy        93        58
            Buggy            4        10
      ====================================================
      TN=93  FP=58  FN=4  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 93
         FP: 58   FN: 4

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.3758
         Exactitud     = (TP + TN) / N   = 0.6242
         Accuracy      (sklearn)         = 0.6242

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7143
         FP-Rate                         = 0.3841

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1471
         Recall    = TP / P              = 0.7143

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7143
         Especificidad (TN/N)            = 0.6159

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6651
         BER (Balanced Error Rate)       = 0.3349

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1869

      ‚≠ê F1-Score:
         F1_Score                        = 0.2439

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4032

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       133        18
            Buggy            8         6
      ====================================================
      TN=133  FP=18  FN=8  TP=6
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 6   TN: 133
         FP: 18   FN: 8

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1576
         Exactitud     = (TP + TN) / N   = 0.8424
         Accuracy      (sklearn)         = 0.8424

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4286
         FP-Rate                         = 0.1192

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2500
         Recall    = TP / P              = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4286
         Especificidad (TN/N)            = 0.8808

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6547
         BER (Balanced Error Rate)       = 0.3453

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2445

      ‚≠ê F1-Score:
         F1_Score                        = 0.3158

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3750

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | hcbou | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       132        19
            Buggy            7         7
      ====================================================
      TN=132  FP=19  FN=7  TP=7
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 7   TN: 132
         FP: 19   FN: 7

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1576
         Exactitud     = (TP + TN) / N   = 0.8424
         Accuracy      (sklearn)         = 0.8424

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5000
         FP-Rate                         = 0.1258

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2692
         Recall    = TP / P              = 0.5000

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5000
         Especificidad (TN/N)            = 0.8742

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6871
         BER (Balanced Error Rate)       = 0.3129

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2862

      ‚≠ê F1-Score:
         F1_Score                        = 0.3500

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4268

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         0       151
            Buggy            1        13
      ====================================================
      TN=0  FP=151  FN=1  TP=13
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 13   TN: 0
         FP: 151   FN: 1

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.9212
         Exactitud     = (TP + TN) / N   = 0.0788
         Accuracy      (sklearn)         = 0.0788

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.9286
         FP-Rate                         = 1.0000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.0793
         Recall    = TP / P              = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.9286
         Especificidad (TN/N)            = 0.0000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.4643
         BER (Balanced Error Rate)       = 0.5357

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = -0.2564

      ‚≠ê F1-Score:
         F1_Score                        = 0.1461

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2955

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       133        18
            Buggy            8         6
      ====================================================
      TN=133  FP=18  FN=8  TP=6
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 6   TN: 133
         FP: 18   FN: 8

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1576
         Exactitud     = (TP + TN) / N   = 0.8424
         Accuracy      (sklearn)         = 0.8424

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4286
         FP-Rate                         = 0.1192

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2500
         Recall    = TP / P              = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4286
         Especificidad (TN/N)            = 0.8808

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6547
         BER (Balanced Error Rate)       = 0.3453

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2445

      ‚≠ê F1-Score:
         F1_Score                        = 0.3158

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3750

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | smote | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       146         5
            Buggy           10         4
      ====================================================
      TN=146  FP=5  FN=10  TP=4
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 4   TN: 146
         FP: 5   FN: 10

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0909
         Exactitud     = (TP + TN) / N   = 0.9091
         Accuracy      (sklearn)         = 0.9091

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2857
         FP-Rate                         = 0.0331

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4444
         Recall    = TP / P              = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2857
         Especificidad (TN/N)            = 0.9669

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6263
         BER (Balanced Error Rate)       = 0.3737

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3100

      ‚≠ê F1-Score:
         F1_Score                        = 0.3478

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3077

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-08}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       132        19
            Buggy            9         5
      ====================================================
      TN=132  FP=19  FN=9  TP=5
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 5   TN: 132
         FP: 19   FN: 9

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1697
         Exactitud     = (TP + TN) / N   = 0.8303
         Accuracy      (sklearn)         = 0.8303

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3571
         FP-Rate                         = 0.1258

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2083
         Recall    = TP / P              = 0.3571

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3571
         Especificidad (TN/N)            = 0.8742

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6157
         BER (Balanced Error Rate)       = 0.3843

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1828

      ‚≠ê F1-Score:
         F1_Score                        = 0.2632

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3125

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       136        15
            Buggy            8         6
      ====================================================
      TN=136  FP=15  FN=8  TP=6
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 6   TN: 136
         FP: 15   FN: 8

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1394
         Exactitud     = (TP + TN) / N   = 0.8606
         Accuracy      (sklearn)         = 0.8606

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4286
         FP-Rate                         = 0.0993

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2857
         Recall    = TP / P              = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4286
         Especificidad (TN/N)            = 0.9007

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6646
         BER (Balanced Error Rate)       = 0.3354

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2753

      ‚≠ê F1-Score:
         F1_Score                        = 0.3429

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3896

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | smote | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       138        13
            Buggy            8         6
      ====================================================
      TN=138  FP=13  FN=8  TP=6
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 6   TN: 138
         FP: 13   FN: 8

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1273
         Exactitud     = (TP + TN) / N   = 0.8727
         Accuracy      (sklearn)         = 0.8727

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4286
         FP-Rate                         = 0.0861

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3158
         Recall    = TP / P              = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4286
         Especificidad (TN/N)            = 0.9139

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6712
         BER (Balanced Error Rate)       = 0.3288

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2990

      ‚≠ê F1-Score:
         F1_Score                        = 0.3636

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4000

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-06}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         0       151
            Buggy            1        13
      ====================================================
      TN=0  FP=151  FN=1  TP=13
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 13   TN: 0
         FP: 151   FN: 1

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.9212
         Exactitud     = (TP + TN) / N   = 0.0788
         Accuracy      (sklearn)         = 0.0788

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.9286
         FP-Rate                         = 1.0000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.0793
         Recall    = TP / P              = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.9286
         Especificidad (TN/N)            = 0.0000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.4643
         BER (Balanced Error Rate)       = 0.5357

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = -0.2564

      ‚≠ê F1-Score:
         F1_Score                        = 0.1461

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2955

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       136        15
            Buggy            8         6
      ====================================================
      TN=136  FP=15  FN=8  TP=6
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 6   TN: 136
         FP: 15   FN: 8

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1394
         Exactitud     = (TP + TN) / N   = 0.8606
         Accuracy      (sklearn)         = 0.8606

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4286
         FP-Rate                         = 0.0993

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2857
         Recall    = TP / P              = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4286
         Especificidad (TN/N)            = 0.9007

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6646
         BER (Balanced Error Rate)       = 0.3354

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2753

      ‚≠ê F1-Score:
         F1_Score                        = 0.3429

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3896

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO FINAL
================================================================================

================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO - DATASET: groovy-1_6_BETA_1
================================================================================
  ‚úì Ranking completo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/groovy-1_6_BETA_1_full_ranking.csv
  ‚úì Mejor modelo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/groovy-1_6_BETA_1_best_model.json

  ‚ñ∫ MEJOR MODELO SELECCIONADO
     - Dataset           : groovy-1_6_BETA_1
     - Modelo            : naive_bayes_gaussian
     - Balanceo          : unbalanced
     - Escalado          : robust
     - M√©tricas clave:
         Recall (Buggy)  : 0.9286
         F2_Score        : 0.2955
         Precision       : 0.0793
         F1_Score        : 0.1461
         MCC             : -0.2564
         BER (‚Üì mejor)   : 0.5357
         Exactitud       : 0.0788
         Error           : 0.9212
================================================================================


================================================================================
‚úì PIPELINE COMPLETO PARA groovy-1_6_BETA_1
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: hbase-0.94.0 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: hbase-0.94.0
[1] Preprocesamiento - Dimensiones originales: (1059, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1059, 67)
[1] Preprocesamiento - Etiquetas √∫nicas en y: [0, 1]
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (847, 66), X_test: (212, 66)
[1] Preprocesamiento - Distribuci√≥n y_train: {0: 0.79456906729634, 1: 0.20543093270365997}
[1] Preprocesamiento - Distribuci√≥n y_test:  {0: 0.7924528301886793, 1: 0.20754716981132076}
[1] Preprocesamiento - Archivos CSV guardados con √©xito en /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/01_preprocessing/hbase-0.94.0

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con hbase-0.94.0 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con hbase-0.94.0 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 673
    Clase Minoritaria (1): 174
    Total de clases: 847
    Ratio de desbalance: 3.87

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 424

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 248
[Minor√≠a] Tama√±o final (original + sint√©tico): 422

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 846
    Distribuci√≥n clases: {0: 424, 1: 422}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con hbase-0.94.0 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 673 muestras
    Clase minoritaria (1): 174 muestras
    Total de clases: 847
    Ratio de desbalance: 3.87

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 423

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 249
[Minoritaria] Tama√±o final (original + sint√©tico): 423

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 846
    Distribuci√≥n clases: {0: 423, 1: 423}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con hbase-0.94.0 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  673
     Clase minoritaria (1):  174
     Total de clases:  847
     Indice de desbalance:  3.87

[SMOTE] Clase mayoritaria (0): 673 -> 423 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 423, 1: 423}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando hbase-0.94.0 con standard
[3] [unbalanced] Escalando hbase-0.94.0 con robust
[3] [csbboost] Escalando hbase-0.94.0 con standard
[3] [csbboost] Escalando hbase-0.94.0 con robust
[3] [hcbou] Escalando hbase-0.94.0 con standard
[3] [hcbou] Escalando hbase-0.94.0 con robust
[3] [smote] Escalando hbase-0.94.0 con standard
[3] [smote] Escalando hbase-0.94.0 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================
‚úì Etiquetas OK para hbase-0.94.0 | unbalanced | standard (positivos=174, negativos=673)
‚úì Etiquetas OK para hbase-0.94.0 | unbalanced | robust (positivos=174, negativos=673)
‚úì Etiquetas OK para hbase-0.94.0 | csbboost | standard (positivos=422, negativos=424)
‚úì Etiquetas OK para hbase-0.94.0 | csbboost | robust (positivos=422, negativos=424)
‚úì Etiquetas OK para hbase-0.94.0 | hcbou | standard (positivos=423, negativos=423)
‚úì Etiquetas OK para hbase-0.94.0 | hcbou | robust (positivos=423, negativos=423)
‚úì Etiquetas OK para hbase-0.94.0 | smote | standard (positivos=423, negativos=423)
‚úì Etiquetas OK para hbase-0.94.0 | smote | robust (positivos=423, negativos=423)

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: hbase-0.94.0
================================================================================

üìã Total de configuraciones: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado:   ['standard', 'robust']
   ‚Ä¢ Modelos por config:  3


********************************************************************************
[1/8] CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hbase-0.94.0 | method=unbalanced | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(847, 65), X_test=(212, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hbase-0.94.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hbase-0.94.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hbase-0.94.0 | method=unbalanced | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(847, 65), X_test=(212, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hbase-0.94.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hbase-0.94.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hbase-0.94.0 | method=csbboost | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hbase-0.94.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hbase-0.94.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hbase-0.94.0 | method=csbboost | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hbase-0.94.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hbase-0.94.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hbase-0.94.0 | method=hcbou | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hbase-0.94.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hbase-0.94.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hbase-0.94.0 | method=hcbou | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hbase-0.94.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hbase-0.94.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hbase-0.94.0 | method=smote | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hbase-0.94.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hbase-0.94.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hbase-0.94.0 | method=smote | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(846, 65), X_test=(212, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hbase-0.94.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hbase-0.94.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hbase-0.94.0 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: hbase-0.94.0
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS - DATASET: hbase-0.94.0
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | unbalanced | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       157        11
            Buggy           28        16
      ====================================================
      TN=157  FP=11  FN=28  TP=16
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 16   TN: 157
         FP: 11   FN: 28

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1840
         Exactitud     = (TP + TN) / N   = 0.8160
         Accuracy      (sklearn)         = 0.8160

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3636
         FP-Rate                         = 0.0655

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5926
         Recall    = TP / P              = 0.3636

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3636
         Especificidad (TN/N)            = 0.9345

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6491
         BER (Balanced Error Rate)       = 0.3509

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3627

      ‚≠ê F1-Score:
         F1_Score                        = 0.4507

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3941

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       137        31
            Buggy           19        25
      ====================================================
      TN=137  FP=31  FN=19  TP=25
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 25   TN: 137
         FP: 31   FN: 19

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2358
         Exactitud     = (TP + TN) / N   = 0.7642
         Accuracy      (sklearn)         = 0.7642

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5682
         FP-Rate                         = 0.1845

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4464
         Recall    = TP / P              = 0.5682

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5682
         Especificidad (TN/N)            = 0.8155

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6918
         BER (Balanced Error Rate)       = 0.3082

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3529

      ‚≠ê F1-Score:
         F1_Score                        = 0.5000

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5388

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       147        21
            Buggy           23        21
      ====================================================
      TN=147  FP=21  FN=23  TP=21
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 21   TN: 147
         FP: 21   FN: 23

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2075
         Exactitud     = (TP + TN) / N   = 0.7925
         Accuracy      (sklearn)         = 0.7925

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4773
         FP-Rate                         = 0.1250

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5000
         Recall    = TP / P              = 0.4773

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4773
         Especificidad (TN/N)            = 0.8750

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6761
         BER (Balanced Error Rate)       = 0.3239

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3584

      ‚≠ê F1-Score:
         F1_Score                        = 0.4884

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4817

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | unbalanced | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       168         0
            Buggy           44         0
      ====================================================
      TN=168  FP=0  FN=44  TP=0
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 0   TN: 168
         FP: 0   FN: 44

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2075
         Exactitud     = (TP + TN) / N   = 0.7925
         Accuracy      (sklearn)         = 0.7925

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.0000
         FP-Rate                         = 0.0000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.0000
         Recall    = TP / P              = 0.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.0000
         Especificidad (TN/N)            = 1.0000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5000
         BER (Balanced Error Rate)       = 0.5000

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.0000

      ‚≠ê F1-Score:
         F1_Score                        = 0.0000

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.0000

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         1       167
            Buggy            0        44
      ====================================================
      TN=1  FP=167  FN=0  TP=44
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 44   TN: 1
         FP: 167   FN: 0

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.7877
         Exactitud     = (TP + TN) / N   = 0.2123
         Accuracy      (sklearn)         = 0.2123

      üé≤ Tasas:
         TP-Rate (Recall)                = 1.0000
         FP-Rate                         = 0.9940

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2085
         Recall    = TP / P              = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 1.0000
         Especificidad (TN/N)            = 0.0060

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5030
         BER (Balanced Error Rate)       = 0.4970

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.0352

      ‚≠ê F1-Score:
         F1_Score                        = 0.3451

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5685

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       147        21
            Buggy           23        21
      ====================================================
      TN=147  FP=21  FN=23  TP=21
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 21   TN: 147
         FP: 21   FN: 23

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2075
         Exactitud     = (TP + TN) / N   = 0.7925
         Accuracy      (sklearn)         = 0.7925

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4773
         FP-Rate                         = 0.1250

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5000
         Recall    = TP / P              = 0.4773

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4773
         Especificidad (TN/N)            = 0.8750

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6761
         BER (Balanced Error Rate)       = 0.3239

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3584

      ‚≠ê F1-Score:
         F1_Score                        = 0.4884

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4817

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | csbboost | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       147        21
            Buggy           25        19
      ====================================================
      TN=147  FP=21  FN=25  TP=19
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 19   TN: 147
         FP: 21   FN: 25

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2170
         Exactitud     = (TP + TN) / N   = 0.7830
         Accuracy      (sklearn)         = 0.7830

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4318
         FP-Rate                         = 0.1250

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4750
         Recall    = TP / P              = 0.4318

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4318
         Especificidad (TN/N)            = 0.8750

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6534
         BER (Balanced Error Rate)       = 0.3466

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3180

      ‚≠ê F1-Score:
         F1_Score                        = 0.4524

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4398

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       136        32
            Buggy           23        21
      ====================================================
      TN=136  FP=32  FN=23  TP=21
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 21   TN: 136
         FP: 32   FN: 23

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2594
         Exactitud     = (TP + TN) / N   = 0.7406
         Accuracy      (sklearn)         = 0.7406

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4773
         FP-Rate                         = 0.1905

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3962
         Recall    = TP / P              = 0.4773

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4773
         Especificidad (TN/N)            = 0.8095

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6434
         BER (Balanced Error Rate)       = 0.3566

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2686

      ‚≠ê F1-Score:
         F1_Score                        = 0.4330

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4585

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       146        22
            Buggy           11        33
      ====================================================
      TN=146  FP=22  FN=11  TP=33
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 33   TN: 146
         FP: 22   FN: 11

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1557
         Exactitud     = (TP + TN) / N   = 0.8443
         Accuracy      (sklearn)         = 0.8443

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7500
         FP-Rate                         = 0.1310

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6000
         Recall    = TP / P              = 0.7500

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7500
         Especificidad (TN/N)            = 0.8690

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8095
         BER (Balanced Error Rate)       = 0.1905

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5728

      ‚≠ê F1-Score:
         F1_Score                        = 0.6667

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.7143

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | csbboost | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy        32       136
            Buggy            2        42
      ====================================================
      TN=32  FP=136  FN=2  TP=42
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 42   TN: 32
         FP: 136   FN: 2

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.6509
         Exactitud     = (TP + TN) / N   = 0.3491
         Accuracy      (sklearn)         = 0.3491

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.9545
         FP-Rate                         = 0.8095

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2360
         Recall    = TP / P              = 0.9545

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.9545
         Especificidad (TN/N)            = 0.1905

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5725
         BER (Balanced Error Rate)       = 0.4275

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1603

      ‚≠ê F1-Score:
         F1_Score                        = 0.3784

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5932

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         2       166
            Buggy            1        43
      ====================================================
      TN=2  FP=166  FN=1  TP=43
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 43   TN: 2
         FP: 166   FN: 1

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.7877
         Exactitud     = (TP + TN) / N   = 0.2123
         Accuracy      (sklearn)         = 0.2123

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.9773
         FP-Rate                         = 0.9881

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2057
         Recall    = TP / P              = 0.9773

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.9773
         Especificidad (TN/N)            = 0.0119

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.4946
         BER (Balanced Error Rate)       = 0.5054

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = -0.0372

      ‚≠ê F1-Score:
         F1_Score                        = 0.3399

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5584

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       148        20
            Buggy           11        33
      ====================================================
      TN=148  FP=20  FN=11  TP=33
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 33   TN: 148
         FP: 20   FN: 11

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1462
         Exactitud     = (TP + TN) / N   = 0.8538
         Accuracy      (sklearn)         = 0.8538

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7500
         FP-Rate                         = 0.1190

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6226
         Recall    = TP / P              = 0.7500

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7500
         Especificidad (TN/N)            = 0.8810

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8155
         BER (Balanced Error Rate)       = 0.1845

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5909

      ‚≠ê F1-Score:
         F1_Score                        = 0.6804

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.7205

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | hcbou | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       149        19
            Buggy           17        27
      ====================================================
      TN=149  FP=19  FN=17  TP=27
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 27   TN: 149
         FP: 19   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1698
         Exactitud     = (TP + TN) / N   = 0.8302
         Accuracy      (sklearn)         = 0.8302

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6136
         FP-Rate                         = 0.1131

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5870
         Recall    = TP / P              = 0.6136

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6136
         Especificidad (TN/N)            = 0.8869

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7503
         BER (Balanced Error Rate)       = 0.2497

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4925

      ‚≠ê F1-Score:
         F1_Score                        = 0.6000

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6081

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       130        38
            Buggy           12        32
      ====================================================
      TN=130  FP=38  FN=12  TP=32
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 32   TN: 130
         FP: 38   FN: 12

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2358
         Exactitud     = (TP + TN) / N   = 0.7642
         Accuracy      (sklearn)         = 0.7642

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7273
         FP-Rate                         = 0.2262

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4571
         Recall    = TP / P              = 0.7273

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7273
         Especificidad (TN/N)            = 0.7738

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7505
         BER (Balanced Error Rate)       = 0.2495

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4321

      ‚≠ê F1-Score:
         F1_Score                        = 0.5614

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6504

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       134        34
            Buggy           19        25
      ====================================================
      TN=134  FP=34  FN=19  TP=25
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 25   TN: 134
         FP: 34   FN: 19

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2500
         Exactitud     = (TP + TN) / N   = 0.7500
         Accuracy      (sklearn)         = 0.7500

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5682
         FP-Rate                         = 0.2024

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4237
         Recall    = TP / P              = 0.5682

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5682
         Especificidad (TN/N)            = 0.7976

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6829
         BER (Balanced Error Rate)       = 0.3171

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3310

      ‚≠ê F1-Score:
         F1_Score                        = 0.4854

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5319

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | hcbou | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       133        35
            Buggy           13        31
      ====================================================
      TN=133  FP=35  FN=13  TP=31
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 31   TN: 133
         FP: 35   FN: 13

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2264
         Exactitud     = (TP + TN) / N   = 0.7736
         Accuracy      (sklearn)         = 0.7736

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7045
         FP-Rate                         = 0.2083

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4697
         Recall    = TP / P              = 0.7045

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7045
         Especificidad (TN/N)            = 0.7917

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7481
         BER (Balanced Error Rate)       = 0.2519

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4346

      ‚≠ê F1-Score:
         F1_Score                        = 0.5636

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6405

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         1       167
            Buggy            0        44
      ====================================================
      TN=1  FP=167  FN=0  TP=44
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 44   TN: 1
         FP: 167   FN: 0

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.7877
         Exactitud     = (TP + TN) / N   = 0.2123
         Accuracy      (sklearn)         = 0.2123

      üé≤ Tasas:
         TP-Rate (Recall)                = 1.0000
         FP-Rate                         = 0.9940

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2085
         Recall    = TP / P              = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 1.0000
         Especificidad (TN/N)            = 0.0060

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5030
         BER (Balanced Error Rate)       = 0.4970

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.0352

      ‚≠ê F1-Score:
         F1_Score                        = 0.3451

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5685

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       135        33
            Buggy           19        25
      ====================================================
      TN=135  FP=33  FN=19  TP=25
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 25   TN: 135
         FP: 33   FN: 19

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2453
         Exactitud     = (TP + TN) / N   = 0.7547
         Accuracy      (sklearn)         = 0.7547

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5682
         FP-Rate                         = 0.1964

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4310
         Recall    = TP / P              = 0.5682

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5682
         Especificidad (TN/N)            = 0.8036

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6859
         BER (Balanced Error Rate)       = 0.3141

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3382

      ‚≠ê F1-Score:
         F1_Score                        = 0.4902

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5342

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | smote | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       139        29
            Buggy           22        22
      ====================================================
      TN=139  FP=29  FN=22  TP=22
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 22   TN: 139
         FP: 29   FN: 22

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2406
         Exactitud     = (TP + TN) / N   = 0.7594
         Accuracy      (sklearn)         = 0.7594

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5000
         FP-Rate                         = 0.1726

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4314
         Recall    = TP / P              = 0.5000

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5000
         Especificidad (TN/N)            = 0.8274

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6637
         BER (Balanced Error Rate)       = 0.3363

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3106

      ‚≠ê F1-Score:
         F1_Score                        = 0.4632

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4846

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       140        28
            Buggy           24        20
      ====================================================
      TN=140  FP=28  FN=24  TP=20
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 20   TN: 140
         FP: 28   FN: 24

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2453
         Exactitud     = (TP + TN) / N   = 0.7547
         Accuracy      (sklearn)         = 0.7547

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4545
         FP-Rate                         = 0.1667

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4167
         Recall    = TP / P              = 0.4545

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4545
         Especificidad (TN/N)            = 0.8333

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6439
         BER (Balanced Error Rate)       = 0.3561

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2790

      ‚≠ê F1-Score:
         F1_Score                        = 0.4348

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4464

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       137        31
            Buggy           11        33
      ====================================================
      TN=137  FP=31  FN=11  TP=33
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 33   TN: 137
         FP: 31   FN: 11

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1981
         Exactitud     = (TP + TN) / N   = 0.8019
         Accuracy      (sklearn)         = 0.8019

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7500
         FP-Rate                         = 0.1845

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5156
         Recall    = TP / P              = 0.7500

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7500
         Especificidad (TN/N)            = 0.8155

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7827
         BER (Balanced Error Rate)       = 0.2173

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4995

      ‚≠ê F1-Score:
         F1_Score                        = 0.6111

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6875

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | smote | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       111        57
            Buggy            9        35
      ====================================================
      TN=111  FP=57  FN=9  TP=35
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 35   TN: 111
         FP: 57   FN: 9

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.3113
         Exactitud     = (TP + TN) / N   = 0.6887
         Accuracy      (sklearn)         = 0.6887

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7955
         FP-Rate                         = 0.3393

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3804
         Recall    = TP / P              = 0.7955

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7955
         Especificidad (TN/N)            = 0.6607

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7281
         BER (Balanced Error Rate)       = 0.2719

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3733

      ‚≠ê F1-Score:
         F1_Score                        = 0.5147

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6530

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy         1       167
            Buggy            0        44
      ====================================================
      TN=1  FP=167  FN=0  TP=44
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 44   TN: 1
         FP: 167   FN: 0

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.7877
         Exactitud     = (TP + TN) / N   = 0.2123
         Accuracy      (sklearn)         = 0.2123

      üé≤ Tasas:
         TP-Rate (Recall)                = 1.0000
         FP-Rate                         = 0.9940

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2085
         Recall    = TP / P              = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 1.0000
         Especificidad (TN/N)            = 0.0060

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5030
         BER (Balanced Error Rate)       = 0.4970

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.0352

      ‚≠ê F1-Score:
         F1_Score                        = 0.3451

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5685

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       137        31
            Buggy           11        33
      ====================================================
      TN=137  FP=31  FN=11  TP=33
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 33   TN: 137
         FP: 31   FN: 11

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1981
         Exactitud     = (TP + TN) / N   = 0.8019
         Accuracy      (sklearn)         = 0.8019

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7500
         FP-Rate                         = 0.1845

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5156
         Recall    = TP / P              = 0.7500

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7500
         Especificidad (TN/N)            = 0.8155

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7827
         BER (Balanced Error Rate)       = 0.2173

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4995

      ‚≠ê F1-Score:
         F1_Score                        = 0.6111

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6875

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO FINAL
================================================================================

================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO - DATASET: hbase-0.94.0
================================================================================
  ‚úì Ranking completo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/hbase-0.94.0_full_ranking.csv
  ‚úì Mejor modelo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/hbase-0.94.0_best_model.json

  ‚ñ∫ MEJOR MODELO SELECCIONADO
     - Dataset           : hbase-0.94.0
     - Modelo            : naive_bayes_gaussian
     - Balanceo          : unbalanced
     - Escalado          : robust
     - M√©tricas clave:
         Recall (Buggy)  : 1.0000
         F2_Score        : 0.5685
         Precision       : 0.2085
         F1_Score        : 0.3451
         MCC             : 0.0352
         BER (‚Üì mejor)   : 0.4970
         Exactitud       : 0.2123
         Error           : 0.7877
================================================================================


================================================================================
‚úì PIPELINE COMPLETO PARA hbase-0.94.0
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: hive-0.9.0 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: hive-0.9.0
[1] Preprocesamiento - Dimensiones originales: (1416, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1416, 67)
[1] Preprocesamiento - Etiquetas √∫nicas en y: [0, 1]
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (1132, 66), X_test: (284, 66)
[1] Preprocesamiento - Distribuci√≥n y_train: {0: 0.8003533568904594, 1: 0.19964664310954064}
[1] Preprocesamiento - Distribuci√≥n y_test:  {0: 0.7992957746478874, 1: 0.2007042253521127}
[1] Preprocesamiento - Archivos CSV guardados con √©xito en /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/01_preprocessing/hive-0.9.0

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con hive-0.9.0 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con hive-0.9.0 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 906
    Clase Minoritaria (1): 226
    Total de clases: 1132
    Ratio de desbalance: 4.01

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 566

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 3
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 339
[Minor√≠a] Tama√±o final (original + sint√©tico): 565

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 1131
    Distribuci√≥n clases: {0: 566, 1: 565}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con hive-0.9.0 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 906 muestras
    Clase minoritaria (1): 226 muestras
    Total de clases: 1132
    Ratio de desbalance: 4.01

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 566

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 340
[Minoritaria] Tama√±o final (original + sint√©tico): 566

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 1132
    Distribuci√≥n clases: {0: 566, 1: 566}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con hive-0.9.0 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  906
     Clase minoritaria (1):  226
     Total de clases:  1132
     Indice de desbalance:  4.01

[SMOTE] Clase mayoritaria (0): 906 -> 566 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 566, 1: 566}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando hive-0.9.0 con standard
[3] [unbalanced] Escalando hive-0.9.0 con robust
[3] [csbboost] Escalando hive-0.9.0 con standard
[3] [csbboost] Escalando hive-0.9.0 con robust
[3] [hcbou] Escalando hive-0.9.0 con standard
[3] [hcbou] Escalando hive-0.9.0 con robust
[3] [smote] Escalando hive-0.9.0 con standard
[3] [smote] Escalando hive-0.9.0 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================
‚úì Etiquetas OK para hive-0.9.0 | unbalanced | standard (positivos=226, negativos=906)
‚úì Etiquetas OK para hive-0.9.0 | unbalanced | robust (positivos=226, negativos=906)
‚úì Etiquetas OK para hive-0.9.0 | csbboost | standard (positivos=565, negativos=566)
‚úì Etiquetas OK para hive-0.9.0 | csbboost | robust (positivos=565, negativos=566)
‚úì Etiquetas OK para hive-0.9.0 | hcbou | standard (positivos=566, negativos=566)
‚úì Etiquetas OK para hive-0.9.0 | hcbou | robust (positivos=566, negativos=566)
‚úì Etiquetas OK para hive-0.9.0 | smote | standard (positivos=566, negativos=566)
‚úì Etiquetas OK para hive-0.9.0 | smote | robust (positivos=566, negativos=566)

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: hive-0.9.0
================================================================================

üìã Total de configuraciones: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado:   ['standard', 'robust']
   ‚Ä¢ Modelos por config:  3


********************************************************************************
[1/8] CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hive-0.9.0 | method=unbalanced | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hive-0.9.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hive-0.9.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hive-0.9.0 | method=unbalanced | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hive-0.9.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/hive-0.9.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hive-0.9.0 | method=csbboost | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1131, 65), X_test=(284, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hive-0.9.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hive-0.9.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hive-0.9.0 | method=csbboost | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1131, 65), X_test=(284, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hive-0.9.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/hive-0.9.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hive-0.9.0 | method=hcbou | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hive-0.9.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hive-0.9.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hive-0.9.0 | method=hcbou | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hive-0.9.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/hive-0.9.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hive-0.9.0 | method=smote | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hive-0.9.0/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hive-0.9.0/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=hive-0.9.0 | method=smote | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1132, 65), X_test=(284, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hive-0.9.0/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/hive-0.9.0/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: hive-0.9.0 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: hive-0.9.0
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS - DATASET: hive-0.9.0
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | unbalanced | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       210        17
            Buggy           30        27
      ====================================================
      TN=210  FP=17  FN=30  TP=27
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 27   TN: 210
         FP: 17   FN: 30

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1655
         Exactitud     = (TP + TN) / N   = 0.8345
         Accuracy      (sklearn)         = 0.8345

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4737
         FP-Rate                         = 0.0749

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6136
         Recall    = TP / P              = 0.4737

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4737
         Especificidad (TN/N)            = 0.9251

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6994
         BER (Balanced Error Rate)       = 0.3006

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4414

      ‚≠ê F1-Score:
         F1_Score                        = 0.5347

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4963

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       222         5
            Buggy           42        15
      ====================================================
      TN=222  FP=5  FN=42  TP=15
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 15   TN: 222
         FP: 5   FN: 42

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1655
         Exactitud     = (TP + TN) / N   = 0.8345
         Accuracy      (sklearn)         = 0.8345

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2632
         FP-Rate                         = 0.0220

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.7500
         Recall    = TP / P              = 0.2632

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2632
         Especificidad (TN/N)            = 0.9780

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6206
         BER (Balanced Error Rate)       = 0.3794

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3775

      ‚≠ê F1-Score:
         F1_Score                        = 0.3896

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3024

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       202        25
            Buggy           21        36
      ====================================================
      TN=202  FP=25  FN=21  TP=36
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 36   TN: 202
         FP: 25   FN: 21

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1620
         Exactitud     = (TP + TN) / N   = 0.8380
         Accuracy      (sklearn)         = 0.8380

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6316
         FP-Rate                         = 0.1101

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5902
         Recall    = TP / P              = 0.6316

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6316
         Especificidad (TN/N)            = 0.8899

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7607
         BER (Balanced Error Rate)       = 0.2393

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5086

      ‚≠ê F1-Score:
         F1_Score                        = 0.6102

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6228

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | unbalanced | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       215        12
            Buggy           28        29
      ====================================================
      TN=215  FP=12  FN=28  TP=29
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 29   TN: 215
         FP: 12   FN: 28

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1408
         Exactitud     = (TP + TN) / N   = 0.8592
         Accuracy      (sklearn)         = 0.8592

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5088
         FP-Rate                         = 0.0529

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.7073
         Recall    = TP / P              = 0.5088

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5088
         Especificidad (TN/N)            = 0.9471

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7280
         BER (Balanced Error Rate)       = 0.2720

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5196

      ‚≠ê F1-Score:
         F1_Score                        = 0.5918

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5390

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-08}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       223         4
            Buggy           51         6
      ====================================================
      TN=223  FP=4  FN=51  TP=6
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 6   TN: 223
         FP: 4   FN: 51

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1937
         Exactitud     = (TP + TN) / N   = 0.8063
         Accuracy      (sklearn)         = 0.8063

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1053
         FP-Rate                         = 0.0176

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6000
         Recall    = TP / P              = 0.1053

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1053
         Especificidad (TN/N)            = 0.9824

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5438
         BER (Balanced Error Rate)       = 0.4562

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1905

      ‚≠ê F1-Score:
         F1_Score                        = 0.1791

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.1261

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       202        25
            Buggy           21        36
      ====================================================
      TN=202  FP=25  FN=21  TP=36
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 36   TN: 202
         FP: 25   FN: 21

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1620
         Exactitud     = (TP + TN) / N   = 0.8380
         Accuracy      (sklearn)         = 0.8380

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6316
         FP-Rate                         = 0.1101

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5902
         Recall    = TP / P              = 0.6316

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6316
         Especificidad (TN/N)            = 0.8899

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7607
         BER (Balanced Error Rate)       = 0.2393

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5086

      ‚≠ê F1-Score:
         F1_Score                        = 0.6102

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6228

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | csbboost | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       193        34
            Buggy           27        30
      ====================================================
      TN=193  FP=34  FN=27  TP=30
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 30   TN: 193
         FP: 34   FN: 27

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2148
         Exactitud     = (TP + TN) / N   = 0.7852
         Accuracy      (sklearn)         = 0.7852

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5263
         FP-Rate                         = 0.1498

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4688
         Recall    = TP / P              = 0.5263

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5263
         Especificidad (TN/N)            = 0.8502

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6883
         BER (Balanced Error Rate)       = 0.3117

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3610

      ‚≠ê F1-Score:
         F1_Score                        = 0.4959

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5137

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       220         7
            Buggy           42        15
      ====================================================
      TN=220  FP=7  FN=42  TP=15
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 15   TN: 220
         FP: 7   FN: 42

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1725
         Exactitud     = (TP + TN) / N   = 0.8275
         Accuracy      (sklearn)         = 0.8275

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2632
         FP-Rate                         = 0.0308

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6818
         Recall    = TP / P              = 0.2632

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2632
         Especificidad (TN/N)            = 0.9692

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6162
         BER (Balanced Error Rate)       = 0.3838

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3481

      ‚≠ê F1-Score:
         F1_Score                        = 0.3797

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3000

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       189        38
            Buggy            9        48
      ====================================================
      TN=189  FP=38  FN=9  TP=48
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 48   TN: 189
         FP: 38   FN: 9

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1655
         Exactitud     = (TP + TN) / N   = 0.8345
         Accuracy      (sklearn)         = 0.8345

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.8421
         FP-Rate                         = 0.1674

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5581
         Recall    = TP / P              = 0.8421

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.8421
         Especificidad (TN/N)            = 0.8326

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8374
         BER (Balanced Error Rate)       = 0.1626

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5881

      ‚≠ê F1-Score:
         F1_Score                        = 0.6713

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.7643

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | csbboost | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       168        59
            Buggy           14        43
      ====================================================
      TN=168  FP=59  FN=14  TP=43
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 43   TN: 168
         FP: 59   FN: 14

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2570
         Exactitud     = (TP + TN) / N   = 0.7430
         Accuracy      (sklearn)         = 0.7430

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7544
         FP-Rate                         = 0.2599

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4216
         Recall    = TP / P              = 0.7544

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7544
         Especificidad (TN/N)            = 0.7401

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7472
         BER (Balanced Error Rate)       = 0.2528

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4128

      ‚≠ê F1-Score:
         F1_Score                        = 0.5409

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6515

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       223         4
            Buggy           48         9
      ====================================================
      TN=223  FP=4  FN=48  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 223
         FP: 4   FN: 48

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1831
         Exactitud     = (TP + TN) / N   = 0.8169
         Accuracy      (sklearn)         = 0.8169

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1579
         FP-Rate                         = 0.0176

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6923
         Recall    = TP / P              = 0.1579

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1579
         Especificidad (TN/N)            = 0.9824

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5701
         BER (Balanced Error Rate)       = 0.4299

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2688

      ‚≠ê F1-Score:
         F1_Score                        = 0.2571

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.1867

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       189        38
            Buggy            9        48
      ====================================================
      TN=189  FP=38  FN=9  TP=48
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 48   TN: 189
         FP: 38   FN: 9

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1655
         Exactitud     = (TP + TN) / N   = 0.8345
         Accuracy      (sklearn)         = 0.8345

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.8421
         FP-Rate                         = 0.1674

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5581
         Recall    = TP / P              = 0.8421

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.8421
         Especificidad (TN/N)            = 0.8326

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8374
         BER (Balanced Error Rate)       = 0.1626

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5881

      ‚≠ê F1-Score:
         F1_Score                        = 0.6713

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.7643

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | hcbou | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       201        26
            Buggy           28        29
      ====================================================
      TN=201  FP=26  FN=28  TP=29
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 29   TN: 201
         FP: 26   FN: 28

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1901
         Exactitud     = (TP + TN) / N   = 0.8099
         Accuracy      (sklearn)         = 0.8099

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5088
         FP-Rate                         = 0.1145

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5273
         Recall    = TP / P              = 0.5088

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5088
         Especificidad (TN/N)            = 0.8855

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6971
         BER (Balanced Error Rate)       = 0.3029

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3996

      ‚≠ê F1-Score:
         F1_Score                        = 0.5179

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5124

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       223         4
            Buggy           43        14
      ====================================================
      TN=223  FP=4  FN=43  TP=14
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 14   TN: 223
         FP: 4   FN: 43

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1655
         Exactitud     = (TP + TN) / N   = 0.8345
         Accuracy      (sklearn)         = 0.8345

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2456
         FP-Rate                         = 0.0176

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.7778
         Recall    = TP / P              = 0.2456

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2456
         Especificidad (TN/N)            = 0.9824

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6140
         BER (Balanced Error Rate)       = 0.3860

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3748

      ‚≠ê F1-Score:
         F1_Score                        = 0.3733

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2846

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       175        52
            Buggy           16        41
      ====================================================
      TN=175  FP=52  FN=16  TP=41
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 41   TN: 175
         FP: 52   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2394
         Exactitud     = (TP + TN) / N   = 0.7606
         Accuracy      (sklearn)         = 0.7606

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7193
         FP-Rate                         = 0.2291

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4409
         Recall    = TP / P              = 0.7193

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7193
         Especificidad (TN/N)            = 0.7709

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7451
         BER (Balanced Error Rate)       = 0.2549

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4184

      ‚≠ê F1-Score:
         F1_Score                        = 0.5467

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6386

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | hcbou | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       184        43
            Buggy           12        45
      ====================================================
      TN=184  FP=43  FN=12  TP=45
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 45   TN: 184
         FP: 43   FN: 12

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1937
         Exactitud     = (TP + TN) / N   = 0.8063
         Accuracy      (sklearn)         = 0.8063

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7895
         FP-Rate                         = 0.1894

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5114
         Recall    = TP / P              = 0.7895

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7895
         Especificidad (TN/N)            = 0.8106

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8000
         BER (Balanced Error Rate)       = 0.2000

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5197

      ‚≠ê F1-Score:
         F1_Score                        = 0.6207

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.7120

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       224         3
            Buggy           49         8
      ====================================================
      TN=224  FP=3  FN=49  TP=8
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 8   TN: 224
         FP: 3   FN: 49

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1831
         Exactitud     = (TP + TN) / N   = 0.8169
         Accuracy      (sklearn)         = 0.8169

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1404
         FP-Rate                         = 0.0132

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.7273
         Recall    = TP / P              = 0.1404

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1404
         Especificidad (TN/N)            = 0.9868

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5636
         BER (Balanced Error Rate)       = 0.4364

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2639

      ‚≠ê F1-Score:
         F1_Score                        = 0.2353

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.1674

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       175        52
            Buggy           16        41
      ====================================================
      TN=175  FP=52  FN=16  TP=41
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 41   TN: 175
         FP: 52   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2394
         Exactitud     = (TP + TN) / N   = 0.7606
         Accuracy      (sklearn)         = 0.7606

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7193
         FP-Rate                         = 0.2291

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4409
         Recall    = TP / P              = 0.7193

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7193
         Especificidad (TN/N)            = 0.7709

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7451
         BER (Balanced Error Rate)       = 0.2549

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4184

      ‚≠ê F1-Score:
         F1_Score                        = 0.5467

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6386

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | smote | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       198        29
            Buggy           19        38
      ====================================================
      TN=198  FP=29  FN=19  TP=38
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 38   TN: 198
         FP: 29   FN: 19

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1690
         Exactitud     = (TP + TN) / N   = 0.8310
         Accuracy      (sklearn)         = 0.8310

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6667
         FP-Rate                         = 0.1278

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5672
         Recall    = TP / P              = 0.6667

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6667
         Especificidad (TN/N)            = 0.8722

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7695
         BER (Balanced Error Rate)       = 0.2305

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5084

      ‚≠ê F1-Score:
         F1_Score                        = 0.6129

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6441

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       218         9
            Buggy           40        17
      ====================================================
      TN=218  FP=9  FN=40  TP=17
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 17   TN: 218
         FP: 9   FN: 40

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1725
         Exactitud     = (TP + TN) / N   = 0.8275
         Accuracy      (sklearn)         = 0.8275

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2982
         FP-Rate                         = 0.0396

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6538
         Recall    = TP / P              = 0.2982

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2982
         Especificidad (TN/N)            = 0.9604

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6293
         BER (Balanced Error Rate)       = 0.3707

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3592

      ‚≠ê F1-Score:
         F1_Score                        = 0.4096

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3346

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       171        56
            Buggy           13        44
      ====================================================
      TN=171  FP=56  FN=13  TP=44
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 44   TN: 171
         FP: 56   FN: 13

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2430
         Exactitud     = (TP + TN) / N   = 0.7570
         Accuracy      (sklearn)         = 0.7570

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7719
         FP-Rate                         = 0.2467

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4400
         Recall    = TP / P              = 0.7719

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7719
         Especificidad (TN/N)            = 0.7533

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7626
         BER (Balanced Error Rate)       = 0.2374

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4404

      ‚≠ê F1-Score:
         F1_Score                        = 0.5605

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6707

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | smote | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       167        60
            Buggy           11        46
      ====================================================
      TN=167  FP=60  FN=11  TP=46
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 46   TN: 167
         FP: 60   FN: 11

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2500
         Exactitud     = (TP + TN) / N   = 0.7500
         Accuracy      (sklearn)         = 0.7500

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.8070
         FP-Rate                         = 0.2643

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4340
         Recall    = TP / P              = 0.8070

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.8070
         Especificidad (TN/N)            = 0.7357

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7714
         BER (Balanced Error Rate)       = 0.2286

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4494

      ‚≠ê F1-Score:
         F1_Score                        = 0.5644

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6886

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       222         5
            Buggy           50         7
      ====================================================
      TN=222  FP=5  FN=50  TP=7
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 7   TN: 222
         FP: 5   FN: 50

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1937
         Exactitud     = (TP + TN) / N   = 0.8063
         Accuracy      (sklearn)         = 0.8063

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1228
         FP-Rate                         = 0.0220

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5833
         Recall    = TP / P              = 0.1228

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1228
         Especificidad (TN/N)            = 0.9780

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5504
         BER (Balanced Error Rate)       = 0.4496

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2007

      ‚≠ê F1-Score:
         F1_Score                        = 0.2029

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.1458

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       188        39
            Buggy           16        41
      ====================================================
      TN=188  FP=39  FN=16  TP=41
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 41   TN: 188
         FP: 39   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1937
         Exactitud     = (TP + TN) / N   = 0.8063
         Accuracy      (sklearn)         = 0.8063

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7193
         FP-Rate                         = 0.1718

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5125
         Recall    = TP / P              = 0.7193

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7193
         Especificidad (TN/N)            = 0.8282

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7737
         BER (Balanced Error Rate)       = 0.2263

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4875

      ‚≠ê F1-Score:
         F1_Score                        = 0.5985

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6656

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO FINAL
================================================================================

================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO - DATASET: hive-0.9.0
================================================================================
  ‚úì Ranking completo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/hive-0.9.0_full_ranking.csv
  ‚úì Mejor modelo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/hive-0.9.0_best_model.json

  ‚ñ∫ MEJOR MODELO SELECCIONADO
     - Dataset           : hive-0.9.0
     - Modelo            : decision_tree
     - Balanceo          : csbboost
     - Escalado          : standard
     - M√©tricas clave:
         Recall (Buggy)  : 0.8421
         F2_Score        : 0.7643
         Precision       : 0.5581
         F1_Score        : 0.6713
         MCC             : 0.5881
         BER (‚Üì mejor)   : 0.1626
         Exactitud       : 0.8345
         Error           : 0.1655
================================================================================


================================================================================
‚úì PIPELINE COMPLETO PARA hive-0.9.0
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: jruby-1.1 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: jruby-1.1
[1] Preprocesamiento - Dimensiones originales: (731, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (731, 67)
[1] Preprocesamiento - Etiquetas √∫nicas en y: [0, 1]
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (584, 66), X_test: (147, 66)
[1] Preprocesamiento - Distribuci√≥n y_train: {0: 0.8801369863013698, 1: 0.11986301369863013}
[1] Preprocesamiento - Distribuci√≥n y_test:  {0: 0.8843537414965986, 1: 0.11564625850340136}
[1] Preprocesamiento - Archivos CSV guardados con √©xito en /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/01_preprocessing/jruby-1.1

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con jruby-1.1 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con jruby-1.1 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 514
    Clase Minoritaria (1): 70
    Total de clases: 584
    Ratio de desbalance: 7.34

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 292

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 222
[Minor√≠a] Tama√±o final (original + sint√©tico): 292

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 584
    Distribuci√≥n clases: {0: 292, 1: 292}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con jruby-1.1 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 514 muestras
    Clase minoritaria (1): 70 muestras
    Total de clases: 584
    Ratio de desbalance: 7.34

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 292

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 222
[Minoritaria] Tama√±o final (original + sint√©tico): 292

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 584
    Distribuci√≥n clases: {0: 292, 1: 292}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con jruby-1.1 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  514
     Clase minoritaria (1):  70
     Total de clases:  584
     Indice de desbalance:  7.34

[SMOTE] Clase mayoritaria (0): 514 -> 292 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 292, 1: 292}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando jruby-1.1 con standard
[3] [unbalanced] Escalando jruby-1.1 con robust
[3] [csbboost] Escalando jruby-1.1 con standard
[3] [csbboost] Escalando jruby-1.1 con robust
[3] [hcbou] Escalando jruby-1.1 con standard
[3] [hcbou] Escalando jruby-1.1 con robust
[3] [smote] Escalando jruby-1.1 con standard
[3] [smote] Escalando jruby-1.1 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================
‚úì Etiquetas OK para jruby-1.1 | unbalanced | standard (positivos=70, negativos=514)
‚úì Etiquetas OK para jruby-1.1 | unbalanced | robust (positivos=70, negativos=514)
‚úì Etiquetas OK para jruby-1.1 | csbboost | standard (positivos=292, negativos=292)
‚úì Etiquetas OK para jruby-1.1 | csbboost | robust (positivos=292, negativos=292)
‚úì Etiquetas OK para jruby-1.1 | hcbou | standard (positivos=292, negativos=292)
‚úì Etiquetas OK para jruby-1.1 | hcbou | robust (positivos=292, negativos=292)
‚úì Etiquetas OK para jruby-1.1 | smote | standard (positivos=292, negativos=292)
‚úì Etiquetas OK para jruby-1.1 | smote | robust (positivos=292, negativos=292)

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: jruby-1.1
================================================================================

üìã Total de configuraciones: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado:   ['standard', 'robust']
   ‚Ä¢ Modelos por config:  3


********************************************************************************
[1/8] CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=jruby-1.1 | method=unbalanced | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/jruby-1.1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/jruby-1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=jruby-1.1 | method=unbalanced | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/jruby-1.1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/jruby-1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=jruby-1.1 | method=csbboost | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/jruby-1.1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/jruby-1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=jruby-1.1 | method=csbboost | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/jruby-1.1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/jruby-1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=jruby-1.1 | method=hcbou | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/jruby-1.1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/jruby-1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=jruby-1.1 | method=hcbou | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/jruby-1.1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/jruby-1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=jruby-1.1 | method=smote | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/jruby-1.1/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/jruby-1.1/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=jruby-1.1 | method=smote | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(584, 65), X_test=(147, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/jruby-1.1/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/jruby-1.1/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: jruby-1.1 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: jruby-1.1
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS - DATASET: jruby-1.1
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | unbalanced | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       126         4
            Buggy            7        10
      ====================================================
      TN=126  FP=4  FN=7  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 126
         FP: 4   FN: 7

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0748
         Exactitud     = (TP + TN) / N   = 0.9252
         Accuracy      (sklearn)         = 0.9252

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5882
         FP-Rate                         = 0.0308

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.7143
         Recall    = TP / P              = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5882
         Especificidad (TN/N)            = 0.9692

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7787
         BER (Balanced Error Rate)       = 0.2213

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.6073

      ‚≠ê F1-Score:
         F1_Score                        = 0.6452

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6098

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       124         6
            Buggy            6        11
      ====================================================
      TN=124  FP=6  FN=6  TP=11
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 11   TN: 124
         FP: 6   FN: 6

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0816
         Exactitud     = (TP + TN) / N   = 0.9184
         Accuracy      (sklearn)         = 0.9184

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6471
         FP-Rate                         = 0.0462

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6471
         Recall    = TP / P              = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6471
         Especificidad (TN/N)            = 0.9538

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8005
         BER (Balanced Error Rate)       = 0.1995

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.6009

      ‚≠ê F1-Score:
         F1_Score                        = 0.6471

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6471

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       127         3
            Buggy            8         9
      ====================================================
      TN=127  FP=3  FN=8  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 127
         FP: 3   FN: 8

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0748
         Exactitud     = (TP + TN) / N   = 0.9252
         Accuracy      (sklearn)         = 0.9252

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5294
         FP-Rate                         = 0.0231

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.7500
         Recall    = TP / P              = 0.5294

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5294
         Especificidad (TN/N)            = 0.9769

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7532
         BER (Balanced Error Rate)       = 0.2468

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5914

      ‚≠ê F1-Score:
         F1_Score                        = 0.6207

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5625

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | unbalanced | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       124         6
            Buggy            9         8
      ====================================================
      TN=124  FP=6  FN=9  TP=8
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 8   TN: 124
         FP: 6   FN: 9

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1020
         Exactitud     = (TP + TN) / N   = 0.8980
         Accuracy      (sklearn)         = 0.8980

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4706
         FP-Rate                         = 0.0462

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5714
         Recall    = TP / P              = 0.4706

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4706
         Especificidad (TN/N)            = 0.9538

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7122
         BER (Balanced Error Rate)       = 0.2878

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4624

      ‚≠ê F1-Score:
         F1_Score                        = 0.5161

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4878

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       130         0
            Buggy           15         2
      ====================================================
      TN=130  FP=0  FN=15  TP=2
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 2   TN: 130
         FP: 0   FN: 15

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1020
         Exactitud     = (TP + TN) / N   = 0.8980
         Accuracy      (sklearn)         = 0.8980

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1176
         FP-Rate                         = 0.0000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 1.0000
         Recall    = TP / P              = 0.1176

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1176
         Especificidad (TN/N)            = 1.0000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5588
         BER (Balanced Error Rate)       = 0.4412

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3248

      ‚≠ê F1-Score:
         F1_Score                        = 0.2105

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.1429

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       127         3
            Buggy            8         9
      ====================================================
      TN=127  FP=3  FN=8  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 127
         FP: 3   FN: 8

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0748
         Exactitud     = (TP + TN) / N   = 0.9252
         Accuracy      (sklearn)         = 0.9252

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5294
         FP-Rate                         = 0.0231

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.7500
         Recall    = TP / P              = 0.5294

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5294
         Especificidad (TN/N)            = 0.9769

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7532
         BER (Balanced Error Rate)       = 0.2468

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5914

      ‚≠ê F1-Score:
         F1_Score                        = 0.6207

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5625

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | csbboost | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       126         4
            Buggy           11         6
      ====================================================
      TN=126  FP=4  FN=11  TP=6
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 6   TN: 126
         FP: 4   FN: 11

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1020
         Exactitud     = (TP + TN) / N   = 0.8980
         Accuracy      (sklearn)         = 0.8980

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3529
         FP-Rate                         = 0.0308

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6000
         Recall    = TP / P              = 0.3529

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3529
         Especificidad (TN/N)            = 0.9692

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6611
         BER (Balanced Error Rate)       = 0.3389

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4092

      ‚≠ê F1-Score:
         F1_Score                        = 0.4444

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3846

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       123         7
            Buggy            6        11
      ====================================================
      TN=123  FP=7  FN=6  TP=11
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 11   TN: 123
         FP: 7   FN: 6

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0884
         Exactitud     = (TP + TN) / N   = 0.9116
         Accuracy      (sklearn)         = 0.9116

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6471
         FP-Rate                         = 0.0538

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6111
         Recall    = TP / P              = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6471
         Especificidad (TN/N)            = 0.9462

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7966
         BER (Balanced Error Rate)       = 0.2034

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.5787

      ‚≠ê F1-Score:
         F1_Score                        = 0.6286

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6395

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       104        26
            Buggy            2        15
      ====================================================
      TN=104  FP=26  FN=2  TP=15
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 15   TN: 104
         FP: 26   FN: 2

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1905
         Exactitud     = (TP + TN) / N   = 0.8095
         Accuracy      (sklearn)         = 0.8095

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.8824
         FP-Rate                         = 0.2000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3659
         Recall    = TP / P              = 0.8824

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.8824
         Especificidad (TN/N)            = 0.8000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8412
         BER (Balanced Error Rate)       = 0.1588

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4866

      ‚≠ê F1-Score:
         F1_Score                        = 0.5172

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6881

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | csbboost | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       109        21
            Buggy            6        11
      ====================================================
      TN=109  FP=21  FN=6  TP=11
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 11   TN: 109
         FP: 21   FN: 6

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1837
         Exactitud     = (TP + TN) / N   = 0.8163
         Accuracy      (sklearn)         = 0.8163

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6471
         FP-Rate                         = 0.1615

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3438
         Recall    = TP / P              = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6471
         Especificidad (TN/N)            = 0.8385

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7428
         BER (Balanced Error Rate)       = 0.2572

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3763

      ‚≠ê F1-Score:
         F1_Score                        = 0.4490

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5500

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       130         0
            Buggy           16         1
      ====================================================
      TN=130  FP=0  FN=16  TP=1
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 1   TN: 130
         FP: 0   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1088
         Exactitud     = (TP + TN) / N   = 0.8912
         Accuracy      (sklearn)         = 0.8912

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.0588
         FP-Rate                         = 0.0000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 1.0000
         Recall    = TP / P              = 0.0588

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.0588
         Especificidad (TN/N)            = 1.0000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5294
         BER (Balanced Error Rate)       = 0.4706

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2289

      ‚≠ê F1-Score:
         F1_Score                        = 0.1111

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.0725

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       104        26
            Buggy            2        15
      ====================================================
      TN=104  FP=26  FN=2  TP=15
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 15   TN: 104
         FP: 26   FN: 2

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1905
         Exactitud     = (TP + TN) / N   = 0.8095
         Accuracy      (sklearn)         = 0.8095

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.8824
         FP-Rate                         = 0.2000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3659
         Recall    = TP / P              = 0.8824

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.8824
         Especificidad (TN/N)            = 0.8000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8412
         BER (Balanced Error Rate)       = 0.1588

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4866

      ‚≠ê F1-Score:
         F1_Score                        = 0.5172

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6881

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | hcbou | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       121         9
            Buggy            9         8
      ====================================================
      TN=121  FP=9  FN=9  TP=8
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 8   TN: 121
         FP: 9   FN: 9

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1224
         Exactitud     = (TP + TN) / N   = 0.8776
         Accuracy      (sklearn)         = 0.8776

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4706
         FP-Rate                         = 0.0692

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.4706
         Recall    = TP / P              = 0.4706

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4706
         Especificidad (TN/N)            = 0.9308

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7007
         BER (Balanced Error Rate)       = 0.2993

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4014

      ‚≠ê F1-Score:
         F1_Score                        = 0.4706

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.4706

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       124         6
            Buggy            6        11
      ====================================================
      TN=124  FP=6  FN=6  TP=11
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 11   TN: 124
         FP: 6   FN: 6

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0816
         Exactitud     = (TP + TN) / N   = 0.9184
         Accuracy      (sklearn)         = 0.9184

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6471
         FP-Rate                         = 0.0462

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6471
         Recall    = TP / P              = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6471
         Especificidad (TN/N)            = 0.9538

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8005
         BER (Balanced Error Rate)       = 0.1995

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.6009

      ‚≠ê F1-Score:
         F1_Score                        = 0.6471

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6471

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       112        18
            Buggy            7        10
      ====================================================
      TN=112  FP=18  FN=7  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 112
         FP: 18   FN: 7

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1701
         Exactitud     = (TP + TN) / N   = 0.8299
         Accuracy      (sklearn)         = 0.8299

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5882
         FP-Rate                         = 0.1385

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3571
         Recall    = TP / P              = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5882
         Especificidad (TN/N)            = 0.8615

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7249
         BER (Balanced Error Rate)       = 0.2751

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3663

      ‚≠ê F1-Score:
         F1_Score                        = 0.4444

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5208

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | hcbou | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       109        21
            Buggy            5        12
      ====================================================
      TN=109  FP=21  FN=5  TP=12
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 12   TN: 109
         FP: 21   FN: 5

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1769
         Exactitud     = (TP + TN) / N   = 0.8231
         Accuracy      (sklearn)         = 0.8231

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.7059
         FP-Rate                         = 0.1615

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3636
         Recall    = TP / P              = 0.7059

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.7059
         Especificidad (TN/N)            = 0.8385

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7722
         BER (Balanced Error Rate)       = 0.2278

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4172

      ‚≠ê F1-Score:
         F1_Score                        = 0.4800

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5941

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       130         0
            Buggy           16         1
      ====================================================
      TN=130  FP=0  FN=16  TP=1
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 1   TN: 130
         FP: 0   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1088
         Exactitud     = (TP + TN) / N   = 0.8912
         Accuracy      (sklearn)         = 0.8912

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.0588
         FP-Rate                         = 0.0000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 1.0000
         Recall    = TP / P              = 0.0588

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.0588
         Especificidad (TN/N)            = 1.0000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5294
         BER (Balanced Error Rate)       = 0.4706

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2289

      ‚≠ê F1-Score:
         F1_Score                        = 0.1111

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.0725

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       112        18
            Buggy            7        10
      ====================================================
      TN=112  FP=18  FN=7  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 112
         FP: 18   FN: 7

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1701
         Exactitud     = (TP + TN) / N   = 0.8299
         Accuracy      (sklearn)         = 0.8299

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5882
         FP-Rate                         = 0.1385

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3571
         Recall    = TP / P              = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5882
         Especificidad (TN/N)            = 0.8615

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7249
         BER (Balanced Error Rate)       = 0.2751

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3663

      ‚≠ê F1-Score:
         F1_Score                        = 0.4444

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5208

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | smote | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       122         8
            Buggy            8         9
      ====================================================
      TN=122  FP=8  FN=8  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 122
         FP: 8   FN: 8

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1088
         Exactitud     = (TP + TN) / N   = 0.8912
         Accuracy      (sklearn)         = 0.8912

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5294
         FP-Rate                         = 0.0615

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5294
         Recall    = TP / P              = 0.5294

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5294
         Especificidad (TN/N)            = 0.9385

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7339
         BER (Balanced Error Rate)       = 0.2661

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4679

      ‚≠ê F1-Score:
         F1_Score                        = 0.5294

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5294

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       124         6
            Buggy            6        11
      ====================================================
      TN=124  FP=6  FN=6  TP=11
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 11   TN: 124
         FP: 6   FN: 6

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0816
         Exactitud     = (TP + TN) / N   = 0.9184
         Accuracy      (sklearn)         = 0.9184

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.6471
         FP-Rate                         = 0.0462

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.6471
         Recall    = TP / P              = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.6471
         Especificidad (TN/N)            = 0.9538

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.8005
         BER (Balanced Error Rate)       = 0.1995

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.6009

      ‚≠ê F1-Score:
         F1_Score                        = 0.6471

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.6471

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       120        10
            Buggy            7        10
      ====================================================
      TN=120  FP=10  FN=7  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 120
         FP: 10   FN: 7

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1156
         Exactitud     = (TP + TN) / N   = 0.8844
         Accuracy      (sklearn)         = 0.8844

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5882
         FP-Rate                         = 0.0769

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5000
         Recall    = TP / P              = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5882
         Especificidad (TN/N)            = 0.9231

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7557
         BER (Balanced Error Rate)       = 0.2443

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4769

      ‚≠ê F1-Score:
         F1_Score                        = 0.5405

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5682

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | smote | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       113        17
            Buggy            7        10
      ====================================================
      TN=113  FP=17  FN=7  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 113
         FP: 17   FN: 7

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1633
         Exactitud     = (TP + TN) / N   = 0.8367
         Accuracy      (sklearn)         = 0.8367

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5882
         FP-Rate                         = 0.1308

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3704
         Recall    = TP / P              = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5882
         Especificidad (TN/N)            = 0.8692

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7287
         BER (Balanced Error Rate)       = 0.2713

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.3778

      ‚≠ê F1-Score:
         F1_Score                        = 0.4545

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5263

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       130         0
            Buggy           16         1
      ====================================================
      TN=130  FP=0  FN=16  TP=1
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 1   TN: 130
         FP: 0   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1088
         Exactitud     = (TP + TN) / N   = 0.8912
         Accuracy      (sklearn)         = 0.8912

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.0588
         FP-Rate                         = 0.0000

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 1.0000
         Recall    = TP / P              = 0.0588

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.0588
         Especificidad (TN/N)            = 1.0000

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5294
         BER (Balanced Error Rate)       = 0.4706

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2289

      ‚≠ê F1-Score:
         F1_Score                        = 0.1111

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.0725

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       121         9
            Buggy            7        10
      ====================================================
      TN=121  FP=9  FN=7  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 121
         FP: 9   FN: 7

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1088
         Exactitud     = (TP + TN) / N   = 0.8912
         Accuracy      (sklearn)         = 0.8912

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.5882
         FP-Rate                         = 0.0692

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.5263
         Recall    = TP / P              = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.5882
         Especificidad (TN/N)            = 0.9308

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.7595
         BER (Balanced Error Rate)       = 0.2405

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.4947

      ‚≠ê F1-Score:
         F1_Score                        = 0.5556

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.5747

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO FINAL
================================================================================

================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO - DATASET: jruby-1.1
================================================================================
  ‚úì Ranking completo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/jruby-1.1_full_ranking.csv
  ‚úì Mejor modelo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/jruby-1.1_best_model.json

  ‚ñ∫ MEJOR MODELO SELECCIONADO
     - Dataset           : jruby-1.1
     - Modelo            : decision_tree
     - Balanceo          : csbboost
     - Escalado          : standard
     - M√©tricas clave:
         Recall (Buggy)  : 0.8824
         F2_Score        : 0.6881
         Precision       : 0.3659
         F1_Score        : 0.5172
         MCC             : 0.4866
         BER (‚Üì mejor)   : 0.1588
         Exactitud       : 0.8095
         Error           : 0.1905
================================================================================


================================================================================
‚úì PIPELINE COMPLETO PARA jruby-1.1
================================================================================




********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************
********************************************************************************************************************************************************************************************************

================ DATASET: wicket-1.3.0-beta2 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: wicket-1.3.0-beta2
[1] Preprocesamiento - Dimensiones originales: (1763, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1763, 67)
[1] Preprocesamiento - Etiquetas √∫nicas en y: [0, 1]
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (1410, 66), X_test: (353, 66)
[1] Preprocesamiento - Distribuci√≥n y_train: {0: 0.926241134751773, 1: 0.07375886524822695}
[1] Preprocesamiento - Distribuci√≥n y_test:  {0: 0.9263456090651558, 1: 0.07365439093484419}
[1] Preprocesamiento - Archivos CSV guardados con √©xito en /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/01_preprocessing/wicket-1.3.0-beta2

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== 'Balanceo' [UNBALANCED] con wicket-1.3.0-beta2 ==========
================================================================
[2] 'Balanceo' [UNBALANCED] - Carga de datos preprocesados completa.
[2] 'Balanceo' [UNBALANCED] - Selecci√≥n de columnas num√©ricas.
[2] 'Balanceo' [UNBALANCED] - Archivos CSV guardados con √©xito.


========== Ballanceo [CSBBoost] con wicket-1.3.0-beta2 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 1306
    Clase Minoritaria (1): 104
    Total de clases: 1410
    Ratio de desbalance: 12.56

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 705

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 601
[Minor√≠a] Tama√±o final (original + sint√©tico): 705

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 1410
    Distribuci√≥n clases: {0: 705, 1: 705}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con wicket-1.3.0-beta2 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 1306 muestras
    Clase minoritaria (1): 104 muestras
    Total de clases: 1410
    Ratio de desbalance: 12.56

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 705

Clase minoritarias---------
[Minoritaria] K √≥ptimo (Silhouete) = 2
[Minoritaria] N√∫mero √≥ptimo de clusters: 2
Mejor √≠ndice silhouette: 0.7938
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 2
[Minoritaria] Nuevas muestras sint√©ticas generadas: 600
[Minoritaria] Tama√±o final (original + sint√©tico): 704

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 1409
    Distribuci√≥n clases: {0: 705, 1: 704}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con wicket-1.3.0-beta2 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  1306
     Clase minoritaria (1):  104
     Total de clases:  1410
     Indice de desbalance:  12.56

[SMOTE] Clase mayoritaria (0): 1306 -> 705 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 705, 1: 705}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [unbalanced] Escalando wicket-1.3.0-beta2 con standard
[3] [unbalanced] Escalando wicket-1.3.0-beta2 con robust
[3] [csbboost] Escalando wicket-1.3.0-beta2 con standard
[3] [csbboost] Escalando wicket-1.3.0-beta2 con robust
[3] [hcbou] Escalando wicket-1.3.0-beta2 con standard
[3] [hcbou] Escalando wicket-1.3.0-beta2 con robust
[3] [smote] Escalando wicket-1.3.0-beta2 con standard
[3] [smote] Escalando wicket-1.3.0-beta2 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================
‚úì Etiquetas OK para wicket-1.3.0-beta2 | unbalanced | standard (positivos=104, negativos=1306)
‚úì Etiquetas OK para wicket-1.3.0-beta2 | unbalanced | robust (positivos=104, negativos=1306)
‚úì Etiquetas OK para wicket-1.3.0-beta2 | csbboost | standard (positivos=705, negativos=705)
‚úì Etiquetas OK para wicket-1.3.0-beta2 | csbboost | robust (positivos=705, negativos=705)
‚úì Etiquetas OK para wicket-1.3.0-beta2 | hcbou | standard (positivos=704, negativos=705)
‚úì Etiquetas OK para wicket-1.3.0-beta2 | hcbou | robust (positivos=704, negativos=705)
‚úì Etiquetas OK para wicket-1.3.0-beta2 | smote | standard (positivos=705, negativos=705)
‚úì Etiquetas OK para wicket-1.3.0-beta2 | smote | robust (positivos=705, negativos=705)

================================================================================
üéØ B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH
üìä Dataset: wicket-1.3.0-beta2
================================================================================

üìã Total de configuraciones: 8
   ‚Ä¢ M√©todos de balanceo: ['unbalanced', 'csbboost', 'hcbou', 'smote']
   ‚Ä¢ Tipos de escalado:   ['standard', 'robust']
   ‚Ä¢ Modelos por config:  3


********************************************************************************
[1/8] CONFIGURACI√ìN: unbalanced_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=wicket-1.3.0-beta2 | method=unbalanced | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/wicket-1.3.0-beta2/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/wicket-1.3.0-beta2/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | unbalanced | standard
======================================================================


‚úÖ Configuraci√≥n 1/8 completada: unbalanced_standard

********************************************************************************
[2/8] CONFIGURACI√ìN: unbalanced_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=wicket-1.3.0-beta2 | method=unbalanced | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/wicket-1.3.0-beta2/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/unbalanced/wicket-1.3.0-beta2/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | unbalanced | robust
======================================================================


‚úÖ Configuraci√≥n 2/8 completada: unbalanced_robust

********************************************************************************
[3/8] CONFIGURACI√ìN: csbboost_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=wicket-1.3.0-beta2 | method=csbboost | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/wicket-1.3.0-beta2/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/wicket-1.3.0-beta2/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | csbboost | standard
======================================================================


‚úÖ Configuraci√≥n 3/8 completada: csbboost_standard

********************************************************************************
[4/8] CONFIGURACI√ìN: csbboost_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=wicket-1.3.0-beta2 | method=csbboost | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/wicket-1.3.0-beta2/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/csbboost/wicket-1.3.0-beta2/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | csbboost | robust
======================================================================


‚úÖ Configuraci√≥n 4/8 completada: csbboost_robust

********************************************************************************
[5/8] CONFIGURACI√ìN: hcbou_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=wicket-1.3.0-beta2 | method=hcbou | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1409, 65), X_test=(353, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/wicket-1.3.0-beta2/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/wicket-1.3.0-beta2/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | hcbou | standard
======================================================================


‚úÖ Configuraci√≥n 5/8 completada: hcbou_standard

********************************************************************************
[6/8] CONFIGURACI√ìN: hcbou_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=wicket-1.3.0-beta2 | method=hcbou | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1409, 65), X_test=(353, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/wicket-1.3.0-beta2/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/hcbou/wicket-1.3.0-beta2/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | hcbou | robust
======================================================================


‚úÖ Configuraci√≥n 6/8 completada: hcbou_robust

********************************************************************************
[7/8] CONFIGURACI√ìN: smote_standard
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=wicket-1.3.0-beta2 | method=smote | scaler=standard
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/wicket-1.3.0-beta2/standard

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/wicket-1.3.0-beta2/standard
          ‚úì naive_bayes_gaussian: guardado
          ‚úì svm: guardado
          ‚úì decision_tree: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | smote | standard
======================================================================


‚úÖ Configuraci√≥n 7/8 completada: smote_standard

********************************************************************************
[8/8] CONFIGURACI√ìN: smote_robust
********************************************************************************

======================================================================
üîß CONFIGURACI√ìN: dataset=wicket-1.3.0-beta2 | method=smote | scaler=robust
======================================================================
       üìå Etiquetas √∫nicas y_train: [0, 1]
       üìå Etiquetas √∫nicas y_test : [0, 1]
       ‚úì Datos cargados: X_train=(1410, 65), X_test=(353, 65)
       ‚úì Target codificado en 0/1 (Buggy = 1)
       üìÅ Directorio de salida: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/wicket-1.3.0-beta2/robust

       Modelos a procesar: ['svm', 'naive_bayes_gaussian', 'decision_tree']
       Modo: paralelo
       Cach√©: activado
       Progreso modelos: 1/3 completados
       Progreso modelos: 2/3 completados
       Progreso modelos: 3/3 completados

       üíæ Guardando resultados en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/04_hyperparameter_tuning/smote/wicket-1.3.0-beta2/robust
          ‚úì naive_bayes_gaussian: guardado
          ‚úì decision_tree: guardado
          ‚úì svm: guardado
       ‚úì Resumen guardado: 3/3 modelos

======================================================================
‚úÖ CONFIGURACI√ìN COMPLETADA: wicket-1.3.0-beta2 | smote | robust
======================================================================


‚úÖ Configuraci√≥n 8/8 completada: smote_robust

================================================================================
üéâ TODAS LAS CONFIGURACIONES COMPLETADAS PARA: wicket-1.3.0-beta2
================================================================================


================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS - DATASET: wicket-1.3.0-beta2
================================================================================

------------------------------------------------------------
Configuraci√≥n: unbalanced_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | unbalanced | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       284        43
            Buggy           23         3
      ====================================================
      TN=284  FP=43  FN=23  TP=3
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 3   TN: 284
         FP: 43   FN: 23

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1870
         Exactitud     = (TP + TN) / N   = 0.8130
         Accuracy      (sklearn)         = 0.8130

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1154
         FP-Rate                         = 0.1315

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.0652
         Recall    = TP / P              = 0.1154

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1154
         Especificidad (TN/N)            = 0.8685

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.4919
         BER (Balanced Error Rate)       = 0.5081

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = -0.0125

      ‚≠ê F1-Score:
         F1_Score                        = 0.0833

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.1000

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       302        25
            Buggy           16        10
      ====================================================
      TN=302  FP=25  FN=16  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 302
         FP: 25   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1161
         Exactitud     = (TP + TN) / N   = 0.8839
         Accuracy      (sklearn)         = 0.8839

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3846
         FP-Rate                         = 0.0765

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2857
         Recall    = TP / P              = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3846
         Especificidad (TN/N)            = 0.9235

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6541
         BER (Balanced Error Rate)       = 0.3459

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2693

      ‚≠ê F1-Score:
         F1_Score                        = 0.3279

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3597

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       313        14
            Buggy           22         4
      ====================================================
      TN=313  FP=14  FN=22  TP=4
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 4   TN: 313
         FP: 14   FN: 22

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1020
         Exactitud     = (TP + TN) / N   = 0.8980
         Accuracy      (sklearn)         = 0.8980

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1538
         FP-Rate                         = 0.0428

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2222
         Recall    = TP / P              = 0.1538

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1538
         Especificidad (TN/N)            = 0.9572

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5555
         BER (Balanced Error Rate)       = 0.4445

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1318

      ‚≠ê F1-Score:
         F1_Score                        = 0.1818

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.1639

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: unbalanced_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | unbalanced | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       251        76
            Buggy           16        10
      ====================================================
      TN=251  FP=76  FN=16  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 251
         FP: 76   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.2606
         Exactitud     = (TP + TN) / N   = 0.7394
         Accuracy      (sklearn)         = 0.7394

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3846
         FP-Rate                         = 0.2324

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1163
         Recall    = TP / P              = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3846
         Especificidad (TN/N)            = 0.7676

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5761
         BER (Balanced Error Rate)       = 0.4239

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.0926

      ‚≠ê F1-Score:
         F1_Score                        = 0.1786

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2632

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       302        25
            Buggy           16        10
      ====================================================
      TN=302  FP=25  FN=16  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 302
         FP: 25   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1161
         Exactitud     = (TP + TN) / N   = 0.8839
         Accuracy      (sklearn)         = 0.8839

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3846
         FP-Rate                         = 0.0765

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2857
         Recall    = TP / P              = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3846
         Especificidad (TN/N)            = 0.9235

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6541
         BER (Balanced Error Rate)       = 0.3459

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2693

      ‚≠ê F1-Score:
         F1_Score                        = 0.3279

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3597

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       313        14
            Buggy           22         4
      ====================================================
      TN=313  FP=14  FN=22  TP=4
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 4   TN: 313
         FP: 14   FN: 22

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1020
         Exactitud     = (TP + TN) / N   = 0.8980
         Accuracy      (sklearn)         = 0.8980

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1538
         FP-Rate                         = 0.0428

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2222
         Recall    = TP / P              = 0.1538

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1538
         Especificidad (TN/N)            = 0.9572

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5555
         BER (Balanced Error Rate)       = 0.4445

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1318

      ‚≠ê F1-Score:
         F1_Score                        = 0.1818

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.1639

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | csbboost | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       304        23
            Buggy           16        10
      ====================================================
      TN=304  FP=23  FN=16  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 304
         FP: 23   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1105
         Exactitud     = (TP + TN) / N   = 0.8895
         Accuracy      (sklearn)         = 0.8895

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3846
         FP-Rate                         = 0.0703

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3030
         Recall    = TP / P              = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3846
         Especificidad (TN/N)            = 0.9297

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6571
         BER (Balanced Error Rate)       = 0.3429

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2820

      ‚≠ê F1-Score:
         F1_Score                        = 0.3390

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3650

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       299        28
            Buggy           16        10
      ====================================================
      TN=299  FP=28  FN=16  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 299
         FP: 28   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1246
         Exactitud     = (TP + TN) / N   = 0.8754
         Accuracy      (sklearn)         = 0.8754

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3846
         FP-Rate                         = 0.0856

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2632
         Recall    = TP / P              = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3846
         Especificidad (TN/N)            = 0.9144

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6495
         BER (Balanced Error Rate)       = 0.3505

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2520

      ‚≠ê F1-Score:
         F1_Score                        = 0.3125

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3521

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       293        34
            Buggy           18         8
      ====================================================
      TN=293  FP=34  FN=18  TP=8
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 8   TN: 293
         FP: 34   FN: 18

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1473
         Exactitud     = (TP + TN) / N   = 0.8527
         Accuracy      (sklearn)         = 0.8527

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3077
         FP-Rate                         = 0.1040

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1905
         Recall    = TP / P              = 0.3077

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3077
         Especificidad (TN/N)            = 0.8960

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6019
         BER (Balanced Error Rate)       = 0.3981

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1644

      ‚≠ê F1-Score:
         F1_Score                        = 0.2353

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2740

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | csbboost | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       302        25
            Buggy           17         9
      ====================================================
      TN=302  FP=25  FN=17  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 302
         FP: 25   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1190
         Exactitud     = (TP + TN) / N   = 0.8810
         Accuracy      (sklearn)         = 0.8810

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3462
         FP-Rate                         = 0.0765

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2647
         Recall    = TP / P              = 0.3462

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3462
         Especificidad (TN/N)            = 0.9235

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6349
         BER (Balanced Error Rate)       = 0.3651

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2388

      ‚≠ê F1-Score:
         F1_Score                        = 0.3000

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3261

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       299        28
            Buggy           16        10
      ====================================================
      TN=299  FP=28  FN=16  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 299
         FP: 28   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1246
         Exactitud     = (TP + TN) / N   = 0.8754
         Accuracy      (sklearn)         = 0.8754

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3846
         FP-Rate                         = 0.0856

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2632
         Recall    = TP / P              = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3846
         Especificidad (TN/N)            = 0.9144

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6495
         BER (Balanced Error Rate)       = 0.3505

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2520

      ‚≠ê F1-Score:
         F1_Score                        = 0.3125

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3521

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       293        34
            Buggy           17         9
      ====================================================
      TN=293  FP=34  FN=17  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 293
         FP: 34   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1445
         Exactitud     = (TP + TN) / N   = 0.8555
         Accuracy      (sklearn)         = 0.8555

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3462
         FP-Rate                         = 0.1040

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2093
         Recall    = TP / P              = 0.3462

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3462
         Especificidad (TN/N)            = 0.8960

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6211
         BER (Balanced Error Rate)       = 0.3789

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1934

      ‚≠ê F1-Score:
         F1_Score                        = 0.2609

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3061

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | hcbou | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       316        11
            Buggy           21         5
      ====================================================
      TN=316  FP=11  FN=21  TP=5
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 5   TN: 316
         FP: 11   FN: 21

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0907
         Exactitud     = (TP + TN) / N   = 0.9093
         Accuracy      (sklearn)         = 0.9093

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.1923
         FP-Rate                         = 0.0336

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3125
         Recall    = TP / P              = 0.1923

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.1923
         Especificidad (TN/N)            = 0.9664

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.5793
         BER (Balanced Error Rate)       = 0.4207

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1992

      ‚≠ê F1-Score:
         F1_Score                        = 0.2381

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2083

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       304        23
            Buggy           16        10
      ====================================================
      TN=304  FP=23  FN=16  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 304
         FP: 23   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1105
         Exactitud     = (TP + TN) / N   = 0.8895
         Accuracy      (sklearn)         = 0.8895

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3846
         FP-Rate                         = 0.0703

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3030
         Recall    = TP / P              = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3846
         Especificidad (TN/N)            = 0.9297

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6571
         BER (Balanced Error Rate)       = 0.3429

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2820

      ‚≠ê F1-Score:
         F1_Score                        = 0.3390

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3650

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       285        42
            Buggy           17         9
      ====================================================
      TN=285  FP=42  FN=17  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 285
         FP: 42   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1671
         Exactitud     = (TP + TN) / N   = 0.8329
         Accuracy      (sklearn)         = 0.8329

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3462
         FP-Rate                         = 0.1284

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1765
         Recall    = TP / P              = 0.3462

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3462
         Especificidad (TN/N)            = 0.8716

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6089
         BER (Balanced Error Rate)       = 0.3911

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1618

      ‚≠ê F1-Score:
         F1_Score                        = 0.2338

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2903

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | hcbou | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       307        20
            Buggy           18         8
      ====================================================
      TN=307  FP=20  FN=18  TP=8
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 8   TN: 307
         FP: 20   FN: 18

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1076
         Exactitud     = (TP + TN) / N   = 0.8924
         Accuracy      (sklearn)         = 0.8924

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3077
         FP-Rate                         = 0.0612

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2857
         Recall    = TP / P              = 0.3077

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3077
         Especificidad (TN/N)            = 0.9388

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6233
         BER (Balanced Error Rate)       = 0.3767

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2383

      ‚≠ê F1-Score:
         F1_Score                        = 0.2963

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3030

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       304        23
            Buggy           16        10
      ====================================================
      TN=304  FP=23  FN=16  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 304
         FP: 23   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1105
         Exactitud     = (TP + TN) / N   = 0.8895
         Accuracy      (sklearn)         = 0.8895

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3846
         FP-Rate                         = 0.0703

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3030
         Recall    = TP / P              = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3846
         Especificidad (TN/N)            = 0.9297

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6571
         BER (Balanced Error Rate)       = 0.3429

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2820

      ‚≠ê F1-Score:
         F1_Score                        = 0.3390

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3650

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       285        42
            Buggy           17         9
      ====================================================
      TN=285  FP=42  FN=17  TP=9
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 9   TN: 285
         FP: 42   FN: 17

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1671
         Exactitud     = (TP + TN) / N   = 0.8329
         Accuracy      (sklearn)         = 0.8329

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3462
         FP-Rate                         = 0.1284

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1765
         Recall    = TP / P              = 0.3462

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3462
         Especificidad (TN/N)            = 0.8716

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6089
         BER (Balanced Error Rate)       = 0.3911

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1618

      ‚≠ê F1-Score:
         F1_Score                        = 0.2338

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2903

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | smote | standard
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       313        14
            Buggy           19         7
      ====================================================
      TN=313  FP=14  FN=19  TP=7
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 7   TN: 313
         FP: 14   FN: 19

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.0935
         Exactitud     = (TP + TN) / N   = 0.9065
         Accuracy      (sklearn)         = 0.9065

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.2692
         FP-Rate                         = 0.0428

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.3333
         Recall    = TP / P              = 0.2692

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.2692
         Especificidad (TN/N)            = 0.9572

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6132
         BER (Balanced Error Rate)       = 0.3868

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2500

      ‚≠ê F1-Score:
         F1_Score                        = 0.2979

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.2800

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       300        27
            Buggy           15        11
      ====================================================
      TN=300  FP=27  FN=15  TP=11
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 11   TN: 300
         FP: 27   FN: 15

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1190
         Exactitud     = (TP + TN) / N   = 0.8810
         Accuracy      (sklearn)         = 0.8810

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4231
         FP-Rate                         = 0.0826

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2895
         Recall    = TP / P              = 0.4231

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4231
         Especificidad (TN/N)            = 0.9174

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6703
         BER (Balanced Error Rate)       = 0.3297

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2870

      ‚≠ê F1-Score:
         F1_Score                        = 0.3438

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3873

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       279        48
            Buggy           16        10
      ====================================================
      TN=279  FP=48  FN=16  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 279
         FP: 48   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1813
         Exactitud     = (TP + TN) / N   = 0.8187
         Accuracy      (sklearn)         = 0.8187

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3846
         FP-Rate                         = 0.1468

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1724
         Recall    = TP / P              = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3846
         Especificidad (TN/N)            = 0.8532

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6189
         BER (Balanced Error Rate)       = 0.3811

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1676

      ‚≠ê F1-Score:
         F1_Score                        = 0.2381

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3086

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | smote | robust
    ‚Üí svm: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - SVM
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       283        44
            Buggy           15        11
      ====================================================
      TN=283  FP=44  FN=15  TP=11
      ====================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 11   TN: 283
         FP: 44   FN: 15

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1671
         Exactitud     = (TP + TN) / N   = 0.8329
         Accuracy      (sklearn)         = 0.8329

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4231
         FP-Rate                         = 0.1346

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2000
         Recall    = TP / P              = 0.4231

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4231
         Especificidad (TN/N)            = 0.8654

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6443
         BER (Balanced Error Rate)       = 0.3557

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2078

      ‚≠ê F1-Score:
         F1_Score                        = 0.2716

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3459

      ============================================================

    ‚úì svm: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       300        27
            Buggy           15        11
      ====================================================
      TN=300  FP=27  FN=15  TP=11
      ====================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 11   TN: 300
         FP: 27   FN: 15

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1190
         Exactitud     = (TP + TN) / N   = 0.8810
         Accuracy      (sklearn)         = 0.8810

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.4231
         FP-Rate                         = 0.0826

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.2895
         Recall    = TP / P              = 0.4231

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.4231
         Especificidad (TN/N)            = 0.9174

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6703
         BER (Balanced Error Rate)       = 0.3297

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.2870

      ‚≠ê F1-Score:
         F1_Score                        = 0.3438

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3873

      ============================================================

    ‚úì naive_bayes_gaussian: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y mejores hiperpar√°metros...
      üìå [Fase 5] Etiquetas √∫nicas y_train: [0, 1]
      üìå [Fase 5] Etiquetas √∫nicas y_test : [0, 1]
      Mejores hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en conjunto de prueba...

      ====================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      (filas = reales, columnas = predichas)
      ====================================================
                          Predicci√≥n
                     No-Buggy    Buggy
      Real  No-Buggy       279        48
            Buggy           16        10
      ====================================================
      TN=279  FP=48  FN=16  TP=10
      ====================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         TP: 10   TN: 279
         FP: 48   FN: 16

      üìà Error y Exactitud:
         Error         = (FP + FN) / N   = 0.1813
         Exactitud     = (TP + TN) / N   = 0.8187
         Accuracy      (sklearn)         = 0.8187

      üé≤ Tasas:
         TP-Rate (Recall)                = 0.3846
         FP-Rate                         = 0.1468

      üîç Precisi√≥n y Recall:
         Precision = TP / P'             = 0.1724
         Recall    = TP / P              = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad (TP/P)             = 0.3846
         Especificidad (TN/N)            = 0.8532

      ‚öñÔ∏è Balanced Accuracy y BER:
         Balanced Accuracy               = 0.6189
         BER (Balanced Error Rate)       = 0.3811

      üßÆ MCC:
         MCC (Matthews Corr. Coef.)      = 0.1676

      ‚≠ê F1-Score:
         F1_Score                        = 0.2381

      ‚≠ê‚≠ê F2-Score (Œ≤=2, Buggy):
         F2_Score                        = 0.3086

      ============================================================

    ‚úì decision_tree: entrenamiento y evaluaci√≥n completados
      Tiempo de entrenamiento: 0.02s


================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO FINAL
================================================================================

================================================================================
FASE 6: SELECCI√ìN DEL MEJOR MODELO - DATASET: wicket-1.3.0-beta2
================================================================================
  ‚úì Ranking completo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/wicket-1.3.0-beta2_full_ranking.csv
  ‚úì Mejor modelo guardado en: /Users/behero/Documents/SCHOOL/UTM/MIS/2025/TERCER-SEMESTRE/prediccion-de-errores-en-la-ingenieria-de-software/JIRA-datasets-classification-pipeline/artifacts/06_model_selection/wicket-1.3.0-beta2_best_model.json

  ‚ñ∫ MEJOR MODELO SELECCIONADO
     - Dataset           : wicket-1.3.0-beta2
     - Modelo            : naive_bayes_gaussian
     - Balanceo          : smote
     - Escalado          : standard
     - M√©tricas clave:
         Recall (Buggy)  : 0.4231
         F2_Score        : 0.3873
         Precision       : 0.2895
         F1_Score        : 0.3438
         MCC             : 0.2870
         BER (‚Üì mejor)   : 0.3297
         Exactitud       : 0.8810
         Error           : 0.1190
================================================================================


================================================================================
‚úì PIPELINE COMPLETO PARA wicket-1.3.0-beta2
================================================================================

==================================================
=== FIN DE EJECUCI√ìN DEL PIPELINE ===
Timestamp: 2025-12-11 09:19:55
==================================================
