=== INICIO DE EJECUCI√ìN DEL PIPELINE ===
Timestamp: 2025-11-27 19:29:37
==================================================



******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************

================ DATASET: activemq-5.0.0 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: activemq-5.0.0
[1] Preprocesamiento - Dimensiones originales: (1884, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1884, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (1507, 66), X_test: (377, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== Ballanceo [CSBBoost] con activemq-5.0.0 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 1273
    Clase Minoritaria (1): 234
    Total de clases: 1507
    Ratio de desbalance: 5.44

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 753

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 520
[Minor√≠a] Tama√±o final (original + sint√©tico): 754

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 1507
    Distribuci√≥n clases: {1: 754, 0: 753}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con activemq-5.0.0 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 1273 muestras
    Clase minoritaria (1): 234 muestras
    Total de clases: 1507
    Ratio de desbalance: 5.44

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 753

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 519
[Minoritaria] Tama√±o final (original + sint√©tico): 753

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 1506
    Distribuci√≥n clases: {0: 753, 1: 753}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con activemq-5.0.0 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  1273
     Clase minoritaria (1):  234
     Total de clases:  1507
     Indice de desbalance:  5.44

[SMOTE] Clase mayoritaria (0): 1273 -> 753 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 753, 1: 753}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [csbboost] Escalando activemq-5.0.0 con standard
[3] [csbboost] Escalando activemq-5.0.0 con robust
[3] [hcbou] Escalando activemq-5.0.0 con standard
[3] [hcbou] Escalando activemq-5.0.0 con robust
[3] [smote] Escalando activemq-5.0.0 con standard
[3] [smote] Escalando activemq-5.0.0 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH: activemq-5.0.0
================================================================================

------------------------------------------------------------
Procesando: csbboost_standard
------------------------------------------------------------

‚Üí activemq-5.0.0 | csbboost | standard

------------------------------------------------------------
Procesando: csbboost_robust
------------------------------------------------------------

‚Üí activemq-5.0.0 | csbboost | robust

------------------------------------------------------------
Procesando: hcbou_standard
------------------------------------------------------------

‚Üí activemq-5.0.0 | hcbou | standard

------------------------------------------------------------
Procesando: hcbou_robust
------------------------------------------------------------

‚Üí activemq-5.0.0 | hcbou | robust

------------------------------------------------------------
Procesando: smote_standard
------------------------------------------------------------

‚Üí activemq-5.0.0 | smote | standard

------------------------------------------------------------
Procesando: smote_robust
------------------------------------------------------------

‚Üí activemq-5.0.0 | smote | robust

================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: activemq-5.0.0
================================================================================

------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      280        38
            Buggy          28        31
      ==================================================
      TN=280  FP=38  FN=28  TP=31
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 31
         True Negatives  (TN): 280
         False Positives (FP): 38
         False Negatives (FN): 28

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1751
         Exactitud = (TP + TN) / N          = 0.8249
         Verificaci√≥n: 1 - Error            = 0.8249

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5254
         FP-Rate = FP / N                   = 0.1195

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4493
         Recall = TP / P (= TP-Rate)        = 0.5254

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5254
         Especificidad = TN / N             = 0.8805
         Verificaci√≥n: 1 - FP-Rate          = 0.8805

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4844

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.13s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          24        35
      ==================================================
      TN=283  FP=35  FN=24  TP=35
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 35
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1565
         Exactitud = (TP + TN) / N          = 0.8435
         Verificaci√≥n: 1 - Error            = 0.8435

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5932
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5000
         Recall = TP / P (= TP-Rate)        = 0.5932

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5932
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5426

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          16        43
      ==================================================
      TN=283  FP=35  FN=16  TP=43
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 43
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1353
         Exactitud = (TP + TN) / N          = 0.8647
         Verificaci√≥n: 1 - Error            = 0.8647

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7288
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5513
         Recall = TP / P (= TP-Rate)        = 0.7288

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7288
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6277

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      267        51
            Buggy          23        36
      ==================================================
      TN=267  FP=51  FN=23  TP=36
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 36
         True Negatives  (TN): 267
         False Positives (FP): 51
         False Negatives (FN): 23

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1963
         Exactitud = (TP + TN) / N          = 0.8037
         Verificaci√≥n: 1 - Error            = 0.8037

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6102
         FP-Rate = FP / N                   = 0.1604

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4138
         Recall = TP / P (= TP-Rate)        = 0.6102

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6102
         Especificidad = TN / N             = 0.8396
         Verificaci√≥n: 1 - FP-Rate          = 0.8396

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4932

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.17s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-08}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          24        35
      ==================================================
      TN=283  FP=35  FN=24  TP=35
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 35
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1565
         Exactitud = (TP + TN) / N          = 0.8435
         Verificaci√≥n: 1 - Error            = 0.8435

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5932
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5000
         Recall = TP / P (= TP-Rate)        = 0.5932

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5932
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5426

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          16        43
      ==================================================
      TN=283  FP=35  FN=16  TP=43
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 43
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1353
         Exactitud = (TP + TN) / N          = 0.8647
         Verificaci√≥n: 1 - Error            = 0.8647

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7288
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5513
         Recall = TP / P (= TP-Rate)        = 0.7288

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7288
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6277

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      270        48
            Buggy          17        42
      ==================================================
      TN=270  FP=48  FN=17  TP=42
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 42
         True Negatives  (TN): 270
         False Positives (FP): 48
         False Negatives (FN): 17

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1724
         Exactitud = (TP + TN) / N          = 0.8276
         Verificaci√≥n: 1 - Error            = 0.8276

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7119
         FP-Rate = FP / N                   = 0.1509

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4667
         Recall = TP / P (= TP-Rate)        = 0.7119

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7119
         Especificidad = TN / N             = 0.8491
         Verificaci√≥n: 1 - FP-Rate          = 0.8491

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5638

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.20s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      287        31
            Buggy          26        33
      ==================================================
      TN=287  FP=31  FN=26  TP=33
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 33
         True Negatives  (TN): 287
         False Positives (FP): 31
         False Negatives (FN): 26

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1512
         Exactitud = (TP + TN) / N          = 0.8488
         Verificaci√≥n: 1 - Error            = 0.8488

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5593
         FP-Rate = FP / N                   = 0.0975

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5156
         Recall = TP / P (= TP-Rate)        = 0.5593

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5593
         Especificidad = TN / N             = 0.9025
         Verificaci√≥n: 1 - FP-Rate          = 0.9025

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5366

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      277        41
            Buggy          19        40
      ==================================================
      TN=277  FP=41  FN=19  TP=40
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 40
         True Negatives  (TN): 277
         False Positives (FP): 41
         False Negatives (FN): 19

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1592
         Exactitud = (TP + TN) / N          = 0.8408
         Verificaci√≥n: 1 - Error            = 0.8408

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6780
         FP-Rate = FP / N                   = 0.1289

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4938
         Recall = TP / P (= TP-Rate)        = 0.6780

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6780
         Especificidad = TN / N             = 0.8711
         Verificaci√≥n: 1 - FP-Rate          = 0.8711

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5714

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          28        31
      ==================================================
      TN=283  FP=35  FN=28  TP=31
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 31
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 28

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1671
         Exactitud = (TP + TN) / N          = 0.8329
         Verificaci√≥n: 1 - Error            = 0.8329

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5254
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4697
         Recall = TP / P (= TP-Rate)        = 0.5254

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5254
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4960

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.13s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-06}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      257        61
            Buggy          20        39
      ==================================================
      TN=257  FP=61  FN=20  TP=39
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 39
         True Negatives  (TN): 257
         False Positives (FP): 61
         False Negatives (FN): 20

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2149
         Exactitud = (TP + TN) / N          = 0.7851
         Verificaci√≥n: 1 - Error            = 0.7851

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6610
         FP-Rate = FP / N                   = 0.1918

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3900
         Recall = TP / P (= TP-Rate)        = 0.6610

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6610
         Especificidad = TN / N             = 0.8082
         Verificaci√≥n: 1 - FP-Rate          = 0.8082

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4906

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      278        40
            Buggy          19        40
      ==================================================
      TN=278  FP=40  FN=19  TP=40
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 40
         True Negatives  (TN): 278
         False Positives (FP): 40
         False Negatives (FN): 19

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1565
         Exactitud = (TP + TN) / N          = 0.8435
         Verificaci√≥n: 1 - Error            = 0.8435

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6780
         FP-Rate = FP / N                   = 0.1258

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5000
         Recall = TP / P (= TP-Rate)        = 0.6780

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6780
         Especificidad = TN / N             = 0.8742
         Verificaci√≥n: 1 - FP-Rate          = 0.8742

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5755

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          23        36
      ==================================================
      TN=283  FP=35  FN=23  TP=36
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 36
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 23

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1538
         Exactitud = (TP + TN) / N          = 0.8462
         Verificaci√≥n: 1 - Error            = 0.8462

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6102
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5070
         Recall = TP / P (= TP-Rate)        = 0.6102

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6102
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5538

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.11s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      283        35
            Buggy          24        35
      ==================================================
      TN=283  FP=35  FN=24  TP=35
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 35
         True Negatives  (TN): 283
         False Positives (FP): 35
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1565
         Exactitud = (TP + TN) / N          = 0.8435
         Verificaci√≥n: 1 - Error            = 0.8435

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5932
         FP-Rate = FP / N                   = 0.1101

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5000
         Recall = TP / P (= TP-Rate)        = 0.5932

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5932
         Especificidad = TN / N             = 0.8899
         Verificaci√≥n: 1 - FP-Rate          = 0.8899

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5426

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      284        34
            Buggy          16        43
      ==================================================
      TN=284  FP=34  FN=16  TP=43
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 43
         True Negatives  (TN): 284
         False Positives (FP): 34
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1326
         Exactitud = (TP + TN) / N          = 0.8674
         Verificaci√≥n: 1 - Error            = 0.8674

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7288
         FP-Rate = FP / N                   = 0.1069

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5584
         Recall = TP / P (= TP-Rate)        = 0.7288

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7288
         Especificidad = TN / N             = 0.8931
         Verificaci√≥n: 1 - FP-Rate          = 0.8931

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6324

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: activemq-5.0.0 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      285        33
            Buggy          22        37
      ==================================================
      TN=285  FP=33  FN=22  TP=37
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 37
         True Negatives  (TN): 285
         False Positives (FP): 33
         False Negatives (FN): 22

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1459
         Exactitud = (TP + TN) / N          = 0.8541
         Verificaci√≥n: 1 - Error            = 0.8541

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6271
         FP-Rate = FP / N                   = 0.1038

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5286
         Recall = TP / P (= TP-Rate)        = 0.6271

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6271
         Especificidad = TN / N             = 0.8962
         Verificaci√≥n: 1 - FP-Rate          = 0.8962

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5736

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.12s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      282        36
            Buggy          24        35
      ==================================================
      TN=282  FP=36  FN=24  TP=35
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 35
         True Negatives  (TN): 282
         False Positives (FP): 36
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1592
         Exactitud = (TP + TN) / N          = 0.8408
         Verificaci√≥n: 1 - Error            = 0.8408

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5932
         FP-Rate = FP / N                   = 0.1132

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4930
         Recall = TP / P (= TP-Rate)        = 0.5932

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5932
         Especificidad = TN / N             = 0.8868
         Verificaci√≥n: 1 - FP-Rate          = 0.8868

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5385

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      284        34
            Buggy          16        43
      ==================================================
      TN=284  FP=34  FN=16  TP=43
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 377
         Positivos reales (P):    59 (Buggy)
         Negativos reales (N):    318 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 43
         True Negatives  (TN): 284
         False Positives (FP): 34
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1326
         Exactitud = (TP + TN) / N          = 0.8674
         Verificaci√≥n: 1 - Error            = 0.8674

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7288
         FP-Rate = FP / N                   = 0.1069

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5584
         Recall = TP / P (= TP-Rate)        = 0.7288

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7288
         Especificidad = TN / N             = 0.8931
         Verificaci√≥n: 1 - FP-Rate          = 0.8931

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6324

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


================================================================================
‚úì PIPELINE COMPLETO PARA activemq-5.0.0
================================================================================




******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************

================ DATASET: derby-10.5.1.1 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: derby-10.5.1.1
[1] Preprocesamiento - Dimensiones originales: (2705, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (2705, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (2164, 66), X_test: (541, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== Ballanceo [CSBBoost] con derby-10.5.1.1 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 1858
    Clase Minoritaria (1): 306
    Total de clases: 2164
    Ratio de desbalance: 6.07

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 1082

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 776
[Minor√≠a] Tama√±o final (original + sint√©tico): 1082

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 2164
    Distribuci√≥n clases: {0: 1082, 1: 1082}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con derby-10.5.1.1 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 1858 muestras
    Clase minoritaria (1): 306 muestras
    Total de clases: 2164
    Ratio de desbalance: 6.07

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 1082

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 776
[Minoritaria] Tama√±o final (original + sint√©tico): 1082

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 2164
    Distribuci√≥n clases: {0: 1082, 1: 1082}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con derby-10.5.1.1 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  1858
     Clase minoritaria (1):  306
     Total de clases:  2164
     Indice de desbalance:  6.07

[SMOTE] Clase mayoritaria (0): 1858 -> 1082 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 1082, 1: 1082}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [csbboost] Escalando derby-10.5.1.1 con standard
[3] [csbboost] Escalando derby-10.5.1.1 con robust
[3] [hcbou] Escalando derby-10.5.1.1 con standard
[3] [hcbou] Escalando derby-10.5.1.1 con robust
[3] [smote] Escalando derby-10.5.1.1 con standard
[3] [smote] Escalando derby-10.5.1.1 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH: derby-10.5.1.1
================================================================================

------------------------------------------------------------
Procesando: csbboost_standard
------------------------------------------------------------

‚Üí derby-10.5.1.1 | csbboost | standard

------------------------------------------------------------
Procesando: csbboost_robust
------------------------------------------------------------

‚Üí derby-10.5.1.1 | csbboost | robust

------------------------------------------------------------
Procesando: hcbou_standard
------------------------------------------------------------

‚Üí derby-10.5.1.1 | hcbou | standard

------------------------------------------------------------
Procesando: hcbou_robust
------------------------------------------------------------

‚Üí derby-10.5.1.1 | hcbou | robust

------------------------------------------------------------
Procesando: smote_standard
------------------------------------------------------------

‚Üí derby-10.5.1.1 | smote | standard

------------------------------------------------------------
Procesando: smote_robust
------------------------------------------------------------

‚Üí derby-10.5.1.1 | smote | robust

================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: derby-10.5.1.1
================================================================================

------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      401        63
            Buggy          51        26
      ==================================================
      TN=401  FP=63  FN=51  TP=26
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 26
         True Negatives  (TN): 401
         False Positives (FP): 63
         False Negatives (FN): 51

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2107
         Exactitud = (TP + TN) / N          = 0.7893
         Verificaci√≥n: 1 - Error            = 0.7893

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3377
         FP-Rate = FP / N                   = 0.1358

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2921
         Recall = TP / P (= TP-Rate)        = 0.3377

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3377
         Especificidad = TN / N             = 0.8642
         Verificaci√≥n: 1 - FP-Rate          = 0.8642

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3133

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.43s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      425        39
            Buggy          43        34
      ==================================================
      TN=425  FP=39  FN=43  TP=34
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 34
         True Negatives  (TN): 425
         False Positives (FP): 39
         False Negatives (FN): 43

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1516
         Exactitud = (TP + TN) / N          = 0.8484
         Verificaci√≥n: 1 - Error            = 0.8484

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4416
         FP-Rate = FP / N                   = 0.0841

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4658
         Recall = TP / P (= TP-Rate)        = 0.4416

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4416
         Especificidad = TN / N             = 0.9159
         Verificaci√≥n: 1 - FP-Rate          = 0.9159

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4533

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      393        71
            Buggy          34        43
      ==================================================
      TN=393  FP=71  FN=34  TP=43
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 43
         True Negatives  (TN): 393
         False Positives (FP): 71
         False Negatives (FN): 34

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1941
         Exactitud = (TP + TN) / N          = 0.8059
         Verificaci√≥n: 1 - Error            = 0.8059

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5584
         FP-Rate = FP / N                   = 0.1530

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3772
         Recall = TP / P (= TP-Rate)        = 0.5584

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5584
         Especificidad = TN / N             = 0.8470
         Verificaci√≥n: 1 - FP-Rate          = 0.8470

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4503

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      313       151
            Buggy          24        53
      ==================================================
      TN=313  FP=151  FN=24  TP=53
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 53
         True Negatives  (TN): 313
         False Positives (FP): 151
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.3235
         Exactitud = (TP + TN) / N          = 0.6765
         Verificaci√≥n: 1 - Error            = 0.6765

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6883
         FP-Rate = FP / N                   = 0.3254

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2598
         Recall = TP / P (= TP-Rate)        = 0.6883

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6883
         Especificidad = TN / N             = 0.6746
         Verificaci√≥n: 1 - FP-Rate          = 0.6746

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3772

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.52s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      459         5
            Buggy          75         2
      ==================================================
      TN=459  FP=5  FN=75  TP=2
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 2
         True Negatives  (TN): 459
         False Positives (FP): 5
         False Negatives (FN): 75

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1479
         Exactitud = (TP + TN) / N          = 0.8521
         Verificaci√≥n: 1 - Error            = 0.8521

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0260
         FP-Rate = FP / N                   = 0.0108

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2857
         Recall = TP / P (= TP-Rate)        = 0.0260

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0260
         Especificidad = TN / N             = 0.9892
         Verificaci√≥n: 1 - FP-Rate          = 0.9892

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.0476

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      380        84
            Buggy          34        43
      ==================================================
      TN=380  FP=84  FN=34  TP=43
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 43
         True Negatives  (TN): 380
         False Positives (FP): 84
         False Negatives (FN): 34

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2181
         Exactitud = (TP + TN) / N          = 0.7819
         Verificaci√≥n: 1 - Error            = 0.7819

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5584
         FP-Rate = FP / N                   = 0.1810

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3386
         Recall = TP / P (= TP-Rate)        = 0.5584

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5584
         Especificidad = TN / N             = 0.8190
         Verificaci√≥n: 1 - FP-Rate          = 0.8190

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4216

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      370        94
            Buggy          27        50
      ==================================================
      TN=370  FP=94  FN=27  TP=50
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 50
         True Negatives  (TN): 370
         False Positives (FP): 94
         False Negatives (FN): 27

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2237
         Exactitud = (TP + TN) / N          = 0.7763
         Verificaci√≥n: 1 - Error            = 0.7763

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6494
         FP-Rate = FP / N                   = 0.2026

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3472
         Recall = TP / P (= TP-Rate)        = 0.6494

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6494
         Especificidad = TN / N             = 0.7974
         Verificaci√≥n: 1 - FP-Rate          = 0.7974

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4525

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.43s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-08}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      422        42
            Buggy          42        35
      ==================================================
      TN=422  FP=42  FN=42  TP=35
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 35
         True Negatives  (TN): 422
         False Positives (FP): 42
         False Negatives (FN): 42

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1553
         Exactitud = (TP + TN) / N          = 0.8447
         Verificaci√≥n: 1 - Error            = 0.8447

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4545
         FP-Rate = FP / N                   = 0.0905

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4545
         Recall = TP / P (= TP-Rate)        = 0.4545

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4545
         Especificidad = TN / N             = 0.9095
         Verificaci√≥n: 1 - FP-Rate          = 0.9095

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4545

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      361       103
            Buggy          32        45
      ==================================================
      TN=361  FP=103  FN=32  TP=45
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 45
         True Negatives  (TN): 361
         False Positives (FP): 103
         False Negatives (FN): 32

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2495
         Exactitud = (TP + TN) / N          = 0.7505
         Verificaci√≥n: 1 - Error            = 0.7505

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5844
         FP-Rate = FP / N                   = 0.2220

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3041
         Recall = TP / P (= TP-Rate)        = 0.5844

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5844
         Especificidad = TN / N             = 0.7780
         Verificaci√≥n: 1 - FP-Rate          = 0.7780

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4000

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      348       116
            Buggy          29        48
      ==================================================
      TN=348  FP=116  FN=29  TP=48
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 48
         True Negatives  (TN): 348
         False Positives (FP): 116
         False Negatives (FN): 29

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2680
         Exactitud = (TP + TN) / N          = 0.7320
         Verificaci√≥n: 1 - Error            = 0.7320

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6234
         FP-Rate = FP / N                   = 0.2500

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2927
         Recall = TP / P (= TP-Rate)        = 0.6234

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6234
         Especificidad = TN / N             = 0.7500
         Verificaci√≥n: 1 - FP-Rate          = 0.7500

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3983

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.56s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      460         4
            Buggy          74         3
      ==================================================
      TN=460  FP=4  FN=74  TP=3
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 3
         True Negatives  (TN): 460
         False Positives (FP): 4
         False Negatives (FN): 74

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1442
         Exactitud = (TP + TN) / N          = 0.8558
         Verificaci√≥n: 1 - Error            = 0.8558

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0390
         FP-Rate = FP / N                   = 0.0086

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4286
         Recall = TP / P (= TP-Rate)        = 0.0390

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0390
         Especificidad = TN / N             = 0.9914
         Verificaci√≥n: 1 - FP-Rate          = 0.9914

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.0714

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      360       104
            Buggy          37        40
      ==================================================
      TN=360  FP=104  FN=37  TP=40
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 40
         True Negatives  (TN): 360
         False Positives (FP): 104
         False Negatives (FN): 37

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2606
         Exactitud = (TP + TN) / N          = 0.7394
         Verificaci√≥n: 1 - Error            = 0.7394

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5195
         FP-Rate = FP / N                   = 0.2241

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2778
         Recall = TP / P (= TP-Rate)        = 0.5195

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5195
         Especificidad = TN / N             = 0.7759
         Verificaci√≥n: 1 - FP-Rate          = 0.7759

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3620

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      393        71
            Buggy          36        41
      ==================================================
      TN=393  FP=71  FN=36  TP=41
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 41
         True Negatives  (TN): 393
         False Positives (FP): 71
         False Negatives (FN): 36

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1978
         Exactitud = (TP + TN) / N          = 0.8022
         Verificaci√≥n: 1 - Error            = 0.8022

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5325
         FP-Rate = FP / N                   = 0.1530

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3661
         Recall = TP / P (= TP-Rate)        = 0.5325

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5325
         Especificidad = TN / N             = 0.8470
         Verificaci√≥n: 1 - FP-Rate          = 0.8470

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4339

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.42s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      421        43
            Buggy          43        34
      ==================================================
      TN=421  FP=43  FN=43  TP=34
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 34
         True Negatives  (TN): 421
         False Positives (FP): 43
         False Negatives (FN): 43

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1590
         Exactitud = (TP + TN) / N          = 0.8410
         Verificaci√≥n: 1 - Error            = 0.8410

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4416
         FP-Rate = FP / N                   = 0.0927

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4416
         Recall = TP / P (= TP-Rate)        = 0.4416

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4416
         Especificidad = TN / N             = 0.9073
         Verificaci√≥n: 1 - FP-Rate          = 0.9073

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4416

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      361       103
            Buggy          33        44
      ==================================================
      TN=361  FP=103  FN=33  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 361
         False Positives (FP): 103
         False Negatives (FN): 33

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2514
         Exactitud = (TP + TN) / N          = 0.7486
         Verificaci√≥n: 1 - Error            = 0.7486

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5714
         FP-Rate = FP / N                   = 0.2220

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2993
         Recall = TP / P (= TP-Rate)        = 0.5714

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5714
         Especificidad = TN / N             = 0.7780
         Verificaci√≥n: 1 - FP-Rate          = 0.7780

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3929

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: derby-10.5.1.1 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      364       100
            Buggy          26        51
      ==================================================
      TN=364  FP=100  FN=26  TP=51
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 51
         True Negatives  (TN): 364
         False Positives (FP): 100
         False Negatives (FN): 26

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2329
         Exactitud = (TP + TN) / N          = 0.7671
         Verificaci√≥n: 1 - Error            = 0.7671

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6623
         FP-Rate = FP / N                   = 0.2155

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3377
         Recall = TP / P (= TP-Rate)        = 0.6623

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6623
         Especificidad = TN / N             = 0.7845
         Verificaci√≥n: 1 - FP-Rate          = 0.7845

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4474

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.50s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      457         7
            Buggy          73         4
      ==================================================
      TN=457  FP=7  FN=73  TP=4
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 4
         True Negatives  (TN): 457
         False Positives (FP): 7
         False Negatives (FN): 73

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1479
         Exactitud = (TP + TN) / N          = 0.8521
         Verificaci√≥n: 1 - Error            = 0.8521

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0519
         FP-Rate = FP / N                   = 0.0151

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3636
         Recall = TP / P (= TP-Rate)        = 0.0519

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0519
         Especificidad = TN / N             = 0.9849
         Verificaci√≥n: 1 - FP-Rate          = 0.9849

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.0909

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      393        71
            Buggy          39        38
      ==================================================
      TN=393  FP=71  FN=39  TP=38
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 541
         Positivos reales (P):    77 (Buggy)
         Negativos reales (N):    464 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 38
         True Negatives  (TN): 393
         False Positives (FP): 71
         False Negatives (FN): 39

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2033
         Exactitud = (TP + TN) / N          = 0.7967
         Verificaci√≥n: 1 - Error            = 0.7967

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4935
         FP-Rate = FP / N                   = 0.1530

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3486
         Recall = TP / P (= TP-Rate)        = 0.4935

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4935
         Especificidad = TN / N             = 0.8470
         Verificaci√≥n: 1 - FP-Rate          = 0.8470

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4086

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


================================================================================
‚úì PIPELINE COMPLETO PARA derby-10.5.1.1
================================================================================




******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************

================ DATASET: groovy-1_6_BETA_1 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: groovy-1_6_BETA_1
[1] Preprocesamiento - Dimensiones originales: (821, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (821, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (656, 66), X_test: (165, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== Ballanceo [CSBBoost] con groovy-1_6_BETA_1 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 600
    Clase Minoritaria (1): 56
    Total de clases: 656
    Ratio de desbalance: 10.71

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 328

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 272
[Minor√≠a] Tama√±o final (original + sint√©tico): 328

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 656
    Distribuci√≥n clases: {0: 328, 1: 328}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con groovy-1_6_BETA_1 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 600 muestras
    Clase minoritaria (1): 56 muestras
    Total de clases: 656
    Ratio de desbalance: 10.71

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 328

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 272
[Minoritaria] Tama√±o final (original + sint√©tico): 328

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 656
    Distribuci√≥n clases: {0: 328, 1: 328}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con groovy-1_6_BETA_1 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  600
     Clase minoritaria (1):  56
     Total de clases:  656
     Indice de desbalance:  10.71

[SMOTE] Clase mayoritaria (0): 600 -> 328 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 328, 1: 328}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [csbboost] Escalando groovy-1_6_BETA_1 con standard
[3] [csbboost] Escalando groovy-1_6_BETA_1 con robust
[3] [hcbou] Escalando groovy-1_6_BETA_1 con standard
[3] [hcbou] Escalando groovy-1_6_BETA_1 con robust
[3] [smote] Escalando groovy-1_6_BETA_1 con standard
[3] [smote] Escalando groovy-1_6_BETA_1 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH: groovy-1_6_BETA_1
================================================================================

------------------------------------------------------------
Procesando: csbboost_standard
------------------------------------------------------------

‚Üí groovy-1_6_BETA_1 | csbboost | standard

------------------------------------------------------------
Procesando: csbboost_robust
------------------------------------------------------------

‚Üí groovy-1_6_BETA_1 | csbboost | robust

------------------------------------------------------------
Procesando: hcbou_standard
------------------------------------------------------------

‚Üí groovy-1_6_BETA_1 | hcbou | standard

------------------------------------------------------------
Procesando: hcbou_robust
------------------------------------------------------------

‚Üí groovy-1_6_BETA_1 | hcbou | robust

------------------------------------------------------------
Procesando: smote_standard
------------------------------------------------------------

‚Üí groovy-1_6_BETA_1 | smote | standard

------------------------------------------------------------
Procesando: smote_robust
------------------------------------------------------------

‚Üí groovy-1_6_BETA_1 | smote | robust

================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: groovy-1_6_BETA_1
================================================================================

------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      150         1
            Buggy          12         2
      ==================================================
      TN=150  FP=1  FN=12  TP=2
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 2
         True Negatives  (TN): 150
         False Positives (FP): 1
         False Negatives (FN): 12

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0788
         Exactitud = (TP + TN) / N          = 0.9212
         Verificaci√≥n: 1 - Error            = 0.9212

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1429
         FP-Rate = FP / N                   = 0.0066

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6667
         Recall = TP / P (= TP-Rate)        = 0.1429

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1429
         Especificidad = TN / N             = 0.9934
         Verificaci√≥n: 1 - FP-Rate          = 0.9934

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2353

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      140        11
            Buggy          10         4
      ==================================================
      TN=140  FP=11  FN=10  TP=4
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 4
         True Negatives  (TN): 140
         False Positives (FP): 11
         False Negatives (FN): 10

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1273
         Exactitud = (TP + TN) / N          = 0.8727
         Verificaci√≥n: 1 - Error            = 0.8727

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2857
         FP-Rate = FP / N                   = 0.0728

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2667
         Recall = TP / P (= TP-Rate)        = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2857
         Especificidad = TN / N             = 0.9272
         Verificaci√≥n: 1 - FP-Rate          = 0.9272

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2759

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      132        19
            Buggy           8         6
      ==================================================
      TN=132  FP=19  FN=8  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 132
         False Positives (FP): 19
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1636
         Exactitud = (TP + TN) / N          = 0.8364
         Verificaci√≥n: 1 - Error            = 0.8364

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4286
         FP-Rate = FP / N                   = 0.1258

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2400
         Recall = TP / P (= TP-Rate)        = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4286
         Especificidad = TN / N             = 0.8742
         Verificaci√≥n: 1 - FP-Rate          = 0.8742

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3077

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      139        12
            Buggy          11         3
      ==================================================
      TN=139  FP=12  FN=11  TP=3
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 3
         True Negatives  (TN): 139
         False Positives (FP): 12
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1394
         Exactitud = (TP + TN) / N          = 0.8606
         Verificaci√≥n: 1 - Error            = 0.8606

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2143
         FP-Rate = FP / N                   = 0.0795

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2000
         Recall = TP / P (= TP-Rate)        = 0.2143

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2143
         Especificidad = TN / N             = 0.9205
         Verificaci√≥n: 1 - FP-Rate          = 0.9205

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2069

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       151
            Buggy           1        13
      ==================================================
      TN=0  FP=151  FN=1  TP=13
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 13
         True Negatives  (TN): 0
         False Positives (FP): 151
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.9212
         Exactitud = (TP + TN) / N          = 0.0788
         Verificaci√≥n: 1 - Error            = 0.0788

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9286
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0793
         Recall = TP / P (= TP-Rate)        = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9286
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1461

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      132        19
            Buggy           8         6
      ==================================================
      TN=132  FP=19  FN=8  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 132
         False Positives (FP): 19
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1636
         Exactitud = (TP + TN) / N          = 0.8364
         Verificaci√≥n: 1 - Error            = 0.8364

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4286
         FP-Rate = FP / N                   = 0.1258

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2400
         Recall = TP / P (= TP-Rate)        = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4286
         Especificidad = TN / N             = 0.8742
         Verificaci√≥n: 1 - FP-Rate          = 0.8742

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3077

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      144         7
            Buggy          10         4
      ==================================================
      TN=144  FP=7  FN=10  TP=4
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 4
         True Negatives  (TN): 144
         False Positives (FP): 7
         False Negatives (FN): 10

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1030
         Exactitud = (TP + TN) / N          = 0.8970
         Verificaci√≥n: 1 - Error            = 0.8970

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2857
         FP-Rate = FP / N                   = 0.0464

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3636
         Recall = TP / P (= TP-Rate)        = 0.2857

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2857
         Especificidad = TN / N             = 0.9536
         Verificaci√≥n: 1 - FP-Rate          = 0.9536

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3200

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      113        38
            Buggy           4        10
      ==================================================
      TN=113  FP=38  FN=4  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 113
         False Positives (FP): 38
         False Negatives (FN): 4

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2545
         Exactitud = (TP + TN) / N          = 0.7455
         Verificaci√≥n: 1 - Error            = 0.7455

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7143
         FP-Rate = FP / N                   = 0.2517

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2083
         Recall = TP / P (= TP-Rate)        = 0.7143

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7143
         Especificidad = TN / N             = 0.7483
         Verificaci√≥n: 1 - FP-Rate          = 0.7483

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3226

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      135        16
            Buggy           9         5
      ==================================================
      TN=135  FP=16  FN=9  TP=5
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 5
         True Negatives  (TN): 135
         False Positives (FP): 16
         False Negatives (FN): 9

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1515
         Exactitud = (TP + TN) / N          = 0.8485
         Verificaci√≥n: 1 - Error            = 0.8485

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3571
         FP-Rate = FP / N                   = 0.1060

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2381
         Recall = TP / P (= TP-Rate)        = 0.3571

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3571
         Especificidad = TN / N             = 0.8940
         Verificaci√≥n: 1 - FP-Rate          = 0.8940

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2857

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      139        12
            Buggy           7         7
      ==================================================
      TN=139  FP=12  FN=7  TP=7
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 7
         True Negatives  (TN): 139
         False Positives (FP): 12
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1152
         Exactitud = (TP + TN) / N          = 0.8848
         Verificaci√≥n: 1 - Error            = 0.8848

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5000
         FP-Rate = FP / N                   = 0.0795

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3684
         Recall = TP / P (= TP-Rate)        = 0.5000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5000
         Especificidad = TN / N             = 0.9205
         Verificaci√≥n: 1 - FP-Rate          = 0.9205

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4242

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       151
            Buggy           1        13
      ==================================================
      TN=0  FP=151  FN=1  TP=13
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 13
         True Negatives  (TN): 0
         False Positives (FP): 151
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.9212
         Exactitud = (TP + TN) / N          = 0.0788
         Verificaci√≥n: 1 - Error            = 0.0788

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9286
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0793
         Recall = TP / P (= TP-Rate)        = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9286
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1461

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      135        16
            Buggy           9         5
      ==================================================
      TN=135  FP=16  FN=9  TP=5
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 5
         True Negatives  (TN): 135
         False Positives (FP): 16
         False Negatives (FN): 9

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1515
         Exactitud = (TP + TN) / N          = 0.8485
         Verificaci√≥n: 1 - Error            = 0.8485

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3571
         FP-Rate = FP / N                   = 0.1060

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2381
         Recall = TP / P (= TP-Rate)        = 0.3571

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3571
         Especificidad = TN / N             = 0.8940
         Verificaci√≥n: 1 - FP-Rate          = 0.8940

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2857

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      141        10
            Buggy           8         6
      ==================================================
      TN=141  FP=10  FN=8  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 141
         False Positives (FP): 10
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1091
         Exactitud = (TP + TN) / N          = 0.8909
         Verificaci√≥n: 1 - Error            = 0.8909

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4286
         FP-Rate = FP / N                   = 0.0662

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3750
         Recall = TP / P (= TP-Rate)        = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4286
         Especificidad = TN / N             = 0.9338
         Verificaci√≥n: 1 - FP-Rate          = 0.9338

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4000

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-06}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      133        18
            Buggy           9         5
      ==================================================
      TN=133  FP=18  FN=9  TP=5
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 5
         True Negatives  (TN): 133
         False Positives (FP): 18
         False Negatives (FN): 9

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1636
         Exactitud = (TP + TN) / N          = 0.8364
         Verificaci√≥n: 1 - Error            = 0.8364

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3571
         FP-Rate = FP / N                   = 0.1192

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2174
         Recall = TP / P (= TP-Rate)        = 0.3571

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3571
         Especificidad = TN / N             = 0.8808
         Verificaci√≥n: 1 - FP-Rate          = 0.8808

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2703

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      136        15
            Buggy           8         6
      ==================================================
      TN=136  FP=15  FN=8  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 136
         False Positives (FP): 15
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1394
         Exactitud = (TP + TN) / N          = 0.8606
         Verificaci√≥n: 1 - Error            = 0.8606

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4286
         FP-Rate = FP / N                   = 0.0993

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2857
         Recall = TP / P (= TP-Rate)        = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4286
         Especificidad = TN / N             = 0.9007
         Verificaci√≥n: 1 - FP-Rate          = 0.9007

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3429

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: groovy-1_6_BETA_1 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      138        13
            Buggy           8         6
      ==================================================
      TN=138  FP=13  FN=8  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 138
         False Positives (FP): 13
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1273
         Exactitud = (TP + TN) / N          = 0.8727
         Verificaci√≥n: 1 - Error            = 0.8727

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4286
         FP-Rate = FP / N                   = 0.0861

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3158
         Recall = TP / P (= TP-Rate)        = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4286
         Especificidad = TN / N             = 0.9139
         Verificaci√≥n: 1 - FP-Rate          = 0.9139

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3636

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        0       151
            Buggy           1        13
      ==================================================
      TN=0  FP=151  FN=1  TP=13
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 13
         True Negatives  (TN): 0
         False Positives (FP): 151
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.9212
         Exactitud = (TP + TN) / N          = 0.0788
         Verificaci√≥n: 1 - Error            = 0.0788

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9286
         FP-Rate = FP / N                   = 1.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 0.0793
         Recall = TP / P (= TP-Rate)        = 0.9286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9286
         Especificidad = TN / N             = 0.0000
         Verificaci√≥n: 1 - FP-Rate          = 0.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1461

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      137        14
            Buggy           8         6
      ==================================================
      TN=137  FP=14  FN=8  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 165
         Positivos reales (P):    14 (Buggy)
         Negativos reales (N):    151 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 137
         False Positives (FP): 14
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1333
         Exactitud = (TP + TN) / N          = 0.8667
         Verificaci√≥n: 1 - Error            = 0.8667

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4286
         FP-Rate = FP / N                   = 0.0927

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3000
         Recall = TP / P (= TP-Rate)        = 0.4286

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4286
         Especificidad = TN / N             = 0.9073
         Verificaci√≥n: 1 - FP-Rate          = 0.9073

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3529

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


================================================================================
‚úì PIPELINE COMPLETO PARA groovy-1_6_BETA_1
================================================================================




******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************

================ DATASET: hbase-0.94.0 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: hbase-0.94.0
[1] Preprocesamiento - Dimensiones originales: (1059, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1059, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (847, 66), X_test: (212, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== Ballanceo [CSBBoost] con hbase-0.94.0 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 673
    Clase Minoritaria (1): 174
    Total de clases: 847
    Ratio de desbalance: 3.87

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 424

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 248
[Minor√≠a] Tama√±o final (original + sint√©tico): 422

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 846
    Distribuci√≥n clases: {0: 424, 1: 422}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con hbase-0.94.0 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 673 muestras
    Clase minoritaria (1): 174 muestras
    Total de clases: 847
    Ratio de desbalance: 3.87

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 423

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 249
[Minoritaria] Tama√±o final (original + sint√©tico): 423

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 846
    Distribuci√≥n clases: {0: 423, 1: 423}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con hbase-0.94.0 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  673
     Clase minoritaria (1):  174
     Total de clases:  847
     Indice de desbalance:  3.87

[SMOTE] Clase mayoritaria (0): 673 -> 423 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 423, 1: 423}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [csbboost] Escalando hbase-0.94.0 con standard
[3] [csbboost] Escalando hbase-0.94.0 con robust
[3] [hcbou] Escalando hbase-0.94.0 con standard
[3] [hcbou] Escalando hbase-0.94.0 con robust
[3] [smote] Escalando hbase-0.94.0 con standard
[3] [smote] Escalando hbase-0.94.0 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH: hbase-0.94.0
================================================================================

------------------------------------------------------------
Procesando: csbboost_standard
------------------------------------------------------------

‚Üí hbase-0.94.0 | csbboost | standard

------------------------------------------------------------
Procesando: csbboost_robust
------------------------------------------------------------

‚Üí hbase-0.94.0 | csbboost | robust

------------------------------------------------------------
Procesando: hcbou_standard
------------------------------------------------------------

‚Üí hbase-0.94.0 | hcbou | standard

------------------------------------------------------------
Procesando: hcbou_robust
------------------------------------------------------------

‚Üí hbase-0.94.0 | hcbou | robust

------------------------------------------------------------
Procesando: smote_standard
------------------------------------------------------------

‚Üí hbase-0.94.0 | smote | standard

------------------------------------------------------------
Procesando: smote_robust
------------------------------------------------------------

‚Üí hbase-0.94.0 | smote | robust

================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: hbase-0.94.0
================================================================================

------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      145        23
            Buggy          24        20
      ==================================================
      TN=145  FP=23  FN=24  TP=20
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 20
         True Negatives  (TN): 145
         False Positives (FP): 23
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2217
         Exactitud = (TP + TN) / N          = 0.7783
         Verificaci√≥n: 1 - Error            = 0.7783

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4545
         FP-Rate = FP / N                   = 0.1369

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4651
         Recall = TP / P (= TP-Rate)        = 0.4545

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4545
         Especificidad = TN / N             = 0.8631
         Verificaci√≥n: 1 - FP-Rate          = 0.8631

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4598

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.06s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      136        32
            Buggy          23        21
      ==================================================
      TN=136  FP=32  FN=23  TP=21
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 21
         True Negatives  (TN): 136
         False Positives (FP): 32
         False Negatives (FN): 23

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2594
         Exactitud = (TP + TN) / N          = 0.7406
         Verificaci√≥n: 1 - Error            = 0.7406

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4773
         FP-Rate = FP / N                   = 0.1905

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3962
         Recall = TP / P (= TP-Rate)        = 0.4773

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4773
         Especificidad = TN / N             = 0.8095
         Verificaci√≥n: 1 - FP-Rate          = 0.8095

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4330

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      142        26
            Buggy          15        29
      ==================================================
      TN=142  FP=26  FN=15  TP=29
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 29
         True Negatives  (TN): 142
         False Positives (FP): 26
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1934
         Exactitud = (TP + TN) / N          = 0.8066
         Verificaci√≥n: 1 - Error            = 0.8066

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6591
         FP-Rate = FP / N                   = 0.1548

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5273
         Recall = TP / P (= TP-Rate)        = 0.6591

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6591
         Especificidad = TN / N             = 0.8452
         Verificaci√≥n: 1 - FP-Rate          = 0.8452

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5859

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      146        22
            Buggy          17        27
      ==================================================
      TN=146  FP=22  FN=17  TP=27
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 27
         True Negatives  (TN): 146
         False Positives (FP): 22
         False Negatives (FN): 17

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1840
         Exactitud = (TP + TN) / N          = 0.8160
         Verificaci√≥n: 1 - Error            = 0.8160

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6136
         FP-Rate = FP / N                   = 0.1310

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5510
         Recall = TP / P (= TP-Rate)        = 0.6136

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6136
         Especificidad = TN / N             = 0.8690
         Verificaci√≥n: 1 - FP-Rate          = 0.8690

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5806

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.12s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        2       166
            Buggy           1        43
      ==================================================
      TN=2  FP=166  FN=1  TP=43
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 43
         True Negatives  (TN): 2
         False Positives (FP): 166
         False Negatives (FN): 1

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.7877
         Exactitud = (TP + TN) / N          = 0.2123
         Verificaci√≥n: 1 - Error            = 0.2123

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.9773
         FP-Rate = FP / N                   = 0.9881

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2057
         Recall = TP / P (= TP-Rate)        = 0.9773

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.9773
         Especificidad = TN / N             = 0.0119
         Verificaci√≥n: 1 - FP-Rate          = 0.0119

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3399

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      143        25
            Buggy          15        29
      ==================================================
      TN=143  FP=25  FN=15  TP=29
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 29
         True Negatives  (TN): 143
         False Positives (FP): 25
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1887
         Exactitud = (TP + TN) / N          = 0.8113
         Verificaci√≥n: 1 - Error            = 0.8113

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6591
         FP-Rate = FP / N                   = 0.1488

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5370
         Recall = TP / P (= TP-Rate)        = 0.6591

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6591
         Especificidad = TN / N             = 0.8512
         Verificaci√≥n: 1 - FP-Rate          = 0.8512

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5918

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      149        19
            Buggy          17        27
      ==================================================
      TN=149  FP=19  FN=17  TP=27
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 27
         True Negatives  (TN): 149
         False Positives (FP): 19
         False Negatives (FN): 17

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1698
         Exactitud = (TP + TN) / N          = 0.8302
         Verificaci√≥n: 1 - Error            = 0.8302

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6136
         FP-Rate = FP / N                   = 0.1131

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5870
         Recall = TP / P (= TP-Rate)        = 0.6136

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6136
         Especificidad = TN / N             = 0.8869
         Verificaci√≥n: 1 - FP-Rate          = 0.8869

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6000

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.07s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      130        38
            Buggy          12        32
      ==================================================
      TN=130  FP=38  FN=12  TP=32
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 32
         True Negatives  (TN): 130
         False Positives (FP): 38
         False Negatives (FN): 12

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2358
         Exactitud = (TP + TN) / N          = 0.7642
         Verificaci√≥n: 1 - Error            = 0.7642

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7273
         FP-Rate = FP / N                   = 0.2262

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4571
         Recall = TP / P (= TP-Rate)        = 0.7273

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7273
         Especificidad = TN / N             = 0.7738
         Verificaci√≥n: 1 - FP-Rate          = 0.7738

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5614

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      142        26
            Buggy          18        26
      ==================================================
      TN=142  FP=26  FN=18  TP=26
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 26
         True Negatives  (TN): 142
         False Positives (FP): 26
         False Negatives (FN): 18

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2075
         Exactitud = (TP + TN) / N          = 0.7925
         Verificaci√≥n: 1 - Error            = 0.7925

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5909
         FP-Rate = FP / N                   = 0.1548

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5000
         Recall = TP / P (= TP-Rate)        = 0.5909

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5909
         Especificidad = TN / N             = 0.8452
         Verificaci√≥n: 1 - FP-Rate          = 0.8452

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5417

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      131        37
            Buggy          13        31
      ==================================================
      TN=131  FP=37  FN=13  TP=31
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 31
         True Negatives  (TN): 131
         False Positives (FP): 37
         False Negatives (FN): 13

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2358
         Exactitud = (TP + TN) / N          = 0.7642
         Verificaci√≥n: 1 - Error            = 0.7642

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7045
         FP-Rate = FP / N                   = 0.2202

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4559
         Recall = TP / P (= TP-Rate)        = 0.7045

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7045
         Especificidad = TN / N             = 0.7798
         Verificaci√≥n: 1 - FP-Rate          = 0.7798

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5536

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.08s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        1       167
            Buggy           0        44
      ==================================================
      TN=1  FP=167  FN=0  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 1
         False Positives (FP): 167
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.7877
         Exactitud = (TP + TN) / N          = 0.2123
         Verificaci√≥n: 1 - Error            = 0.2123

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 0.9940

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2085
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0060
         Verificaci√≥n: 1 - FP-Rate          = 0.0060

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3451

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      142        26
            Buggy          18        26
      ==================================================
      TN=142  FP=26  FN=18  TP=26
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 26
         True Negatives  (TN): 142
         False Positives (FP): 26
         False Negatives (FN): 18

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2075
         Exactitud = (TP + TN) / N          = 0.7925
         Verificaci√≥n: 1 - Error            = 0.7925

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5909
         FP-Rate = FP / N                   = 0.1548

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5000
         Recall = TP / P (= TP-Rate)        = 0.5909

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5909
         Especificidad = TN / N             = 0.8452
         Verificaci√≥n: 1 - FP-Rate          = 0.8452

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5417

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      139        29
            Buggy          22        22
      ==================================================
      TN=139  FP=29  FN=22  TP=22
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 22
         True Negatives  (TN): 139
         False Positives (FP): 29
         False Negatives (FN): 22

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2406
         Exactitud = (TP + TN) / N          = 0.7594
         Verificaci√≥n: 1 - Error            = 0.7594

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5000
         FP-Rate = FP / N                   = 0.1726

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4314
         Recall = TP / P (= TP-Rate)        = 0.5000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5000
         Especificidad = TN / N             = 0.8274
         Verificaci√≥n: 1 - FP-Rate          = 0.8274

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4632

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.07s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 0.0001}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      140        28
            Buggy          24        20
      ==================================================
      TN=140  FP=28  FN=24  TP=20
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 20
         True Negatives  (TN): 140
         False Positives (FP): 28
         False Negatives (FN): 24

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2453
         Exactitud = (TP + TN) / N          = 0.7547
         Verificaci√≥n: 1 - Error            = 0.7547

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4545
         FP-Rate = FP / N                   = 0.1667

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4167
         Recall = TP / P (= TP-Rate)        = 0.4545

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4545
         Especificidad = TN / N             = 0.8333
         Verificaci√≥n: 1 - FP-Rate          = 0.8333

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4348

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      137        31
            Buggy          11        33
      ==================================================
      TN=137  FP=31  FN=11  TP=33
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 33
         True Negatives  (TN): 137
         False Positives (FP): 31
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1981
         Exactitud = (TP + TN) / N          = 0.8019
         Verificaci√≥n: 1 - Error            = 0.8019

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7500
         FP-Rate = FP / N                   = 0.1845

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5156
         Recall = TP / P (= TP-Rate)        = 0.7500

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7500
         Especificidad = TN / N             = 0.8155
         Verificaci√≥n: 1 - FP-Rate          = 0.8155

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6111

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hbase-0.94.0 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      129        39
            Buggy          17        27
      ==================================================
      TN=129  FP=39  FN=17  TP=27
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 27
         True Negatives  (TN): 129
         False Positives (FP): 39
         False Negatives (FN): 17

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2642
         Exactitud = (TP + TN) / N          = 0.7358
         Verificaci√≥n: 1 - Error            = 0.7358

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6136
         FP-Rate = FP / N                   = 0.2321

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4091
         Recall = TP / P (= TP-Rate)        = 0.6136

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6136
         Especificidad = TN / N             = 0.7679
         Verificaci√≥n: 1 - FP-Rate          = 0.7679

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4909

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.06s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy        1       167
            Buggy           0        44
      ==================================================
      TN=1  FP=167  FN=0  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 1
         False Positives (FP): 167
         False Negatives (FN): 0

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.7877
         Exactitud = (TP + TN) / N          = 0.2123
         Verificaci√≥n: 1 - Error            = 0.2123

      üé≤ Tasas:
         TP-Rate = TP / P                   = 1.0000
         FP-Rate = FP / N                   = 0.9940

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2085
         Recall = TP / P (= TP-Rate)        = 1.0000

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 1.0000
         Especificidad = TN / N             = 0.0060
         Verificaci√≥n: 1 - FP-Rate          = 0.0060

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3451

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      137        31
            Buggy          11        33
      ==================================================
      TN=137  FP=31  FN=11  TP=33
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 212
         Positivos reales (P):    44 (Buggy)
         Negativos reales (N):    168 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 33
         True Negatives  (TN): 137
         False Positives (FP): 31
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1981
         Exactitud = (TP + TN) / N          = 0.8019
         Verificaci√≥n: 1 - Error            = 0.8019

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7500
         FP-Rate = FP / N                   = 0.1845

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5156
         Recall = TP / P (= TP-Rate)        = 0.7500

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7500
         Especificidad = TN / N             = 0.8155
         Verificaci√≥n: 1 - FP-Rate          = 0.8155

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6111

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


================================================================================
‚úì PIPELINE COMPLETO PARA hbase-0.94.0
================================================================================




******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************

================ DATASET: hive-0.9.0 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: hive-0.9.0
[1] Preprocesamiento - Dimensiones originales: (1416, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1416, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (1132, 66), X_test: (284, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== Ballanceo [CSBBoost] con hive-0.9.0 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 906
    Clase Minoritaria (1): 226
    Total de clases: 1132
    Ratio de desbalance: 4.01

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 566

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 3
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 339
[Minor√≠a] Tama√±o final (original + sint√©tico): 565

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 1131
    Distribuci√≥n clases: {0: 566, 1: 565}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con hive-0.9.0 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 906 muestras
    Clase minoritaria (1): 226 muestras
    Total de clases: 1132
    Ratio de desbalance: 4.01

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 566

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 340
[Minoritaria] Tama√±o final (original + sint√©tico): 566

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 1132
    Distribuci√≥n clases: {0: 566, 1: 566}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con hive-0.9.0 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  906
     Clase minoritaria (1):  226
     Total de clases:  1132
     Indice de desbalance:  4.01

[SMOTE] Clase mayoritaria (0): 906 -> 566 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 566, 1: 566}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [csbboost] Escalando hive-0.9.0 con standard
[3] [csbboost] Escalando hive-0.9.0 con robust
[3] [hcbou] Escalando hive-0.9.0 con standard
[3] [hcbou] Escalando hive-0.9.0 con robust
[3] [smote] Escalando hive-0.9.0 con standard
[3] [smote] Escalando hive-0.9.0 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH: hive-0.9.0
================================================================================

------------------------------------------------------------
Procesando: csbboost_standard
------------------------------------------------------------

‚Üí hive-0.9.0 | csbboost | standard

------------------------------------------------------------
Procesando: csbboost_robust
------------------------------------------------------------

‚Üí hive-0.9.0 | csbboost | robust

------------------------------------------------------------
Procesando: hcbou_standard
------------------------------------------------------------

‚Üí hive-0.9.0 | hcbou | standard

------------------------------------------------------------
Procesando: hcbou_robust
------------------------------------------------------------

‚Üí hive-0.9.0 | hcbou | robust

------------------------------------------------------------
Procesando: smote_standard
------------------------------------------------------------

‚Üí hive-0.9.0 | smote | standard

------------------------------------------------------------
Procesando: smote_robust
------------------------------------------------------------

‚Üí hive-0.9.0 | smote | robust

================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: hive-0.9.0
================================================================================

------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      192        35
            Buggy          27        30
      ==================================================
      TN=192  FP=35  FN=27  TP=30
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 30
         True Negatives  (TN): 192
         False Positives (FP): 35
         False Negatives (FN): 27

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2183
         Exactitud = (TP + TN) / N          = 0.7817
         Verificaci√≥n: 1 - Error            = 0.7817

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5263
         FP-Rate = FP / N                   = 0.1542

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4615
         Recall = TP / P (= TP-Rate)        = 0.5263

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5263
         Especificidad = TN / N             = 0.8458
         Verificaci√≥n: 1 - FP-Rate          = 0.8458

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4918

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.17s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      221         6
            Buggy          42        15
      ==================================================
      TN=221  FP=6  FN=42  TP=15
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 15
         True Negatives  (TN): 221
         False Positives (FP): 6
         False Negatives (FN): 42

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1690
         Exactitud = (TP + TN) / N          = 0.8310
         Verificaci√≥n: 1 - Error            = 0.8310

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2632
         FP-Rate = FP / N                   = 0.0264

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7143
         Recall = TP / P (= TP-Rate)        = 0.2632

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2632
         Especificidad = TN / N             = 0.9736
         Verificaci√≥n: 1 - FP-Rate          = 0.9736

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3846

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      185        42
            Buggy          13        44
      ==================================================
      TN=185  FP=42  FN=13  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 185
         False Positives (FP): 42
         False Negatives (FN): 13

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1937
         Exactitud = (TP + TN) / N          = 0.8063
         Verificaci√≥n: 1 - Error            = 0.8063

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7719
         FP-Rate = FP / N                   = 0.1850

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5116
         Recall = TP / P (= TP-Rate)        = 0.7719

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7719
         Especificidad = TN / N             = 0.8150
         Verificaci√≥n: 1 - FP-Rate          = 0.8150

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6154

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      189        38
            Buggy          19        38
      ==================================================
      TN=189  FP=38  FN=19  TP=38
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 38
         True Negatives  (TN): 189
         False Positives (FP): 38
         False Negatives (FN): 19

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2007
         Exactitud = (TP + TN) / N          = 0.7993
         Verificaci√≥n: 1 - Error            = 0.7993

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6667
         FP-Rate = FP / N                   = 0.1674

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5000
         Recall = TP / P (= TP-Rate)        = 0.6667

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6667
         Especificidad = TN / N             = 0.8326
         Verificaci√≥n: 1 - FP-Rate          = 0.8326

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5714

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.14s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      223         4
            Buggy          48         9
      ==================================================
      TN=223  FP=4  FN=48  TP=9
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 9
         True Negatives  (TN): 223
         False Positives (FP): 4
         False Negatives (FN): 48

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1831
         Exactitud = (TP + TN) / N          = 0.8169
         Verificaci√≥n: 1 - Error            = 0.8169

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1579
         FP-Rate = FP / N                   = 0.0176

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6923
         Recall = TP / P (= TP-Rate)        = 0.1579

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1579
         Especificidad = TN / N             = 0.9824
         Verificaci√≥n: 1 - FP-Rate          = 0.9824

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2571

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      185        42
            Buggy          13        44
      ==================================================
      TN=185  FP=42  FN=13  TP=44
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 44
         True Negatives  (TN): 185
         False Positives (FP): 42
         False Negatives (FN): 13

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1937
         Exactitud = (TP + TN) / N          = 0.8063
         Verificaci√≥n: 1 - Error            = 0.8063

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7719
         FP-Rate = FP / N                   = 0.1850

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5116
         Recall = TP / P (= TP-Rate)        = 0.7719

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7719
         Especificidad = TN / N             = 0.8150
         Verificaci√≥n: 1 - FP-Rate          = 0.8150

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6154

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      209        18
            Buggy          29        28
      ==================================================
      TN=209  FP=18  FN=29  TP=28
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 28
         True Negatives  (TN): 209
         False Positives (FP): 18
         False Negatives (FN): 29

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1655
         Exactitud = (TP + TN) / N          = 0.8345
         Verificaci√≥n: 1 - Error            = 0.8345

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4912
         FP-Rate = FP / N                   = 0.0793

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6087
         Recall = TP / P (= TP-Rate)        = 0.4912

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4912
         Especificidad = TN / N             = 0.9207
         Verificaci√≥n: 1 - FP-Rate          = 0.9207

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5437

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.11s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      223         4
            Buggy          43        14
      ==================================================
      TN=223  FP=4  FN=43  TP=14
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 14
         True Negatives  (TN): 223
         False Positives (FP): 4
         False Negatives (FN): 43

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1655
         Exactitud = (TP + TN) / N          = 0.8345
         Verificaci√≥n: 1 - Error            = 0.8345

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2456
         FP-Rate = FP / N                   = 0.0176

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7778
         Recall = TP / P (= TP-Rate)        = 0.2456

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2456
         Especificidad = TN / N             = 0.9824
         Verificaci√≥n: 1 - FP-Rate          = 0.9824

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3733

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      175        52
            Buggy          16        41
      ==================================================
      TN=175  FP=52  FN=16  TP=41
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 41
         True Negatives  (TN): 175
         False Positives (FP): 52
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2394
         Exactitud = (TP + TN) / N          = 0.7606
         Verificaci√≥n: 1 - Error            = 0.7606

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7193
         FP-Rate = FP / N                   = 0.2291

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4409
         Recall = TP / P (= TP-Rate)        = 0.7193

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7193
         Especificidad = TN / N             = 0.7709
         Verificaci√≥n: 1 - FP-Rate          = 0.7709

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5467

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      191        36
            Buggy          19        38
      ==================================================
      TN=191  FP=36  FN=19  TP=38
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 38
         True Negatives  (TN): 191
         False Positives (FP): 36
         False Negatives (FN): 19

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1937
         Exactitud = (TP + TN) / N          = 0.8063
         Verificaci√≥n: 1 - Error            = 0.8063

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6667
         FP-Rate = FP / N                   = 0.1586

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5135
         Recall = TP / P (= TP-Rate)        = 0.6667

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6667
         Especificidad = TN / N             = 0.8414
         Verificaci√≥n: 1 - FP-Rate          = 0.8414

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5802

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.12s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      224         3
            Buggy          49         8
      ==================================================
      TN=224  FP=3  FN=49  TP=8
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 8
         True Negatives  (TN): 224
         False Positives (FP): 3
         False Negatives (FN): 49

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1831
         Exactitud = (TP + TN) / N          = 0.8169
         Verificaci√≥n: 1 - Error            = 0.8169

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1404
         FP-Rate = FP / N                   = 0.0132

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7273
         Recall = TP / P (= TP-Rate)        = 0.1404

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1404
         Especificidad = TN / N             = 0.9868
         Verificaci√≥n: 1 - FP-Rate          = 0.9868

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2353

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      175        52
            Buggy          16        41
      ==================================================
      TN=175  FP=52  FN=16  TP=41
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 41
         True Negatives  (TN): 175
         False Positives (FP): 52
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2394
         Exactitud = (TP + TN) / N          = 0.7606
         Verificaci√≥n: 1 - Error            = 0.7606

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7193
         FP-Rate = FP / N                   = 0.2291

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4409
         Recall = TP / P (= TP-Rate)        = 0.7193

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7193
         Especificidad = TN / N             = 0.7709
         Verificaci√≥n: 1 - FP-Rate          = 0.7709

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5467

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      200        27
            Buggy          22        35
      ==================================================
      TN=200  FP=27  FN=22  TP=35
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 35
         True Negatives  (TN): 200
         False Positives (FP): 27
         False Negatives (FN): 22

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1725
         Exactitud = (TP + TN) / N          = 0.8275
         Verificaci√≥n: 1 - Error            = 0.8275

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6140
         FP-Rate = FP / N                   = 0.1189

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5645
         Recall = TP / P (= TP-Rate)        = 0.6140

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6140
         Especificidad = TN / N             = 0.8811
         Verificaci√≥n: 1 - FP-Rate          = 0.8811

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5882

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.11s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      218         9
            Buggy          40        17
      ==================================================
      TN=218  FP=9  FN=40  TP=17
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 17
         True Negatives  (TN): 218
         False Positives (FP): 9
         False Negatives (FN): 40

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1725
         Exactitud = (TP + TN) / N          = 0.8275
         Verificaci√≥n: 1 - Error            = 0.8275

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2982
         FP-Rate = FP / N                   = 0.0396

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6538
         Recall = TP / P (= TP-Rate)        = 0.2982

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2982
         Especificidad = TN / N             = 0.9604
         Verificaci√≥n: 1 - FP-Rate          = 0.9604

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4096

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      171        56
            Buggy          15        42
      ==================================================
      TN=171  FP=56  FN=15  TP=42
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 42
         True Negatives  (TN): 171
         False Positives (FP): 56
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2500
         Exactitud = (TP + TN) / N          = 0.7500
         Verificaci√≥n: 1 - Error            = 0.7500

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7368
         FP-Rate = FP / N                   = 0.2467

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4286
         Recall = TP / P (= TP-Rate)        = 0.7368

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7368
         Especificidad = TN / N             = 0.7533
         Verificaci√≥n: 1 - FP-Rate          = 0.7533

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5419

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: hive-0.9.0 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      191        36
            Buggy          16        41
      ==================================================
      TN=191  FP=36  FN=16  TP=41
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 41
         True Negatives  (TN): 191
         False Positives (FP): 36
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1831
         Exactitud = (TP + TN) / N          = 0.8169
         Verificaci√≥n: 1 - Error            = 0.8169

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7193
         FP-Rate = FP / N                   = 0.1586

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5325
         Recall = TP / P (= TP-Rate)        = 0.7193

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7193
         Especificidad = TN / N             = 0.8414
         Verificaci√≥n: 1 - FP-Rate          = 0.8414

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6119

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.10s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      222         5
            Buggy          50         7
      ==================================================
      TN=222  FP=5  FN=50  TP=7
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 7
         True Negatives  (TN): 222
         False Positives (FP): 5
         False Negatives (FN): 50

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1937
         Exactitud = (TP + TN) / N          = 0.8063
         Verificaci√≥n: 1 - Error            = 0.8063

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1228
         FP-Rate = FP / N                   = 0.0220

      üîç Precision y Recall:
         Precision = TP / P'                = 0.5833
         Recall = TP / P (= TP-Rate)        = 0.1228

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1228
         Especificidad = TN / N             = 0.9780
         Verificaci√≥n: 1 - FP-Rate          = 0.9780

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2029

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 20}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      171        56
            Buggy          15        42
      ==================================================
      TN=171  FP=56  FN=15  TP=42
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 284
         Positivos reales (P):    57 (Buggy)
         Negativos reales (N):    227 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 42
         True Negatives  (TN): 171
         False Positives (FP): 56
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2500
         Exactitud = (TP + TN) / N          = 0.7500
         Verificaci√≥n: 1 - Error            = 0.7500

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.7368
         FP-Rate = FP / N                   = 0.2467

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4286
         Recall = TP / P (= TP-Rate)        = 0.7368

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.7368
         Especificidad = TN / N             = 0.7533
         Verificaci√≥n: 1 - FP-Rate          = 0.7533

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5419

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


================================================================================
‚úì PIPELINE COMPLETO PARA hive-0.9.0
================================================================================




******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************

================ DATASET: jruby-1.1 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: jruby-1.1
[1] Preprocesamiento - Dimensiones originales: (731, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (731, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (584, 66), X_test: (147, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== Ballanceo [CSBBoost] con jruby-1.1 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 514
    Clase Minoritaria (1): 70
    Total de clases: 584
    Ratio de desbalance: 7.34

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 292

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 222
[Minor√≠a] Tama√±o final (original + sint√©tico): 292

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 584
    Distribuci√≥n clases: {0: 292, 1: 292}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con jruby-1.1 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 514 muestras
    Clase minoritaria (1): 70 muestras
    Total de clases: 584
    Ratio de desbalance: 7.34

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 292

Clase minoritarias---------
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 1
[Minoritaria] Nuevas muestras sint√©ticas generadas: 222
[Minoritaria] Tama√±o final (original + sint√©tico): 292

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 584
    Distribuci√≥n clases: {0: 292, 1: 292}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con jruby-1.1 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  514
     Clase minoritaria (1):  70
     Total de clases:  584
     Indice de desbalance:  7.34

[SMOTE] Clase mayoritaria (0): 514 -> 292 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 292, 1: 292}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [csbboost] Escalando jruby-1.1 con standard
[3] [csbboost] Escalando jruby-1.1 con robust
[3] [hcbou] Escalando jruby-1.1 con standard
[3] [hcbou] Escalando jruby-1.1 con robust
[3] [smote] Escalando jruby-1.1 con standard
[3] [smote] Escalando jruby-1.1 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH: jruby-1.1
================================================================================

------------------------------------------------------------
Procesando: csbboost_standard
------------------------------------------------------------

‚Üí jruby-1.1 | csbboost | standard

------------------------------------------------------------
Procesando: csbboost_robust
------------------------------------------------------------

‚Üí jruby-1.1 | csbboost | robust

------------------------------------------------------------
Procesando: hcbou_standard
------------------------------------------------------------

‚Üí jruby-1.1 | hcbou | standard

------------------------------------------------------------
Procesando: hcbou_robust
------------------------------------------------------------

‚Üí jruby-1.1 | hcbou | robust

------------------------------------------------------------
Procesando: smote_standard
------------------------------------------------------------

‚Üí jruby-1.1 | smote | standard

------------------------------------------------------------
Procesando: smote_robust
------------------------------------------------------------

‚Üí jruby-1.1 | smote | robust

================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: jruby-1.1
================================================================================

------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      126         4
            Buggy          11         6
      ==================================================
      TN=126  FP=4  FN=11  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 126
         False Positives (FP): 4
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1020
         Exactitud = (TP + TN) / N          = 0.8980
         Verificaci√≥n: 1 - Error            = 0.8980

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3529
         FP-Rate = FP / N                   = 0.0308

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6000
         Recall = TP / P (= TP-Rate)        = 0.3529

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3529
         Especificidad = TN / N             = 0.9692
         Verificaci√≥n: 1 - FP-Rate          = 0.9692

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4444

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      123         7
            Buggy           6        11
      ==================================================
      TN=123  FP=7  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 123
         False Positives (FP): 7
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0884
         Exactitud = (TP + TN) / N          = 0.9116
         Verificaci√≥n: 1 - Error            = 0.9116

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.0538

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6111
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.9462
         Verificaci√≥n: 1 - FP-Rate          = 0.9462

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6286

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      119        11
            Buggy           7        10
      ==================================================
      TN=119  FP=11  FN=7  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 119
         False Positives (FP): 11
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1224
         Exactitud = (TP + TN) / N          = 0.8776
         Verificaci√≥n: 1 - Error            = 0.8776

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5882
         FP-Rate = FP / N                   = 0.0846

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4762
         Recall = TP / P (= TP-Rate)        = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5882
         Especificidad = TN / N             = 0.9154
         Verificaci√≥n: 1 - FP-Rate          = 0.9154

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5263

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      111        19
            Buggy           6        11
      ==================================================
      TN=111  FP=19  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 111
         False Positives (FP): 19
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1701
         Exactitud = (TP + TN) / N          = 0.8299
         Verificaci√≥n: 1 - Error            = 0.8299

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.1462

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3667
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.8538
         Verificaci√≥n: 1 - FP-Rate          = 0.8538

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4681

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      130         0
            Buggy          16         1
      ==================================================
      TN=130  FP=0  FN=16  TP=1
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 1
         True Negatives  (TN): 130
         False Positives (FP): 0
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1088
         Exactitud = (TP + TN) / N          = 0.8912
         Verificaci√≥n: 1 - Error            = 0.8912

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0588
         FP-Rate = FP / N                   = 0.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 1.0000
         Recall = TP / P (= TP-Rate)        = 0.0588

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0588
         Especificidad = TN / N             = 1.0000
         Verificaci√≥n: 1 - FP-Rate          = 1.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1111

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      119        11
            Buggy           7        10
      ==================================================
      TN=119  FP=11  FN=7  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 119
         False Positives (FP): 11
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1224
         Exactitud = (TP + TN) / N          = 0.8776
         Verificaci√≥n: 1 - Error            = 0.8776

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5882
         FP-Rate = FP / N                   = 0.0846

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4762
         Recall = TP / P (= TP-Rate)        = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5882
         Especificidad = TN / N             = 0.9154
         Verificaci√≥n: 1 - FP-Rate          = 0.9154

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5263

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      128         2
            Buggy          11         6
      ==================================================
      TN=128  FP=2  FN=11  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 128
         False Positives (FP): 2
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0884
         Exactitud = (TP + TN) / N          = 0.9116
         Verificaci√≥n: 1 - Error            = 0.9116

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3529
         FP-Rate = FP / N                   = 0.0154

      üîç Precision y Recall:
         Precision = TP / P'                = 0.7500
         Recall = TP / P (= TP-Rate)        = 0.3529

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3529
         Especificidad = TN / N             = 0.9846
         Verificaci√≥n: 1 - FP-Rate          = 0.9846

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4800

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      124         6
            Buggy           6        11
      ==================================================
      TN=124  FP=6  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 124
         False Positives (FP): 6
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0816
         Exactitud = (TP + TN) / N          = 0.9184
         Verificaci√≥n: 1 - Error            = 0.9184

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.0462

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6471
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.9538
         Verificaci√≥n: 1 - FP-Rate          = 0.9538

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6471

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      114        16
            Buggy           6        11
      ==================================================
      TN=114  FP=16  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 114
         False Positives (FP): 16
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1497
         Exactitud = (TP + TN) / N          = 0.8503
         Verificaci√≥n: 1 - Error            = 0.8503

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.1231

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4074
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.8769
         Verificaci√≥n: 1 - FP-Rate          = 0.8769

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5000

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      118        12
            Buggy           7        10
      ==================================================
      TN=118  FP=12  FN=7  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 118
         False Positives (FP): 12
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1293
         Exactitud = (TP + TN) / N          = 0.8707
         Verificaci√≥n: 1 - Error            = 0.8707

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5882
         FP-Rate = FP / N                   = 0.0923

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4545
         Recall = TP / P (= TP-Rate)        = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5882
         Especificidad = TN / N             = 0.9077
         Verificaci√≥n: 1 - FP-Rate          = 0.9077

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5128

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      130         0
            Buggy          16         1
      ==================================================
      TN=130  FP=0  FN=16  TP=1
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 1
         True Negatives  (TN): 130
         False Positives (FP): 0
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1088
         Exactitud = (TP + TN) / N          = 0.8912
         Verificaci√≥n: 1 - Error            = 0.8912

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0588
         FP-Rate = FP / N                   = 0.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 1.0000
         Recall = TP / P (= TP-Rate)        = 0.0588

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0588
         Especificidad = TN / N             = 1.0000
         Verificaci√≥n: 1 - FP-Rate          = 1.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1111

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      114        16
            Buggy           6        11
      ==================================================
      TN=114  FP=16  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 114
         False Positives (FP): 16
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1497
         Exactitud = (TP + TN) / N          = 0.8503
         Verificaci√≥n: 1 - Error            = 0.8503

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.1231

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4074
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.8769
         Verificaci√≥n: 1 - FP-Rate          = 0.8769

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5000

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      127         3
            Buggy          11         6
      ==================================================
      TN=127  FP=3  FN=11  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 127
         False Positives (FP): 3
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0952
         Exactitud = (TP + TN) / N          = 0.9048
         Verificaci√≥n: 1 - Error            = 0.9048

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3529
         FP-Rate = FP / N                   = 0.0231

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6667
         Recall = TP / P (= TP-Rate)        = 0.3529

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3529
         Especificidad = TN / N             = 0.9769
         Verificaci√≥n: 1 - FP-Rate          = 0.9769

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4615

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-06}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      124         6
            Buggy           6        11
      ==================================================
      TN=124  FP=6  FN=6  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 124
         False Positives (FP): 6
         False Negatives (FN): 6

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0816
         Exactitud = (TP + TN) / N          = 0.9184
         Verificaci√≥n: 1 - Error            = 0.9184

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.6471
         FP-Rate = FP / N                   = 0.0462

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6471
         Recall = TP / P (= TP-Rate)        = 0.6471

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.6471
         Especificidad = TN / N             = 0.9538
         Verificaci√≥n: 1 - FP-Rate          = 0.9538

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.6471

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      124         6
            Buggy           8         9
      ==================================================
      TN=124  FP=6  FN=8  TP=9
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 9
         True Negatives  (TN): 124
         False Positives (FP): 6
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0952
         Exactitud = (TP + TN) / N          = 0.9048
         Verificaci√≥n: 1 - Error            = 0.9048

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5294
         FP-Rate = FP / N                   = 0.0462

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6000
         Recall = TP / P (= TP-Rate)        = 0.5294

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5294
         Especificidad = TN / N             = 0.9538
         Verificaci√≥n: 1 - FP-Rate          = 0.9538

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5625

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: jruby-1.1 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      113        17
            Buggy           7        10
      ==================================================
      TN=113  FP=17  FN=7  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 113
         False Positives (FP): 17
         False Negatives (FN): 7

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1633
         Exactitud = (TP + TN) / N          = 0.8367
         Verificaci√≥n: 1 - Error            = 0.8367

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5882
         FP-Rate = FP / N                   = 0.1308

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3704
         Recall = TP / P (= TP-Rate)        = 0.5882

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5882
         Especificidad = TN / N             = 0.8692
         Verificaci√≥n: 1 - FP-Rate          = 0.8692

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4545

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-09}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      130         0
            Buggy          16         1
      ==================================================
      TN=130  FP=0  FN=16  TP=1
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 1
         True Negatives  (TN): 130
         False Positives (FP): 0
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1088
         Exactitud = (TP + TN) / N          = 0.8912
         Verificaci√≥n: 1 - Error            = 0.8912

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.0588
         FP-Rate = FP / N                   = 0.0000

      üîç Precision y Recall:
         Precision = TP / P'                = 1.0000
         Recall = TP / P (= TP-Rate)        = 0.0588

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.0588
         Especificidad = TN / N             = 1.0000
         Verificaci√≥n: 1 - FP-Rate          = 1.0000

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.1111

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      124         6
            Buggy           8         9
      ==================================================
      TN=124  FP=6  FN=8  TP=9
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 147
         Positivos reales (P):    17 (Buggy)
         Negativos reales (N):    130 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 9
         True Negatives  (TN): 124
         False Positives (FP): 6
         False Negatives (FN): 8

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0952
         Exactitud = (TP + TN) / N          = 0.9048
         Verificaci√≥n: 1 - Error            = 0.9048

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5294
         FP-Rate = FP / N                   = 0.0462

      üîç Precision y Recall:
         Precision = TP / P'                = 0.6000
         Recall = TP / P (= TP-Rate)        = 0.5294

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5294
         Especificidad = TN / N             = 0.9538
         Verificaci√≥n: 1 - FP-Rate          = 0.9538

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.5625

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


================================================================================
‚úì PIPELINE COMPLETO PARA jruby-1.1
================================================================================




******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************
******************************************************************************************************************************************************

================ DATASET: wicket-1.3.0-beta2 ================


================================================================================
FASE 1: PREPROCESAMIENTO
================================================================================
[1] Preprocesamiento - Dataset original cargado: wicket-1.3.0-beta2
[1] Preprocesamiento - Dimensiones originales: (1763, 70)
[1] Preprocesamiento - Columnas eliminadas: ['HeuBug', 'HeuBugCount', 'RealBugCount']
[1] Preprocesamiento - Dimensiones nuevas: (1763, 67)
[1] Preprocesamiento - Divisi√≥n estratificada 80/20 realizada.
[1] Preprocesamiento - X_train: (1410, 66), X_test: (353, 66)
[1] Preprocesamiento - Archivos CSV guardados en con √©xito

================================================================================
FASE 2: BALANCEO DE CLASES
================================================================================


========== Ballanceo [CSBBoost] con wicket-1.3.0-beta2 ==========
=============================================================
[2] Balanceo [CSBBoost] - Carga de datos preprocesados completa.
[2] Balanceo [CSBBoost] - Selecci√≥n de columnas num√©ricas.
[2] Implementaci√≥n CSBBoost Iniciada
    Clase Mayoritaria (0): 1306
    Clase Minoritaria (1): 104
    Total de clases: 1410
    Ratio de desbalance: 12.56

Clases Mayoritarias---------
[Mayor√≠a] K √≥ptimo (Silhouette) = 2
[Mayor√≠a] Tama√±o despu√©s de undersampling clusterizado: 705

Clases Minoritarias---------
[Minor√≠a] K' √≥ptimo (Silhouette) = 2
[Minor√≠a] Nuevas muestras sint√©ticas generadas: 601
[Minor√≠a] Tama√±o final (original + sint√©tico): 705

CSBBoost balanceo terminado.
    Tama√±o final train balanceado: 1410
    Distribuci√≥n clases: {0: 705, 1: 705}

[2] Balanceo [CSBBoost] - CSBBoost completado.
[2] Balanceo [CSBBoost] - Archivos CSV guardados con √©xito.


========== Balanceo [HCBOU] con wicket-1.3.0-beta2 ==========
=========================================================
[2] Balanceo [HCBOU] - Carga de datos preprocesados completa.
[2] Balanceo [HCBOU] - Selecci√≥n de columnas num√©ricas.
[2] Balanceo [HCBOU] - Par√°metros: {'max_clusters_maj': 8, 'max_clusters_min': 6, 'k_smote': 3, 'min_cluster_obs': 5}
[2] Implementaci√≥n de HCBOU Iniciada
    Clase mayoritaria (0): 1306 muestras
    Clase minoritaria (1): 104 muestras
    Total de clases: 1410
    Ratio de desbalance: 12.56

Clase Mayoritarias---------
[Mayoritaria] Aplicando submuestreo
[Mayoritaria] Tama√±o despu√©s de submuestreo: 705

Clase minoritarias---------
[Minoritaria] K √≥ptimo (Silhouete) = 2
[Minoritaria] N√∫mero √≥ptimo de clusters: 2
Mejor √≠ndice silhouette: 0.7938
[Minoritaria] K¬¥ √≥ptimo (Silhouete) = 2
[Minoritaria] Nuevas muestras sint√©ticas generadas: 600
[Minoritaria] Tama√±o final (original + sint√©tico): 704

HCBOU balanceo terminado.
    Tama√±o final del train balanceado: 1409
    Distribuci√≥n clases: {0: 705, 1: 704}

[2] Balanceo [HCBOU] - HCBOU completado.
[2] Balanceo [HCBOU] - Archivos CSV guardados con √©xito.


========== Balanceo [SMOTE] con wicket-1.3.0-beta2 ==========
=========================================================
[2] Balanceo [SMOTE] - Carga de datos preprocesados completa.
[2] Balanceo [SMOTE] - Selecci√≥n de columnas num√©ricas.
Implementaci√≥n de SMOTE Iniciada.
     Clase mayoritaria (0):  1306
     Clase minoritaria (1):  104
     Total de clases:  1410
     Indice de desbalance:  12.56

[SMOTE] Clase mayoritaria (0): 1306 -> 705 muestras
[SMOTE] Distribuci√≥n final (aprox N/2 por clase): {0: 705, 1: 705}

[2] Balanceo [SMOTE] - SMOTE completado.
[2] Balanceo [SMOTE] - Archivos CSV guardados con √©xito.

================================================================================
FASE 3: ESCALADO DE CARACTER√çSTICAS
================================================================================
[3] [csbboost] Escalando wicket-1.3.0-beta2 con standard
[3] [csbboost] Escalando wicket-1.3.0-beta2 con robust
[3] [hcbou] Escalando wicket-1.3.0-beta2 con standard
[3] [hcbou] Escalando wicket-1.3.0-beta2 con robust
[3] [smote] Escalando wicket-1.3.0-beta2 con standard
[3] [smote] Escalando wicket-1.3.0-beta2 con robust

================================================================================
FASE 4: B√öSQUEDA DE HIPERPAR√ÅMETROS (GRIDSEARCH)
================================================================================

================================================================================
B√öSQUEDA DE HIPERPAR√ÅMETROS CON GRIDSEARCH: wicket-1.3.0-beta2
================================================================================

------------------------------------------------------------
Procesando: csbboost_standard
------------------------------------------------------------

‚Üí wicket-1.3.0-beta2 | csbboost | standard

------------------------------------------------------------
Procesando: csbboost_robust
------------------------------------------------------------

‚Üí wicket-1.3.0-beta2 | csbboost | robust

------------------------------------------------------------
Procesando: hcbou_standard
------------------------------------------------------------

‚Üí wicket-1.3.0-beta2 | hcbou | standard

------------------------------------------------------------
Procesando: hcbou_robust
------------------------------------------------------------

‚Üí wicket-1.3.0-beta2 | hcbou | robust

------------------------------------------------------------
Procesando: smote_standard
------------------------------------------------------------

‚Üí wicket-1.3.0-beta2 | smote | standard

------------------------------------------------------------
Procesando: smote_robust
------------------------------------------------------------

‚Üí wicket-1.3.0-beta2 | smote | robust

================================================================================
FASE 5: ENTRENAMIENTO FINAL CON MEJORES HIPERPAR√ÅMETROS
================================================================================

================================================================================
ENTRENAMIENTO FINAL DE MODELOS: wicket-1.3.0-beta2
================================================================================

------------------------------------------------------------
Configuraci√≥n: csbboost_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | csbboost | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      313        14
            Buggy          15        11
      ==================================================
      TN=313  FP=14  FN=15  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 313
         False Positives (FP): 14
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0822
         Exactitud = (TP + TN) / N          = 0.9178
         Verificaci√≥n: 1 - Error            = 0.9178

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4231
         FP-Rate = FP / N                   = 0.0428

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4400
         Recall = TP / P (= TP-Rate)        = 0.4231

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4231
         Especificidad = TN / N             = 0.9572
         Verificaci√≥n: 1 - FP-Rate          = 0.9572

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.4314

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.16s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      299        28
            Buggy          16        10
      ==================================================
      TN=299  FP=28  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 299
         False Positives (FP): 28
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1246
         Exactitud = (TP + TN) / N          = 0.8754
         Verificaci√≥n: 1 - Error            = 0.8754

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0856

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2632
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9144
         Verificaci√≥n: 1 - FP-Rate          = 0.9144

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3125

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      299        28
            Buggy          20         6
      ==================================================
      TN=299  FP=28  FN=20  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 299
         False Positives (FP): 28
         False Negatives (FN): 20

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1360
         Exactitud = (TP + TN) / N          = 0.8640
         Verificaci√≥n: 1 - Error            = 0.8640

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2308
         FP-Rate = FP / N                   = 0.0856

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1765
         Recall = TP / P (= TP-Rate)        = 0.2308

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2308
         Especificidad = TN / N             = 0.9144
         Verificaci√≥n: 1 - FP-Rate          = 0.9144

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2000

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.03s


------------------------------------------------------------
Configuraci√≥n: csbboost_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | csbboost | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      302        25
            Buggy          17         9
      ==================================================
      TN=302  FP=25  FN=17  TP=9
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 9
         True Negatives  (TN): 302
         False Positives (FP): 25
         False Negatives (FN): 17

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1190
         Exactitud = (TP + TN) / N          = 0.8810
         Verificaci√≥n: 1 - Error            = 0.8810

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3462
         FP-Rate = FP / N                   = 0.0765

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2647
         Recall = TP / P (= TP-Rate)        = 0.3462

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3462
         Especificidad = TN / N             = 0.9235
         Verificaci√≥n: 1 - FP-Rate          = 0.9235

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3000

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.12s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      299        28
            Buggy          16        10
      ==================================================
      TN=299  FP=28  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 299
         False Positives (FP): 28
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1246
         Exactitud = (TP + TN) / N          = 0.8754
         Verificaci√≥n: 1 - Error            = 0.8754

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0856

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2632
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9144
         Verificaci√≥n: 1 - FP-Rate          = 0.9144

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3125

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      299        28
            Buggy          20         6
      ==================================================
      TN=299  FP=28  FN=20  TP=6
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 6
         True Negatives  (TN): 299
         False Positives (FP): 28
         False Negatives (FN): 20

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1360
         Exactitud = (TP + TN) / N          = 0.8640
         Verificaci√≥n: 1 - Error            = 0.8640

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2308
         FP-Rate = FP / N                   = 0.0856

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1765
         Recall = TP / P (= TP-Rate)        = 0.2308

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2308
         Especificidad = TN / N             = 0.9144
         Verificaci√≥n: 1 - FP-Rate          = 0.9144

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2000

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: hcbou_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | hcbou | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      316        11
            Buggy          21         5
      ==================================================
      TN=316  FP=11  FN=21  TP=5
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 5
         True Negatives  (TN): 316
         False Positives (FP): 11
         False Negatives (FN): 21

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0907
         Exactitud = (TP + TN) / N          = 0.9093
         Verificaci√≥n: 1 - Error            = 0.9093

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.1923
         FP-Rate = FP / N                   = 0.0336

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3125
         Recall = TP / P (= TP-Rate)        = 0.1923

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.1923
         Especificidad = TN / N             = 0.9664
         Verificaci√≥n: 1 - FP-Rate          = 0.9664

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2381

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.18s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-07}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      304        23
            Buggy          16        10
      ==================================================
      TN=304  FP=23  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 304
         False Positives (FP): 23
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1105
         Exactitud = (TP + TN) / N          = 0.8895
         Verificaci√≥n: 1 - Error            = 0.8895

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0703

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3030
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9297
         Verificaci√≥n: 1 - FP-Rate          = 0.9297

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3390

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      240        87
            Buggy          11        15
      ==================================================
      TN=240  FP=87  FN=11  TP=15
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 15
         True Negatives  (TN): 240
         False Positives (FP): 87
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2776
         Exactitud = (TP + TN) / N          = 0.7224
         Verificaci√≥n: 1 - Error            = 0.7224

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5769
         FP-Rate = FP / N                   = 0.2661

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1471
         Recall = TP / P (= TP-Rate)        = 0.5769

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5769
         Especificidad = TN / N             = 0.7339
         Verificaci√≥n: 1 - FP-Rate          = 0.7339

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2344

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: hcbou_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | hcbou | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      312        15
            Buggy          16        10
      ==================================================
      TN=312  FP=15  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 312
         False Positives (FP): 15
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0878
         Exactitud = (TP + TN) / N          = 0.9122
         Verificaci√≥n: 1 - Error            = 0.9122

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0459

      üîç Precision y Recall:
         Precision = TP / P'                = 0.4000
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9541
         Verificaci√≥n: 1 - FP-Rate          = 0.9541

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3922

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.14s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-05}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      304        23
            Buggy          16        10
      ==================================================
      TN=304  FP=23  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 304
         False Positives (FP): 23
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1105
         Exactitud = (TP + TN) / N          = 0.8895
         Verificaci√≥n: 1 - Error            = 0.8895

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0703

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3030
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9297
         Verificaci√≥n: 1 - FP-Rate          = 0.9297

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3390

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 8, 'min_samples_split': 2}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      240        87
            Buggy          11        15
      ==================================================
      TN=240  FP=87  FN=11  TP=15
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 15
         True Negatives  (TN): 240
         False Positives (FP): 87
         False Negatives (FN): 11

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.2776
         Exactitud = (TP + TN) / N          = 0.7224
         Verificaci√≥n: 1 - Error            = 0.7224

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.5769
         FP-Rate = FP / N                   = 0.2661

      üîç Precision y Recall:
         Precision = TP / P'                = 0.1471
         Recall = TP / P (= TP-Rate)        = 0.5769

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.5769
         Especificidad = TN / N             = 0.7339
         Verificaci√≥n: 1 - FP-Rate          = 0.7339

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2344

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.01s


------------------------------------------------------------
Configuraci√≥n: smote_standard
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | smote | standard
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      313        14
            Buggy          19         7
      ==================================================
      TN=313  FP=14  FN=19  TP=7
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 7
         True Negatives  (TN): 313
         False Positives (FP): 14
         False Negatives (FN): 19

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.0935
         Exactitud = (TP + TN) / N          = 0.9065
         Verificaci√≥n: 1 - Error            = 0.9065

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.2692
         FP-Rate = FP / N                   = 0.0428

      üîç Precision y Recall:
         Precision = TP / P'                = 0.3333
         Recall = TP / P (= TP-Rate)        = 0.2692

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.2692
         Especificidad = TN / N             = 0.9572
         Verificaci√≥n: 1 - FP-Rate          = 0.9572

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2979

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.16s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-06}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      300        27
            Buggy          15        11
      ==================================================
      TN=300  FP=27  FN=15  TP=11
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 11
         True Negatives  (TN): 300
         False Positives (FP): 27
         False Negatives (FN): 15

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1190
         Exactitud = (TP + TN) / N          = 0.8810
         Verificaci√≥n: 1 - Error            = 0.8810

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.4231
         FP-Rate = FP / N                   = 0.0826

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2895
         Recall = TP / P (= TP-Rate)        = 0.4231

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.4231
         Especificidad = TN / N             = 0.9174
         Verificaci√≥n: 1 - FP-Rate          = 0.9174

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3438

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      294        33
            Buggy          16        10
      ==================================================
      TN=294  FP=33  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 294
         False Positives (FP): 33
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1388
         Exactitud = (TP + TN) / N          = 0.8612
         Verificaci√≥n: 1 - Error            = 0.8612

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.1009

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2326
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.8991
         Verificaci√≥n: 1 - FP-Rate          = 0.8991

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2899

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


------------------------------------------------------------
Configuraci√≥n: smote_robust
------------------------------------------------------------

‚Üí Entrenamiento final: wicket-1.3.0-beta2 | smote | robust
    ‚Üí svm: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - SVM
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      301        26
            Buggy          16        10
      ==================================================
      TN=301  FP=26  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - SVM
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 301
         False Positives (FP): 26
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1190
         Exactitud = (TP + TN) / N          = 0.8810
         Verificaci√≥n: 1 - Error            = 0.8810

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0795

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2778
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9205
         Verificaci√≥n: 1 - FP-Rate          = 0.9205

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3226

      ============================================================

    ‚úì svm: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.11s

    ‚Üí naive_bayes_gaussian: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'var_smoothing': 1e-06}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - NAIVE_BAYES_GAUSSIAN
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      299        28
            Buggy          16        10
      ==================================================
      TN=299  FP=28  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - NAIVE_BAYES_GAUSSIAN
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 299
         False Positives (FP): 28
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1246
         Exactitud = (TP + TN) / N          = 0.8754
         Verificaci√≥n: 1 - Error            = 0.8754

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.0856

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2632
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.9144
         Verificaci√≥n: 1 - FP-Rate          = 0.9144

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.3125

      ============================================================

    ‚úì naive_bayes_gaussian: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.00s

    ‚Üí decision_tree: cargando datos y hiperpar√°metros...
      Hiperpar√°metros: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5}
      Entrenando modelo final...
      Evaluando en test set...

      ==================================================
      MATRIZ DE CONFUSI√ìN - DECISION_TREE
      ==================================================
                        Predicci√≥n
                   No-Buggy    Buggy
      Real  No-Buggy      294        33
            Buggy          16        10
      ==================================================
      TN=294  FP=33  FN=16  TP=10
      ==================================================


      ============================================================
      M√âTRICAS FINALES - DECISION_TREE
      ============================================================

      üìä Conteos:
         Total de instancias (N): 353
         Positivos reales (P):    26 (Buggy)
         Negativos reales (N):    327 (No-Buggy)

      üéØ Matriz de Confusi√≥n:
         True Positives  (TP): 10
         True Negatives  (TN): 294
         False Positives (FP): 33
         False Negatives (FN): 16

      üìà Error y Exactitud:
         Error = (FP + FN) / N              = 0.1388
         Exactitud = (TP + TN) / N          = 0.8612
         Verificaci√≥n: 1 - Error            = 0.8612

      üé≤ Tasas:
         TP-Rate = TP / P                   = 0.3846
         FP-Rate = FP / N                   = 0.1009

      üîç Precision y Recall:
         Precision = TP / P'                = 0.2326
         Recall = TP / P (= TP-Rate)        = 0.3846

      üí° Sensibilidad y Especificidad:
         Sensibilidad = TP / P (= TP-Rate)  = 0.3846
         Especificidad = TN / N             = 0.8991
         Verificaci√≥n: 1 - FP-Rate          = 0.8991

      ‚≠ê Otras M√©tricas:
         F1-Score                           = 0.2899

      ============================================================

    ‚úì decision_tree: Entrenamiento y evaluaci√≥n completados
       Tiempo de entrenamiento: 0.02s


================================================================================
‚úì PIPELINE COMPLETO PARA wicket-1.3.0-beta2
================================================================================

==================================================
=== FIN DE EJECUCI√ìN DEL PIPELINE ===
Timestamp: 2025-11-27 19:35:12
==================================================
